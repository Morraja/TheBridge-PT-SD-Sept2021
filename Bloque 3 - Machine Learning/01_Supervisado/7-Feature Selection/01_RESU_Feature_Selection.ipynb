{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de variables (Feature Selection)\n",
    "\n",
    "En este notebook veremos los métodos más utilizados para seleccionar variables de nuestro dataframe que nos ayude a focalizar el problema. Pero, ¿por qué seleccionar variables, dónde queda eso de que necesitamos datos y cuantos más datos mejor? Pues sí y no, porque obtendremos mejores resultados cuanta más información **útil** dispongamos para extraer patrones.\n",
    "\n",
    "Existen dos razones principales por las que hacer selección de variables:\n",
    " - **Reducir complejidad coputacional.** Cuantos menos datos tengamos, menor carga tendrá que soportar el modelo, por lo que podrá realizar los cálculos mucho más rápido, y necesitaremos menores recursos para implementarlo.\n",
    " - **Reducir overfitting.** Algunos algoritmos se ven afectados por las variables que no aportan información para predecir la variable objetivo, ya que generan ruido y favorecen que el resultado sea menos preciso, pues el algoritmo no es capaz de detectar que no es información útil y hacen overfitting con estas variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto en la teoría, tenemos diferentes tipos de reducción de variables. Podemos diferenciar 3 tipos diferentes:\n",
    "\n",
    " - **Supervisado**: buscamos extraer la información comparando con la varaible objetivo.\n",
    " - **No supervisadoo**: como no tenemos variable objetivo, solo podemos buscar relaciones entre las propias variables\n",
    " - **Reducción de dimensionalidad**: buscamos reducir variables creándonos otras que sean combinaciones de las originales. Lo que buscamos aquí consiste en sacar la información mínima necesaria de las variables que tenemos para crearnos un conjunto de menos variables que las originales. Dentro de estos métodos entra nuestro amigo PCA, sobre el cual volveremos mucho más adelante.\n",
    " \n",
    "En este notebook veremos los 2 primeros, que son los que más vamos a utilizar, y que no suponen la pérdida de las variables originales. Para facilitar el seguimiento del notebook, se ha decidido dividirlo con el siguiente formato:\n",
    " - Selección basada en estadísticos (no supervisado y supervisado)\n",
    " - Selección basada en modelo (Solo supervisado):\n",
    "   - Intrínseco\n",
    "   - Wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección basada en estadísticos\n",
    "\n",
    "La primera opción que se nos viene a la cabeza a la hora de reducir variables, es la eliminación de aquellas varaibles que no presentan cambios, es decir, las constantes, ya que no aportan absolutamente nada de información. Partiendo de esta premisa, es razonable asumir que las características con baja varianza son peores que aquellas con alta varianza. Por lo tanto, se puede considerar que las características con variación por debajo de un cierto umbral no serán útiles para nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basado en estadísticos: No supervisado\n",
    "\n",
    "Para ello, nos vamos a basar en el objeto de ``sklearn`` llamado ``VarainceThreshold``, y es que para casi todo lo que te puedas imaginar hay un objeto de ``sklearn``. Su tilización será exactamente igual que los que hemos visto hasta la fecha: ``fit`` con los datos y posterior ``transform`` (o ``fit_transform`` directamente). Cuando lo creamos, podemos indicar el umbral que queremos utilizar para mantener o no una variable en nuestro dataset.\n",
    "\n",
    "Además, utilizaremos la función ``make_classification``, que nos generará automáticamente un dataset aleatorio con un target binario.\n",
    "\n",
    "Para comprobar el funcionamiento del objeto, utilizaremos el atributo ``shape``, que nos indicará cuántas filas (las mismas siempre) y columnas tiene la salida, pudiendo comprobar que se reducen las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T10:10:17.058096Z",
     "start_time": "2020-11-19T10:10:13.843481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "x_data_generated, y_data_generated = make_classification()\n",
    "x_data_generated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T10:10:17.825065Z",
     "start_time": "2020-11-19T10:10:17.818065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empezamos con un umbral relativamente bajo, 0.7, lo que significa que se eliminarán aquellas variables que tengan una varainza de 0.7 o inferior:\n",
    "umbral = 0.7\n",
    "\n",
    "VarianceThreshold(umbral).fit_transform(x_data_generated).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T10:10:18.837626Z",
     "start_time": "2020-11-19T10:10:18.833589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subiendo el umbral de varianza, nos vamos quedando con las variables que varían más, es decir, con aquellas que más información nos aportan:\n",
    "umbral = 0.8\n",
    "\n",
    "VarianceThreshold(umbral).fit_transform(x_data_generated).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T10:10:20.212419Z",
     "start_time": "2020-11-19T10:10:20.207432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umbral = 0.9\n",
    "\n",
    "VarianceThreshold(umbral).fit_transform(x_data_generated).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Basado en estadísticos: Supervisado\n",
    "\n",
    "Además de lo que acabamos de ver para el caso \"No supervisado\", cuando disponemos de un objetivo podemos aplicar otras técnicas. En este caso, lo que vamos a hacer es utilizar la función ``f_classif``, que nos devuelve la relación de cada varaible con el objetivo. En el caso de clasificación utilizamos ``f_classif``, mientras que para los modelos de regresión utilizaremos ``f_rregression``.\n",
    "\n",
    "Si te fijas en el código, utilizaremos este objeto como argumento de otro objeto: ``SelectKBest``, que es un objeto que, dada una función de scoring (como es ``f_classif``) y un valor entero ``k``, me devolverá únicamente las ``k`` varaibles con mayor score en base a esa funciónd e scoring. En el ejemplo, nos quedaremos con las 5 variables que mayor relación tienen con el objetivo.\n",
    "\n",
    "Por si te interesa, existen otras funciones de scoring, como son ``mutual_info_classif`` o ``mutual_info_regression``.\n",
    "\n",
    "Además, utilizaremos la función ``cross_val_score`` para validar los resultados. Lo que hace esta función es evaluar un modelo haciendo *cross validation* sobre un conjunto de datos, buscando minimizar el error (el valor negativo es porque internamente busca maximizar algo, y queremos que el error sea mínimo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T10:10:22.132032Z",
     "start_time": "2020-11-19T10:10:22.121062Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "x_data_kbest = SelectKBest(f_classif, k=5).fit_transform(x_data_generated, y_data_generated)\n",
    "x_data_varth = VarianceThreshold(.9).fit_transform(x_data_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a comprobar si realmente mejora nuestro modelo o no. Para ello, utilizaremos el mimsmo modelo en todos, que en este caso será una regresión logística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T10:10:24.915747Z",
     "start_time": "2020-11-19T10:10:24.911758Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logit = LogisticRegression(solver='lbfgs', random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T10:10:25.414124Z",
     "start_time": "2020-11-19T10:10:25.386181Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.25200045497449886"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logit, x_data_generated, y_data_generated, \n",
    "                scoring='neg_log_loss', cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T10:10:25.923503Z",
     "start_time": "2020-11-19T10:10:25.907511Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21056685727321672"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logit, x_data_kbest, y_data_generated, \n",
    "                scoring='neg_log_loss', cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T10:10:26.516993Z",
     "start_time": "2020-11-19T10:10:26.500038Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.24344334581500177"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logit, x_data_varth, y_data_generated, \n",
    "                scoring='neg_log_loss', cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Como puedes observar, el valor se aproxima más a 0 cuando utilizamos nuestra selección de variables, lo que nos hace suponer que esto realmente funciona, auqnue para comprobarlo deberíamos utilizar un caso real, y no siempre nos va a resultar de utilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO\n",
    "\n",
    "Prueba la selección de variables que acabamos de ver con el conjunto de datos del Titanic. En este caso, intenta predecir si se trata de un hombre o de una mujer. Para ello, créate 1 modelo (el que quieras) y ejecútalo con las diferentes combinaciones, haciendo uso de la función ``cross_val_score``, por lo que no será necesario que dividas en train y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../../../data/titanic.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived      int64\n",
      "Pclass        int64\n",
      "Age         float64\n",
      "SibSp         int64\n",
      "Parch         int64\n",
      "Embarked     object\n",
      "Sex          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_cols = ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Embarked']\n",
    "y_col = 'Sex'\n",
    "df = df[X_cols + [y_col]]\n",
    "df['Age'] = df['Age'].fillna(0)\n",
    "df['Embarked'] = df['Embarked'].fillna('')\n",
    "print(df.dtypes)\n",
    "\n",
    "X = pd.get_dummies(df[X_cols])\n",
    "Y = df[y_col]\n",
    "\n",
    "X_kbest = SelectKBest(f_classif, k=3).fit_transform(X, Y)\n",
    "X_varth = VarianceThreshold(.7).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_varth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T10:10:25.414124Z",
     "start_time": "2020-11-19T10:10:25.386181Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7824596774193548"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, X, Y, scoring='accuracy', cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T10:10:25.923503Z",
     "start_time": "2020-11-19T10:10:25.907511Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8012096774193548"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, X_kbest, Y, scoring='accuracy', cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T10:10:26.516993Z",
     "start_time": "2020-11-19T10:10:26.500038Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6284274193548386"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, X_varth, Y, scoring='accuracy', cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección basada en modelo\n",
    "\n",
    "Otro enfoque que se suele dar a este probleam consiste en utilizar algún modelo de referencia para la selección de variables, basando en la imprtancia de estas en la toma de decisiones del modelo. Se suelen utilizar dos tipos de modelos: alguno basado en árboles como los árboles de decisión o un modelo lineal con regularización Lasso, para que sea propenso a eliminar aquellos pesos de las variables menos importantes.\n",
    "\n",
    "La premisa es clara: si las varaibles no aportan nada de información a un modelo simple, no es necesario arrastrarlas a uno más complejo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervisado intrínseco\n",
    "\n",
    "Para esta implementación, nos vamos a ayudar del objeto ``SelectFromModel``, que recibirá como un modelo como parámetro ``estimator`` y nos devolverá las variables más relevantes para dicho modelo.\n",
    "\n",
    "Además, utilizaremos un objeto que nos servirá de enlace con el próximo notebook: ``make_pipeline``. Este objeto nos permitirá enlazar más de un objeto de ``sklearn`` para pasárselo a nuestro ``cross_val_score`` y que podemos evaluarlo de forma directa, sin tener que hacer cosas \"por fuera\". Como veremos en el próximo notebook, estos \"pipelines\" nos serán de mucha utilidad.\n",
    "\n",
    "Finalmente, comprobamos cómo funcionan diferentes algoritmos: *LogisticRegression*, *DecisionTreeClassifier* y *DecisionTreeClassifier* con selección de variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T10:10:29.773202Z",
     "start_time": "2020-11-19T10:10:29.554472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.16306275850824994\n",
      "-2.7631181035414594\n",
      "-0.1780273414861167\n"
     ]
    }
   ],
   "source": [
    "# Synthetic example\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "x_data_generated, y_data_generated = make_classification()\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=10, random_state=17)\n",
    "pipe = make_pipeline(SelectFromModel(estimator=clf), logit)\n",
    "\n",
    "print(cross_val_score(logit, x_data_generated, y_data_generated, scoring='neg_log_loss', cv=5).mean())\n",
    "print(cross_val_score(clf, x_data_generated, y_data_generated, scoring='neg_log_loss', cv=5).mean())\n",
    "print(cross_val_score(pipe, x_data_generated, y_data_generated, scoring='neg_log_loss', cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes observar, en este caso nos mejora el modelo de regresión logística basándose en las mejores varaibles seleccionadas por el árbol de decisión, que por sí solo no es precisamente bueno. Sin embargo, esto no siempre es así, dependerá mucho de los datos, como todo en este mundo, auqnue por lo general suele mejorar más veces de las que empeora los resultados. Además, el número de variables modificará enormemente este resultado.\n",
    "\n",
    "Por otra parte, podemos aplicar la estandarización a nuestros datos para ver si mejoran los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T10:12:40.084628Z",
     "start_time": "2020-11-19T10:12:39.986914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR + selection:  -0.19112417902348622\n",
      "LR:  -0.17459386179109018\n",
      "DT:  -2.7631181035414594\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_data = x_data_generated\n",
    "y_data = y_data_generated\n",
    "\n",
    "pipe1 = make_pipeline(StandardScaler(), SelectFromModel(estimator=clf), logit)\n",
    "\n",
    "pipe2 = make_pipeline(StandardScaler(), logit)\n",
    "\n",
    "print('LR + selection: ', cross_val_score(pipe1, x_data_generated, y_data_generated, scoring='neg_log_loss', cv=5).mean())\n",
    "print('LR: ', cross_val_score(pipe2, x_data_generated, y_data_generated, scoring='neg_log_loss', cv=5).mean())\n",
    "print('DT: ', cross_val_score(clf, x_data_generated, y_data_generated, scoring='neg_log_loss', cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, y contra lo que podíamos imaginar, los resultados empeoran, poniendo de manifiesto que no siempre podemos anticiparnos a lo que va a pasar, que necesitamos probar y probar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO\n",
    "\n",
    "Utiliza el DataFrame que te dejo a continuación para trabajar los conceptos que acabamos de ver. Prueba los 2 modelos de clasificación que te apetezcan y compáralos entre sí y con sus versiones basadas en selección de variables con estimador basado en Árbol de decisión y Regresión Logística, así como con y sin estandarización. Es decir, deberías terminar con un total de 10 modelos:\n",
    " - Modelo A\n",
    " - Modelo B\n",
    " - Modelo A con selección de variables basado en RL\n",
    " - Modelo A con selección de variables basado en DT\n",
    " - Modelo B con selección de variables basado en RL\n",
    " - Modelo B con selección de variables basado en DT\n",
    " - Modelo A con selección de variables basado en RL y escalado\n",
    " - Modelo A con selección de variables basado en DT y escalado\n",
    " - Modelo B con selección de variables basado en RL y escalado\n",
    " - Modelo B con selección de variables basado en DT y escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../../../data/vgsales.csv\")\n",
    "\n",
    "def get_platform(x):\n",
    "    if x in ['DS', 'Wii', 'GBA', 'GC', '3DS', 'N64']:\n",
    "        return 'Nintendo'\n",
    "    elif x in ['PS2', 'PS3', 'PS', 'PSP', 'PS4', 'PSV', 'SNES']:\n",
    "        return 'Sony'\n",
    "    elif x in ['X360', 'PC', 'XB', 'XOne']:\n",
    "        return 'Microsoft'\n",
    "    else:\n",
    "        return ''\n",
    "df['Platform'] = df['Platform'].apply(lambda x: get_platform(x))\n",
    "\n",
    "df = df[df['Platform'] != '']\n",
    "df = df[df['Publisher'].isin(df['Publisher'].value_counts()[:20].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['NA_Sales', 'JP_Sales', 'Other_Sales']:\n",
    "    df[col + '_global'] = df[col]/df['Global_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['NA_Sales', 'JP_Sales', 'Other_Sales']:\n",
    "    df[col + '_genre'] = df.groupby('Genre').apply(lambda x: x[col]/x[col].sum()).reset_index()[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.6567996637023186\n",
      "LR + Select LR: 0.6510008479919984\n",
      "LR + Select DT: 0.6213147499873164\n",
      "DT: 0.6492234470995533\n",
      "DT + Select LR: 0.566058721633943\n",
      "DT + Select DT: 0.64961709899763\n"
     ]
    }
   ],
   "source": [
    "X_cols = ['Year', 'Genre', 'Publisher', 'NA_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales', \n",
    "          'NA_Sales_global', 'JP_Sales_global', 'Other_Sales_global', 'Global_Sales', \n",
    "          'NA_Sales_genre', 'JP_Sales_genre', 'Other_Sales_genre', 'Global_Sales']\n",
    "y_col = 'Platform'\n",
    "\n",
    "X = pd.get_dummies(df[X_cols]).fillna(0)\n",
    "y = df[y_col]\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "lg = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "pipe_ejercicio = make_pipeline(StandardScaler(), lg)\n",
    "pipe_ejercicio_2 = make_pipeline(StandardScaler(), SelectFromModel(estimator=lg), lg)\n",
    "pipe_ejercicio_3 = make_pipeline(StandardScaler(), SelectFromModel(estimator=dt), lg)\n",
    "pipe_ejercicio_4 = make_pipeline(StandardScaler(), dt)\n",
    "pipe_ejercicio_5 = make_pipeline(StandardScaler(), SelectFromModel(estimator=lg), dt)\n",
    "pipe_ejercicio_6 = make_pipeline(StandardScaler(), SelectFromModel(estimator=dt), dt)\n",
    "\n",
    "print(f\"LR: {cross_val_score(pipe_ejercicio, X, y, scoring='accuracy', cv=5).mean()}\")\n",
    "print(f\"LR + Select LR: {cross_val_score(pipe_ejercicio_2, X, y, scoring='accuracy', cv=5).mean()}\")\n",
    "print(f\"LR + Select DT: {cross_val_score(pipe_ejercicio_3, X, y, scoring='accuracy', cv=5).mean()}\")\n",
    "print(f\"DT: {cross_val_score(pipe_ejercicio_4, X, y, scoring='accuracy', cv=5).mean()}\")\n",
    "print(f\"DT + Select LR: {cross_val_score(pipe_ejercicio_5, X, y, scoring='accuracy', cv=5).mean()}\")\n",
    "print(f\"DT + Select DT: {cross_val_score(pipe_ejercicio_6, X, y, scoring='accuracy', cv=5).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervisado wrapper\n",
    "\n",
    "Por último, vamos a utilizar otro método que suele emplearse muy a menudo: la selección de variables de forma recursiva. Para ello, nos basaremos en el objeto de ``sklearn`` llamado ``RFE``, que recibe como parámetros el modelo a utilizar para evaluar la importancia de las variables (``estimator``), el número de variables que seleccionar (``n_features_to_select``) y el número de variables que eliminar en cada iteración (``step``).\n",
    "\n",
    "En este caso, vamos a probar el ejemplo sobre el dataset de dígitos, y obtendremos las variables más importantes, que en este caso serán los píxeles. No hace falta que entiendas la mayoría del código, solamente quédate con la parte donde se utiliza el RFE, que es el objeto que nos permitirá reducir las variables de forma recursiva:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T10:36:46.595134Z",
     "start_time": "2020-11-19T10:36:36.919545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargamos los datos en \"X\" e \"y\":\n",
    "digits = load_digits()\n",
    "X = digits.images.reshape((len(digits.images), -1))\n",
    "y = digits.target\n",
    "\n",
    "# Creamos el objeto RFE y lo utilizamos para rankear la importancia de cada pixel:\n",
    "svc = SVC(kernel=\"linear\", C=1)\n",
    "rfe = RFE(estimator=svc, n_features_to_select=1, step=1)\n",
    "rfe.fit(X, y)\n",
    "ranking = rfe.ranking_.reshape(digits.images[0].shape)\n",
    "\n",
    "# Graficamos este ranking:\n",
    "plt.matshow(ranking, cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.title(\"Pixels más importantes según RFE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T10:42:05.336475Z",
     "start_time": "2020-11-19T10:41:59.409990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 10)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel=\"linear\", C=1)\n",
    "rfe = RFE(estimator=svc, n_features_to_select=10, step=1)\n",
    "rfe.fit_transform(X, y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO\n",
    "\n",
    "Vuelve a leer el DataFrame del Titanic y crea un modelo que sea capaz de predecir si una persona ha sobrevivido o no. Para ello, realiza lo siguiente:\n",
    " 1. Modelo regresión logística\n",
    " 2. Modelo regresión logística con estandarización\n",
    " 3. Modelo regresión logística con selección de varaibles basado en varianza\n",
    " 4. Modelo regresión logística con selección de variables basado en árbol de decisión\n",
    " 5. Modelo regresión logística con selección de variables basado en árbol de decisión y escalado\n",
    " 6. Modelo regresión logística con selección de variables basado en RFE\n",
    " 7. Modelo regresión logística con selección de variables basado en RFE y escalado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
