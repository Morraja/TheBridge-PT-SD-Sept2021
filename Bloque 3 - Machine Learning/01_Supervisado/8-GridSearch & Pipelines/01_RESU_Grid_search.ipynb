{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch y Pipelines\n",
    "\n",
    "En este notebook vamos a ver un par de cosas que ya hemos mencionado en algún que otro notebook:\n",
    " - **GridSearch**: es una herramienta de optimización que se utiliza para buscar la mejor combinación de hiperparámetros. Consiste en definir una red de valores para cada parámetro, y el objeto se encargará de gestionar la combinación de cada uno de ellos, devolviendo el mejor resultado en cada caso.\n",
    " \n",
    " - **Pipelines**: son una interfaz para trabajar con combinaciones de objetos de ``sklearn`` como si fueran uno solo. De este modo, podremos diseñar combinaciones de tratamientos de datos con modelos y utilizarlos en nuestros GridSearch, o aplicarles cross validation, como vimos en el notebook pasado. En este caso los implementaremos directamente, en lugar de utilizar una función específica.\n",
    " \n",
    "Para implementar la búsqueda de la combinación de parámetros óptima, vamos a ver 3 estrategias, que irán avanzando de menor a mayor complejidad:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Método simple\n",
    "\n",
    "Itera un algoritmo sobre un conjunto de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 100],\n",
       "                         'coef0': [-10, -1, 0, 0.1, 0.5, 1, 10, 100],\n",
       "                         'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'rbf', 'sigmoid']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "\n",
    "# Cargamos los datos:\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state=42)\n",
    "\n",
    "# Creamos modelo:\n",
    "svc = svm.SVC()\n",
    "\n",
    "# Definimos parámetros:\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "    'C': [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'coef0': [-10, -1, 0, 0.1, 0.5, 1, 10, 100]\n",
    "    \n",
    "}\n",
    "\n",
    "# Nos creamos iterador basado en cross validation:\n",
    "grid = GridSearchCV(estimator = svc,\n",
    "                   param_grid = parameters,\n",
    "                   n_jobs = -1,\n",
    "                   scoring = 'accuracy',\n",
    "                   cv = 10)\n",
    "\n",
    "# Entrenamos sobre train:\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator: SVC(C=0.1, coef0=-10, kernel='linear')\n",
      "Best params: {'C': 0.1, 'coef0': -10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best score: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos los mejores parámetros:\n",
    "print(\"Best estimator:\", grid.best_estimator_)\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y lo probamos sobre test:\n",
    "best_estimator = grid.best_estimator_\n",
    "best_estimator.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Forma pro\n",
    "\n",
    "La forma pro es la que hace esto mismo, pero recogiendo los errores de entrenamiento y validación, y teniendo la capacidad de parar el proceso cuando se requiera. Además, puede guardar el modelo en local una vez terminado si es mejor que el que había anteriormente, o cargar el modelo anterior y seguir reentrenando (no en este notebook).\n",
    "\n",
    "En este caso, además, introduciremos los pipelines, creándolos utilizando directamente su constructor ``Pipeline(steps=[])``. Si te fijas bien en el código, con este método podemos comparar diferentes algoritmos, con sus diferentes combinaciones de parámetros, gracias a estos pipelines. La sintáxis es el objeto ``Pipeline``, que recibe como parámetros ``steps``, que es una lista de tuplas, donde la primera se corresponde con el nombre que le das al paso, y el segundo el obejto que se ejecuta en ese paso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('classifier',\n",
       "                                        DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'classifier': [LogisticRegression(C=1.5)],\n",
       "                          'classifier__C': array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5]),\n",
       "                          'classifier__penalty': ['l1', 'l2']},\n",
       "                         {'classifier': [DecisionTreeClassifier()],\n",
       "                          'classifier__criterion': ['entropy', 'gini'],\n",
       "                          'classifier__max_depth': [10, 8, 5, 2]},\n",
       "                         {'classifier': [SVC()],\n",
       "                          'classifier__kernel': ['linear', 'rbf', 'sigmoid']}])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe = Pipeline(steps=[('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "logistic_params = {\n",
    "    'classifier': [LogisticRegression()],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__C': np.arange(0, 4, 0.5)\n",
    "}\n",
    "\n",
    "decision_tree_params = {\n",
    "    'classifier': [DecisionTreeClassifier()],\n",
    "    'classifier__max_depth': [10, 8, 5, 2],\n",
    "    'classifier__criterion': ['entropy', 'gini']\n",
    "}\n",
    "\n",
    "svc_params = {\n",
    "    'classifier': [svm.SVC()],\n",
    "    'classifier__kernel': ['linear', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "search_space = [logistic_params, decision_tree_params, svc_params]\n",
    "\n",
    "grid = GridSearchCV(pipe,\n",
    "                   search_space,\n",
    "                   cv=10,\n",
    "                   n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('classifier', LogisticRegression(C=1.5))])\n",
      "{'classifier': LogisticRegression(C=1.5), 'classifier__C': 1.5, 'classifier__penalty': 'l2'}\n",
      "0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(grid.predict(X_test))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Next Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comenzamos definiendo los pipelines principales:\n",
    "reg_log = Pipeline(steps = [\n",
    "    (\"imputer\", SimpleImputer()),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"reglog\", LogisticRegression())\n",
    "])\n",
    "\n",
    "svc = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"selectkbest\", SelectKBest()),\n",
    "    (\"svc\", svm.SVC())\n",
    "])\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "# Y definimos sus parámetros:\n",
    "re_log_param = {\n",
    "    \"imputer__strategy\": ['mean', 'median', 'most_frequent'],\n",
    "    \"reglog__penalty\": [\"l1\", \"l2\"],\n",
    "    \"reglog__C\": np.arange(0, 4, 0.5)\n",
    "}\n",
    "\n",
    "svc_param = {\n",
    "    \"selectkbest__k\": [1, 2, 3],\n",
    "    \"svc__C\": np.arange(0.1, 0.9, 0.1),\n",
    "    \"svc__kernel\": ['linear', 'poly', 'rbf']\n",
    "}\n",
    "\n",
    "decision_tree_params = {\n",
    "    'max_depth': [10, 100, 500, 1000],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Nos creamos los grids de cada uno:\n",
    "gs_reg_log = GridSearchCV(reg_log,\n",
    "                         re_log_param,\n",
    "                         cv = 10,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=-1,\n",
    "                         verbose=1)\n",
    "\n",
    "gs_svm = GridSearchCV(svc,\n",
    "                         svc_param,\n",
    "                         cv = 10,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=-1,\n",
    "                         verbose=1)\n",
    "\n",
    "gs_decision_tree = GridSearchCV(decision_tree,\n",
    "                         decision_tree_params,\n",
    "                         cv = 10,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=-1,\n",
    "                         verbose=1)\n",
    "grids = {\n",
    "    \"gs_reg_log\": gs_reg_log,\n",
    "    \"gs_svm\": gs_svm,\n",
    "    \"gs_rand_forest\": gs_decision_tree\n",
    "}\n",
    "#gs_reg_log.fit(X_train, y_train)\n",
    "#print(\"Best estimator:\", gs_reg_log.best_estimator_)\n",
    "#print(\"Best params:\", gs_reg_log.best_params_)\n",
    "#print(\"Best score:\", gs_reg_log.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "for nombre, grid_search in grids.items():\n",
    "    grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('gs_reg_log', GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('imputer', SimpleImputer()),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('reglog', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'imputer__strategy': ['mean', 'median',\n",
       "                                               'most_frequent'],\n",
       "                         'reglog__C': array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5]),\n",
       "                         'reglog__penalty': ['l1', 'l2']},\n",
       "             scoring='accuracy', verbose=1)), ('gs_svm', GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('selectkbest', SelectKBest()),\n",
       "                                       ('svc', SVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'selectkbest__k': [1, 2, 3],\n",
       "                         'svc__C': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]),\n",
       "                         'svc__kernel': ['linear', 'poly', 'rbf']},\n",
       "             scoring='accuracy', verbose=1)), ('gs_rand_forest', GridSearchCV(cv=10, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [10, 100, 500, 1000]},\n",
       "             scoring='accuracy', verbose=1))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grids.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grid</th>\n",
       "      <th>Best score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs_svm</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs_reg_log</td>\n",
       "      <td>0.941667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs_rand_forest</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Grid  Best score\n",
       "1          gs_svm    0.950000\n",
       "0      gs_reg_log    0.941667\n",
       "2  gs_rand_forest    0.925000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grids = [(i, j.best_score_) for i, j in grids.items()]\n",
    "\n",
    "best_grids = pd.DataFrame(best_grids, columns = ['Grid', 'Best score'])\n",
    "best_grids.sort_values(by='Best score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator: Pipeline(steps=[('scaler', StandardScaler()), ('selectkbest', SelectKBest(k=2)),\n",
      "                ('svc', SVC(C=0.1, kernel='linear'))])\n",
      "Best params: {'selectkbest__k': 2, 'svc__C': 0.1, 'svc__kernel': 'linear'}\n",
      "Best score: 0.9499999999999998\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator:\", gs_svm.best_estimator_)\n",
    "print(\"Best params:\", gs_svm.best_params_)\n",
    "print(\"Best score:\", gs_svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenemos mejores resultados:\n",
    "estimador = gs_svm.best_estimator_\n",
    "estimador.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos predecir:\n",
    "estimador.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraemos los nombres de las variables:\n",
    "iris['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.72477507e-23, 2.69962606e-14, 1.93619072e-72, 3.57639330e-65])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sacamos los pvalores de cada uno\n",
    "estimador['selectkbest'].pvalues_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos guardar el modelo, podemos ayudarnos de **pickle**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Escribir\n",
    "with open('finished_model.model', 'wb') as archivo_salida:\n",
    "    pickle.dump(estimador, archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer\n",
    "with open('finished_model.model', 'rb') as archivo_entrada:\n",
    "    pipeline_importado = pickle.load(archivo_entrada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez importado, ya podemos utilizarlo como si lo acabásemos de crear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('selectkbest', SelectKBest(k=2)),\n",
       "                ('svc', SVC(C=0.1, kernel='linear'))])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_importado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_flowers = np.array([[6.9, 3.1, 5.1, 2.3],\n",
    "                        [5.8, 2.7, 3.9, 1.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_importado.predict(X_test)\n",
    "pipeline_importado.predict(new_flowers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm.best_estimator_.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
