{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHn7-mEg__Op"
   },
   "source": [
    "## Ejercicio: sklearn breast cancer\n",
    "\n",
    "1. Carga el dataset [breast_cancer de `sklearn`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2942,
     "status": "ok",
     "timestamp": 1600160561693,
     "user": {
      "displayName": "Clara Piniella",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZPvtfXzLnQ9Q1a_2oR-Aa6UCX0_HyTfsCraMd=s64",
      "userId": "06217688725952462825"
     },
     "user_tz": -120
    },
    "id": "trrbrcXx__Ov",
    "outputId": "b19676c4-6a3a-49ac-d22f-7ea24747b6ba"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(data=np.c_[cancer.data, cancer.target],\n",
    "                 columns = list(cancer.feature_names) + ['target'])\n",
    "\n",
    "y_col = 'target'\n",
    "X_cols = [col for col in df.columns if col not in y_col]\n",
    "\n",
    "X = df[X_cols].fillna(0)\n",
    "y = df[y_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar todos los métodos de clasificación vistos hasta ahora mediante GridSearchCV. Para ello vamos a ir poco a poco utilizando los métodos que acabamos de ver.\n",
    "\n",
    "En este caso, el objetivo será predecir si una persona tiene cáncer o no, por lo que utilizaremos algoritmos de clasificación para predecir la variable \"target\".\n",
    "\n",
    "2. Utiliza el método simple para, seleccionando un algoritmo de tu agrado, probar varias combinaciones de parámetros para obtener la mejor predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 100],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# Creamos modelo:\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Definimos parámetros:\n",
    "parameters = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 100],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag']\n",
    "    \n",
    "}\n",
    "\n",
    "# Nos creamos iterador basado en cross validation:\n",
    "grid = GridSearchCV(estimator = model,\n",
    "                   param_grid = parameters,\n",
    "                   n_jobs = -1,\n",
    "                   scoring = 'accuracy',\n",
    "                   cv = 10)\n",
    "\n",
    "# Entrenamos sobre train:\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9846153846153847\n",
      "Test: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {grid.score(X_train, y_train)}\")\n",
    "print(f\"Test: {grid.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Selecciona ahora dos algoritmos de clasificación y utiliza el \"método pro\" para encontrar la mejor combinación de modelo y parámetros posible. ¿Es mejor que la que habías obtenido antes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('modelo', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'modelo': [LogisticRegression(C=100,\n",
       "                                                        solver='newton-cg')],\n",
       "                          'modelo__C': [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 100],\n",
       "                          'modelo__penalty': ['l1', 'l2'],\n",
       "                          'modelo__solver': ['newton-cg', 'lbfgs', 'liblinear',\n",
       "                                             'sag']},\n",
       "                         {'modelo': [DecisionTreeClassifier()],\n",
       "                          'modelo__max_depth': array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                          'modelo__min_samples_split': [2, 5, 10]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe = Pipeline(steps=[(\"modelo\", LogisticRegression())])\n",
    "\n",
    "\n",
    "pipe_lg_params = {\n",
    "    'modelo': [LogisticRegression()],\n",
    "    'modelo__penalty': ['l1', 'l2'],\n",
    "    'modelo__C': [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 100],\n",
    "    'modelo__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag']\n",
    "}\n",
    "\n",
    "pipe_dt_params = {\n",
    "    'modelo': [DecisionTreeClassifier()],\n",
    "    'modelo__max_depth': np.arange(1, 10),\n",
    "    'modelo__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "search_space = [pipe_lg_params, pipe_dt_params]\n",
    "\n",
    "# Nos creamos iterador basado en cross validation:\n",
    "grid2 = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = search_space,\n",
    "    n_jobs = -1,\n",
    "    scoring = 'accuracy',\n",
    "    cv = 10)\n",
    "\n",
    "grid2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00290098, 0.00250058, 0.01290047, 0.00219977, 0.15769393,\n",
       "        0.07571802, 0.01080089, 0.03657613, 0.00200007, 0.00170002,\n",
       "        0.02060242, 0.00199995, 0.17341979, 0.07856021, 0.01199992,\n",
       "        0.0393038 , 0.00210071, 0.00220032, 0.17052305, 0.00195255,\n",
       "        0.15861964, 0.06030872, 0.01310432, 0.04660254, 0.00530131,\n",
       "        0.00220103, 0.31097641, 0.0032001 , 0.20077534, 0.05460715,\n",
       "        0.01545315, 0.03640213, 0.0025002 , 0.00200078, 0.34039662,\n",
       "        0.00200133, 0.2321142 , 0.05865872, 0.01360228, 0.03390517,\n",
       "        0.00240099, 0.00290065, 0.37366421, 0.00220053, 0.18968029,\n",
       "        0.05870738, 0.01400063, 0.03315377, 0.00160007, 0.00220058,\n",
       "        0.4116607 , 0.00200045, 0.20299335, 0.06071713, 0.01550167,\n",
       "        0.04450941, 0.00230463, 0.00160096, 0.36280684, 0.0017004 ,\n",
       "        0.28173332, 0.06030884, 0.01932118, 0.04373443, 0.00725222,\n",
       "        0.00913067, 0.00800397, 0.01110876, 0.01120918, 0.01100042,\n",
       "        0.01389952, 0.01299989, 0.0109    , 0.01330097, 0.01409998,\n",
       "        0.01209998, 0.0142009 , 0.01740158, 0.01335773, 0.014501  ,\n",
       "        0.01250007, 0.0174011 , 0.01350079, 0.01740053, 0.0159008 ,\n",
       "        0.01660144, 0.01790059, 0.01821818, 0.01335118, 0.01430125,\n",
       "        0.01210318]),\n",
       " 'std_fit_time': array([5.39233533e-04, 8.06707432e-04, 1.70050661e-03, 8.72089904e-04,\n",
       "        2.17838985e-02, 1.14339089e-02, 2.35803730e-03, 7.81198558e-03,\n",
       "        1.83272410e-06, 4.58010570e-04, 4.47629008e-03, 6.32221755e-04,\n",
       "        2.18917373e-02, 1.91155543e-02, 3.89826426e-03, 7.24240145e-03,\n",
       "        3.00091907e-04, 6.00593255e-04, 5.01485468e-02, 1.19210294e-03,\n",
       "        3.41581281e-02, 1.16636878e-02, 4.95728113e-03, 9.50072342e-03,\n",
       "        1.02472979e-02, 4.00391331e-04, 9.94272062e-02, 3.99408810e-03,\n",
       "        2.22567501e-02, 8.44037697e-03, 9.89087639e-03, 3.61158534e-03,\n",
       "        1.28422749e-03, 4.46809209e-04, 1.46368235e-01, 4.46547953e-04,\n",
       "        5.29513041e-02, 9.99905335e-03, 2.10763239e-03, 4.88581413e-03,\n",
       "        1.01992726e-03, 1.81354161e-03, 1.53892679e-01, 7.47966742e-04,\n",
       "        2.77338243e-02, 1.30266591e-02, 2.68478493e-03, 3.70126585e-03,\n",
       "        6.63465298e-04, 5.99235182e-04, 2.23955530e-01, 8.94337221e-04,\n",
       "        2.30718515e-02, 1.48115837e-02, 4.60878912e-03, 7.93648069e-03,\n",
       "        7.80253802e-04, 6.62847279e-04, 2.34926044e-01, 6.41740940e-04,\n",
       "        3.13007793e-02, 8.06571376e-03, 6.57312225e-03, 1.47300470e-02,\n",
       "        7.50000400e-04, 4.07537027e-03, 4.47801193e-04, 4.66020115e-03,\n",
       "        4.92380665e-03, 2.49085340e-03, 7.14764015e-03, 7.11359296e-03,\n",
       "        1.22053525e-03, 2.05276922e-03, 4.84788017e-03, 2.16597349e-03,\n",
       "        2.08898150e-03, 9.20114063e-03, 3.49894271e-03, 3.47172579e-03,\n",
       "        1.28525868e-03, 5.64201267e-03, 4.31868794e-03, 5.59049142e-03,\n",
       "        6.25231934e-03, 6.21740051e-03, 1.15633002e-02, 1.09246246e-02,\n",
       "        1.64297284e-03, 3.52342948e-03, 1.11148733e-03]),\n",
       " 'mean_score_time': array([0.        , 0.        , 0.00410066, 0.        , 0.00386915,\n",
       "        0.00465267, 0.00680678, 0.00775204, 0.        , 0.        ,\n",
       "        0.00610025, 0.        , 0.00559955, 0.00360134, 0.0043015 ,\n",
       "        0.00400152, 0.        , 0.        , 0.00690019, 0.        ,\n",
       "        0.00380032, 0.00479965, 0.00450048, 0.00370069, 0.        ,\n",
       "        0.        , 0.0046747 , 0.        , 0.00460031, 0.00410078,\n",
       "        0.00399997, 0.00480108, 0.        , 0.        , 0.00356236,\n",
       "        0.        , 0.00360088, 0.00555589, 0.00409985, 0.00510099,\n",
       "        0.        , 0.        , 0.00470083, 0.        , 0.00420072,\n",
       "        0.00360065, 0.00430105, 0.00745196, 0.        , 0.        ,\n",
       "        0.00420003, 0.        , 0.00540133, 0.00370009, 0.00360656,\n",
       "        0.00380304, 0.        , 0.        , 0.00330026, 0.        ,\n",
       "        0.00570056, 0.00560489, 0.00358012, 0.00441008, 0.00415051,\n",
       "        0.00399539, 0.00455246, 0.0046139 , 0.006899  , 0.00450079,\n",
       "        0.00340178, 0.00580177, 0.00390081, 0.00449991, 0.0053015 ,\n",
       "        0.00700121, 0.00540092, 0.00350015, 0.00404282, 0.0044003 ,\n",
       "        0.00393884, 0.00590041, 0.00360148, 0.00310044, 0.00470049,\n",
       "        0.00620015, 0.00390165, 0.00418413, 0.00420301, 0.00690343,\n",
       "        0.00475297]),\n",
       " 'std_score_time': array([0.        , 0.        , 0.00122031, 0.        , 0.0008318 ,\n",
       "        0.00123004, 0.00382204, 0.00724906, 0.        , 0.        ,\n",
       "        0.00482671, 0.        , 0.00346923, 0.00066385, 0.00118822,\n",
       "        0.00063298, 0.        , 0.        , 0.00457157, 0.        ,\n",
       "        0.001078  , 0.00354465, 0.001629  , 0.00089967, 0.        ,\n",
       "        0.        , 0.00214299, 0.        , 0.00091637, 0.00094238,\n",
       "        0.00044745, 0.00146947, 0.        , 0.        , 0.00093171,\n",
       "        0.        , 0.00049002, 0.00276927, 0.00144616, 0.00254753,\n",
       "        0.        , 0.        , 0.00141853, 0.        , 0.00160047,\n",
       "        0.00101969, 0.00118887, 0.00448899, 0.        , 0.        ,\n",
       "        0.0023588 , 0.        , 0.00380047, 0.00064047, 0.00067634,\n",
       "        0.00074706, 0.        , 0.        , 0.00089913, 0.        ,\n",
       "        0.00355112, 0.00648278, 0.00101396, 0.00202599, 0.00109617,\n",
       "        0.00161264, 0.00127288, 0.00164236, 0.00488708, 0.00080533,\n",
       "        0.00101952, 0.00451281, 0.00122158, 0.00136136, 0.00325715,\n",
       "        0.00435991, 0.00205879, 0.00067065, 0.00145988, 0.002245  ,\n",
       "        0.00185338, 0.00672909, 0.0004907 , 0.00053707, 0.00219364,\n",
       "        0.00483393, 0.0010436 , 0.00072981, 0.00087296, 0.01021982,\n",
       "        0.0033162 ]),\n",
       " 'param_modelo': masked_array(data=[LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    LogisticRegression(C=100, solver='newton-cg'),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier()],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_modelo__C': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_modelo__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l1',\n",
       "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l1', 'l1',\n",
       "                    'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2',\n",
       "                    'l2', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_modelo__solver': masked_array(data=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'newton-cg',\n",
       "                    'lbfgs', 'liblinear', 'sag', 'newton-cg', 'lbfgs',\n",
       "                    'liblinear', 'sag', 'newton-cg', 'lbfgs', 'liblinear',\n",
       "                    'sag', 'newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'newton-cg',\n",
       "                    'lbfgs', 'liblinear', 'sag', 'newton-cg', 'lbfgs',\n",
       "                    'liblinear', 'sag', 'newton-cg', 'lbfgs', 'liblinear',\n",
       "                    'sag', 'newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'newton-cg',\n",
       "                    'lbfgs', 'liblinear', 'sag', 'newton-cg', 'lbfgs',\n",
       "                    'liblinear', 'sag', 'newton-cg', 'lbfgs', 'liblinear',\n",
       "                    'sag', 'newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_modelo__max_depth': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 1, 1, 1, 2, 2, 2, 3, 3,\n",
       "                    3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9,\n",
       "                    9],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_modelo__min_samples_split': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 2, 5, 10, 2, 5, 10, 2,\n",
       "                    5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5,\n",
       "                    10, 2, 5, 10],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.001,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'newton-cg'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.001,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'lbfgs'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.001,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'liblinear'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.001,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'sag'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.001,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'newton-cg'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.001,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'lbfgs'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.001,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'liblinear'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.001,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'sag'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.01,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'newton-cg'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.01,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'lbfgs'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.01,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'liblinear'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.01,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'sag'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.01,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'newton-cg'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.01,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'lbfgs'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.01,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'liblinear'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.01,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'sag'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.1,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'newton-cg'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.1,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'lbfgs'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.1,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'liblinear'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.1,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'sag'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.1,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'newton-cg'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.1,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'lbfgs'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.1,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'liblinear'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.1,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'sag'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.5,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'newton-cg'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.5,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'lbfgs'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.5,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'liblinear'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.5,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'sag'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.5,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'newton-cg'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.5,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'lbfgs'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.5,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'liblinear'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 0.5,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'sag'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 1,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'newton-cg'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 1,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'lbfgs'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 1,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'liblinear'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 1,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'sag'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 1,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'newton-cg'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 1,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'lbfgs'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 1,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'liblinear'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 1,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'sag'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 5,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'newton-cg'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 5,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'lbfgs'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 5,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'liblinear'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 5,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'sag'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 5,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'newton-cg'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 5,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'lbfgs'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 5,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'liblinear'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 5,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'sag'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 10,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'newton-cg'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 10,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'lbfgs'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 10,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'liblinear'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 10,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'sag'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 10,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'newton-cg'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 10,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'lbfgs'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 10,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'liblinear'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 10,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'sag'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 100,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'newton-cg'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 100,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'lbfgs'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 100,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'liblinear'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 100,\n",
       "   'modelo__penalty': 'l1',\n",
       "   'modelo__solver': 'sag'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 100,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'newton-cg'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 100,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'lbfgs'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 100,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'liblinear'},\n",
       "  {'modelo': LogisticRegression(C=100, solver='newton-cg'),\n",
       "   'modelo__C': 100,\n",
       "   'modelo__penalty': 'l2',\n",
       "   'modelo__solver': 'sag'},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 1,\n",
       "   'modelo__min_samples_split': 2},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 1,\n",
       "   'modelo__min_samples_split': 5},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 1,\n",
       "   'modelo__min_samples_split': 10},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 2,\n",
       "   'modelo__min_samples_split': 2},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 2,\n",
       "   'modelo__min_samples_split': 5},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 2,\n",
       "   'modelo__min_samples_split': 10},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 3,\n",
       "   'modelo__min_samples_split': 2},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 3,\n",
       "   'modelo__min_samples_split': 5},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 3,\n",
       "   'modelo__min_samples_split': 10},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 4,\n",
       "   'modelo__min_samples_split': 2},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 4,\n",
       "   'modelo__min_samples_split': 5},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 4,\n",
       "   'modelo__min_samples_split': 10},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 5,\n",
       "   'modelo__min_samples_split': 2},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 5,\n",
       "   'modelo__min_samples_split': 5},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 5,\n",
       "   'modelo__min_samples_split': 10},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 6,\n",
       "   'modelo__min_samples_split': 2},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 6,\n",
       "   'modelo__min_samples_split': 5},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 6,\n",
       "   'modelo__min_samples_split': 10},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 7,\n",
       "   'modelo__min_samples_split': 2},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 7,\n",
       "   'modelo__min_samples_split': 5},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 7,\n",
       "   'modelo__min_samples_split': 10},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 8,\n",
       "   'modelo__min_samples_split': 2},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 8,\n",
       "   'modelo__min_samples_split': 5},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 8,\n",
       "   'modelo__min_samples_split': 10},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 9,\n",
       "   'modelo__min_samples_split': 2},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 9,\n",
       "   'modelo__min_samples_split': 5},\n",
       "  {'modelo': DecisionTreeClassifier(),\n",
       "   'modelo__max_depth': 9,\n",
       "   'modelo__min_samples_split': 10}],\n",
       " 'split0_test_score': array([       nan,        nan, 0.97826087,        nan, 1.        ,\n",
       "        1.        , 0.97826087, 0.95652174,        nan,        nan,\n",
       "        0.95652174,        nan, 0.97826087, 1.        , 1.        ,\n",
       "        0.95652174,        nan,        nan, 1.        ,        nan,\n",
       "        0.97826087, 0.97826087, 1.        , 0.95652174,        nan,\n",
       "               nan, 0.97826087,        nan, 0.97826087, 0.97826087,\n",
       "        0.97826087, 0.95652174,        nan,        nan, 0.97826087,\n",
       "               nan, 0.97826087, 0.97826087, 0.97826087, 0.95652174,\n",
       "               nan,        nan, 0.95652174,        nan, 0.97826087,\n",
       "        0.95652174, 0.97826087, 0.95652174,        nan,        nan,\n",
       "        0.95652174,        nan, 0.97826087, 0.95652174, 0.95652174,\n",
       "        0.95652174,        nan,        nan, 0.95652174,        nan,\n",
       "        0.95652174, 0.97826087, 0.95652174, 0.95652174, 0.89130435,\n",
       "        0.89130435, 0.89130435, 0.89130435, 0.89130435, 0.89130435,\n",
       "        0.97826087, 0.97826087, 0.97826087, 0.95652174, 0.95652174,\n",
       "        0.95652174, 0.93478261, 0.95652174, 0.93478261, 0.95652174,\n",
       "        0.93478261, 0.95652174, 0.93478261, 0.91304348, 0.93478261,\n",
       "        0.91304348, 0.89130435, 0.93478261, 0.91304348, 0.93478261,\n",
       "        0.91304348]),\n",
       " 'split1_test_score': array([       nan,        nan, 0.95652174,        nan, 0.97826087,\n",
       "        1.        , 1.        , 0.95652174,        nan,        nan,\n",
       "        0.97826087,        nan, 0.91304348, 1.        , 1.        ,\n",
       "        0.95652174,        nan,        nan, 0.95652174,        nan,\n",
       "        0.91304348, 0.95652174, 0.97826087, 0.95652174,        nan,\n",
       "               nan, 0.97826087,        nan, 0.91304348, 0.97826087,\n",
       "        0.97826087, 0.95652174,        nan,        nan, 0.95652174,\n",
       "               nan, 0.95652174, 0.97826087, 0.95652174, 0.95652174,\n",
       "               nan,        nan, 0.95652174,        nan, 0.95652174,\n",
       "        0.95652174, 0.95652174, 0.95652174,        nan,        nan,\n",
       "        0.95652174,        nan, 0.95652174, 0.95652174, 0.95652174,\n",
       "        0.95652174,        nan,        nan, 0.97826087,        nan,\n",
       "        0.95652174, 0.97826087, 0.95652174, 0.95652174, 0.86956522,\n",
       "        0.86956522, 0.86956522, 0.93478261, 0.93478261, 0.93478261,\n",
       "        0.91304348, 0.91304348, 0.91304348, 0.91304348, 0.91304348,\n",
       "        0.91304348, 0.91304348, 0.91304348, 0.91304348, 0.91304348,\n",
       "        0.91304348, 0.91304348, 0.91304348, 0.91304348, 0.91304348,\n",
       "        0.93478261, 0.93478261, 0.91304348, 0.93478261, 0.93478261,\n",
       "        0.91304348]),\n",
       " 'split2_test_score': array([       nan,        nan, 0.91304348,        nan, 0.91304348,\n",
       "        0.89130435, 0.89130435, 0.89130435,        nan,        nan,\n",
       "        0.89130435,        nan, 0.93478261, 0.91304348, 0.91304348,\n",
       "        0.89130435,        nan,        nan, 0.91304348,        nan,\n",
       "        0.95652174, 0.91304348, 0.93478261, 0.89130435,        nan,\n",
       "               nan, 0.93478261,        nan, 0.95652174, 0.93478261,\n",
       "        0.93478261, 0.89130435,        nan,        nan, 0.95652174,\n",
       "               nan, 0.95652174, 0.93478261, 0.95652174, 0.89130435,\n",
       "               nan,        nan, 0.97826087,        nan, 0.97826087,\n",
       "        0.97826087, 0.95652174, 0.89130435,        nan,        nan,\n",
       "        0.97826087,        nan, 0.97826087, 0.95652174, 0.97826087,\n",
       "        0.89130435,        nan,        nan, 0.97826087,        nan,\n",
       "        0.97826087, 0.93478261, 0.97826087, 0.89130435, 0.91304348,\n",
       "        0.91304348, 0.91304348, 0.97826087, 0.97826087, 0.97826087,\n",
       "        0.97826087, 0.97826087, 0.97826087, 0.97826087, 0.97826087,\n",
       "        0.97826087, 0.97826087, 0.97826087, 0.97826087, 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.97826087, 0.97826087,\n",
       "        0.97826087, 0.97826087, 0.97826087, 0.95652174, 1.        ,\n",
       "        1.        ]),\n",
       " 'split3_test_score': array([       nan,        nan, 0.86956522,        nan, 0.84782609,\n",
       "        0.84782609, 0.82608696, 0.84782609,        nan,        nan,\n",
       "        0.82608696,        nan, 0.91304348, 0.84782609, 0.84782609,\n",
       "        0.84782609,        nan,        nan, 0.86956522,        nan,\n",
       "        0.91304348, 0.89130435, 0.89130435, 0.84782609,        nan,\n",
       "               nan, 0.89130435,        nan, 0.91304348, 0.89130435,\n",
       "        0.89130435, 0.84782609,        nan,        nan, 0.89130435,\n",
       "               nan, 0.91304348, 0.89130435, 0.89130435, 0.84782609,\n",
       "               nan,        nan, 0.91304348,        nan, 0.93478261,\n",
       "        0.91304348, 0.91304348, 0.84782609,        nan,        nan,\n",
       "        0.93478261,        nan, 0.91304348, 0.89130435, 0.91304348,\n",
       "        0.84782609,        nan,        nan, 0.93478261,        nan,\n",
       "        0.93478261, 0.89130435, 0.93478261, 0.84782609, 0.80434783,\n",
       "        0.80434783, 0.80434783, 0.84782609, 0.84782609, 0.84782609,\n",
       "        0.84782609, 0.84782609, 0.84782609, 0.84782609, 0.84782609,\n",
       "        0.84782609, 0.84782609, 0.84782609, 0.84782609, 0.82608696,\n",
       "        0.82608696, 0.84782609, 0.82608696, 0.82608696, 0.84782609,\n",
       "        0.84782609, 0.82608696, 0.84782609, 0.82608696, 0.84782609,\n",
       "        0.84782609]),\n",
       " 'split4_test_score': array([       nan,        nan, 0.97826087,        nan, 0.95652174,\n",
       "        0.95652174, 0.95652174, 0.97826087,        nan,        nan,\n",
       "        0.95652174,        nan, 0.97826087, 0.95652174, 0.95652174,\n",
       "        0.97826087,        nan,        nan, 0.95652174,        nan,\n",
       "        0.97826087, 0.95652174, 0.95652174, 0.97826087,        nan,\n",
       "               nan, 1.        ,        nan, 1.        , 0.97826087,\n",
       "        1.        , 0.97826087,        nan,        nan, 1.        ,\n",
       "               nan, 1.        , 0.97826087, 1.        , 0.97826087,\n",
       "               nan,        nan, 1.        ,        nan, 1.        ,\n",
       "        0.97826087, 1.        , 0.97826087,        nan,        nan,\n",
       "        1.        ,        nan, 1.        , 0.97826087, 1.        ,\n",
       "        0.97826087,        nan,        nan, 1.        ,        nan,\n",
       "        1.        , 0.97826087, 1.        , 0.97826087, 0.91304348,\n",
       "        0.91304348, 0.91304348, 0.91304348, 0.91304348, 0.91304348,\n",
       "        0.91304348, 0.93478261, 0.91304348, 0.97826087, 0.95652174,\n",
       "        0.95652174, 0.97826087, 0.95652174, 0.97826087, 0.95652174,\n",
       "        0.97826087, 0.97826087, 0.95652174, 0.95652174, 0.95652174,\n",
       "        0.89130435, 0.95652174, 0.91304348, 0.93478261, 0.95652174,\n",
       "        0.95652174]),\n",
       " 'split5_test_score': array([       nan,        nan, 0.95555556,        nan, 0.95555556,\n",
       "        0.97777778, 0.97777778, 0.95555556,        nan,        nan,\n",
       "        0.97777778,        nan, 0.97777778, 0.95555556, 0.97777778,\n",
       "        0.95555556,        nan,        nan, 0.95555556,        nan,\n",
       "        0.97777778, 0.95555556, 0.95555556, 0.95555556,        nan,\n",
       "               nan, 0.95555556,        nan, 0.95555556, 0.95555556,\n",
       "        0.95555556, 0.95555556,        nan,        nan, 0.95555556,\n",
       "               nan, 0.95555556, 0.95555556, 0.95555556, 0.95555556,\n",
       "               nan,        nan, 0.95555556,        nan, 0.97777778,\n",
       "        0.97777778, 0.95555556, 0.95555556,        nan,        nan,\n",
       "        0.97777778,        nan, 0.95555556, 0.97777778, 0.95555556,\n",
       "        0.95555556,        nan,        nan, 1.        ,        nan,\n",
       "        1.        , 0.93333333, 0.97777778, 0.95555556, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.91111111, 0.91111111, 0.91111111,\n",
       "        0.95555556, 0.95555556, 0.95555556, 0.97777778, 0.97777778,\n",
       "        0.97777778, 0.97777778, 0.97777778, 0.97777778, 0.97777778,\n",
       "        0.97777778, 0.97777778, 0.97777778, 0.97777778, 0.97777778,\n",
       "        0.97777778, 0.95555556, 0.97777778, 0.97777778, 0.97777778,\n",
       "        0.97777778]),\n",
       " 'split6_test_score': array([       nan,        nan, 0.84444444,        nan, 0.93333333,\n",
       "        0.82222222, 0.84444444, 0.8       ,        nan,        nan,\n",
       "        0.82222222,        nan, 0.95555556, 0.88888889, 0.88888889,\n",
       "        0.8       ,        nan,        nan, 0.88888889,        nan,\n",
       "        0.97777778, 0.88888889, 0.88888889, 0.8       ,        nan,\n",
       "               nan, 0.97777778,        nan, 0.97777778, 0.97777778,\n",
       "        0.97777778, 0.8       ,        nan,        nan, 1.        ,\n",
       "               nan, 0.97777778, 1.        , 1.        , 0.8       ,\n",
       "               nan,        nan, 1.        ,        nan, 1.        ,\n",
       "        0.95555556, 1.        , 0.8       ,        nan,        nan,\n",
       "        1.        ,        nan, 1.        , 1.        , 1.        ,\n",
       "        0.8       ,        nan,        nan, 0.97777778,        nan,\n",
       "        1.        , 0.95555556, 1.        , 0.8       , 0.88888889,\n",
       "        0.88888889, 0.88888889, 0.91111111, 0.91111111, 0.91111111,\n",
       "        0.97777778, 0.97777778, 0.97777778, 0.91111111, 0.88888889,\n",
       "        0.95555556, 0.93333333, 0.95555556, 0.95555556, 0.95555556,\n",
       "        0.91111111, 0.93333333, 0.91111111, 0.88888889, 0.95555556,\n",
       "        0.91111111, 0.93333333, 0.91111111, 0.91111111, 0.88888889,\n",
       "        0.91111111]),\n",
       " 'split7_test_score': array([       nan,        nan, 0.88888889,        nan, 0.91111111,\n",
       "        0.91111111, 0.91111111, 0.91111111,        nan,        nan,\n",
       "        0.88888889,        nan, 0.93333333, 0.88888889, 0.88888889,\n",
       "        0.91111111,        nan,        nan, 0.88888889,        nan,\n",
       "        0.95555556, 0.91111111, 0.91111111, 0.91111111,        nan,\n",
       "               nan, 0.95555556,        nan, 0.95555556, 0.93333333,\n",
       "        0.95555556, 0.91111111,        nan,        nan, 0.95555556,\n",
       "               nan, 0.95555556, 0.93333333, 0.95555556, 0.91111111,\n",
       "               nan,        nan, 0.95555556,        nan, 0.95555556,\n",
       "        0.95555556, 0.95555556, 0.91111111,        nan,        nan,\n",
       "        0.95555556,        nan, 0.95555556, 0.95555556, 0.95555556,\n",
       "        0.91111111,        nan,        nan, 0.95555556,        nan,\n",
       "        0.95555556, 0.93333333, 0.95555556, 0.91111111, 0.84444444,\n",
       "        0.84444444, 0.84444444, 0.95555556, 0.95555556, 0.95555556,\n",
       "        0.95555556, 0.95555556, 0.95555556, 0.95555556, 0.95555556,\n",
       "        0.95555556, 0.95555556, 0.95555556, 0.95555556, 0.95555556,\n",
       "        0.95555556, 0.95555556, 0.95555556, 0.95555556, 0.95555556,\n",
       "        0.95555556, 0.95555556, 0.95555556, 0.95555556, 0.95555556,\n",
       "        0.95555556]),\n",
       " 'split8_test_score': array([       nan,        nan, 0.93333333,        nan, 0.93333333,\n",
       "        0.93333333, 0.95555556, 0.93333333,        nan,        nan,\n",
       "        0.95555556,        nan, 0.93333333, 0.91111111, 0.91111111,\n",
       "        0.93333333,        nan,        nan, 0.91111111,        nan,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333,        nan,\n",
       "               nan, 0.93333333,        nan, 0.95555556, 0.95555556,\n",
       "        0.95555556, 0.93333333,        nan,        nan, 0.95555556,\n",
       "               nan, 0.95555556, 0.93333333, 0.95555556, 0.93333333,\n",
       "               nan,        nan, 0.95555556,        nan, 0.95555556,\n",
       "        0.93333333, 0.97777778, 0.93333333,        nan,        nan,\n",
       "        0.97777778,        nan, 0.97777778, 0.95555556, 0.97777778,\n",
       "        0.93333333,        nan,        nan, 0.95555556,        nan,\n",
       "        0.97777778, 0.93333333, 0.97777778, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.97777778, 0.97777778, 0.95555556, 0.97777778, 0.97777778,\n",
       "        0.95555556, 0.97777778, 0.97777778, 0.95555556, 0.97777778,\n",
       "        0.97777778, 0.95555556, 0.97777778, 0.97777778, 0.95555556,\n",
       "        0.97777778, 0.97777778, 0.95555556, 0.97777778, 0.97777778,\n",
       "        0.95555556]),\n",
       " 'split9_test_score': array([       nan,        nan, 0.86666667,        nan, 0.88888889,\n",
       "        0.88888889, 0.86666667, 0.84444444,        nan,        nan,\n",
       "        0.86666667,        nan, 0.88888889, 0.88888889, 0.88888889,\n",
       "        0.84444444,        nan,        nan, 0.88888889,        nan,\n",
       "        0.88888889, 0.88888889, 0.88888889, 0.84444444,        nan,\n",
       "               nan, 0.88888889,        nan, 0.86666667, 0.86666667,\n",
       "        0.88888889, 0.84444444,        nan,        nan, 0.88888889,\n",
       "               nan, 0.86666667, 0.88888889, 0.88888889, 0.84444444,\n",
       "               nan,        nan, 0.86666667,        nan, 0.86666667,\n",
       "        0.88888889, 0.88888889, 0.84444444,        nan,        nan,\n",
       "        0.88888889,        nan, 0.86666667, 0.88888889, 0.86666667,\n",
       "        0.84444444,        nan,        nan, 0.93333333,        nan,\n",
       "        0.91111111, 0.88888889, 0.86666667, 0.84444444, 0.84444444,\n",
       "        0.84444444, 0.84444444, 0.88888889, 0.88888889, 0.88888889,\n",
       "        0.88888889, 0.88888889, 0.88888889, 0.91111111, 0.84444444,\n",
       "        0.88888889, 0.88888889, 0.86666667, 0.88888889, 0.86666667,\n",
       "        0.84444444, 0.88888889, 0.88888889, 0.86666667, 0.88888889,\n",
       "        0.86666667, 0.84444444, 0.88888889, 0.86666667, 0.84444444,\n",
       "        0.88888889]),\n",
       " 'mean_test_score': array([       nan,        nan, 0.91845411,        nan, 0.93178744,\n",
       "        0.92289855, 0.92077295, 0.90748792,        nan,        nan,\n",
       "        0.91198068,        nan, 0.94062802, 0.92507246, 0.92729469,\n",
       "        0.90748792,        nan,        nan, 0.92289855,        nan,\n",
       "        0.94724638, 0.927343  , 0.93386473, 0.90748792,        nan,\n",
       "               nan, 0.94937198,        nan, 0.94719807, 0.94497585,\n",
       "        0.9515942 , 0.90748792,        nan,        nan, 0.95381643,\n",
       "               nan, 0.95154589, 0.94719807, 0.95381643, 0.90748792,\n",
       "               nan,        nan, 0.95376812,        nan, 0.96033816,\n",
       "        0.94937198, 0.95821256, 0.90748792,        nan,        nan,\n",
       "        0.9626087 ,        nan, 0.95816425, 0.95169082, 0.95599034,\n",
       "        0.90748792,        nan,        nan, 0.96700483,        nan,\n",
       "        0.96705314, 0.9405314 , 0.96038647, 0.90748792, 0.88357488,\n",
       "        0.88357488, 0.88357488, 0.91652174, 0.91652174, 0.91652174,\n",
       "        0.93859903, 0.94077295, 0.93637681, 0.94072464, 0.92966184,\n",
       "        0.93855072, 0.93855072, 0.93855072, 0.93855072, 0.93855072,\n",
       "        0.93188406, 0.94067633, 0.93415459, 0.92536232, 0.93637681,\n",
       "        0.92541063, 0.92536232, 0.92758454, 0.92541063, 0.93183575,\n",
       "        0.93193237]),\n",
       " 'std_test_score': array([       nan,        nan, 0.04653345,        nan, 0.04202721,\n",
       "        0.05848572, 0.0583094 , 0.05670858,        nan,        nan,\n",
       "        0.0574781 ,        nan, 0.02962219, 0.04835382, 0.05017984,\n",
       "        0.05670858,        nan,        nan, 0.03977767,        nan,\n",
       "        0.03143573, 0.03138699, 0.03701974, 0.05670858,        nan,\n",
       "               nan, 0.03551878,        nan, 0.03715227, 0.03725039,\n",
       "        0.03513894, 0.05670858,        nan,        nan, 0.03606998,\n",
       "               nan, 0.03540377, 0.03579841, 0.03606998, 0.05670858,\n",
       "               nan,        nan, 0.03760928,        nan, 0.03685167,\n",
       "        0.02808904, 0.03338108, 0.05670858,        nan,        nan,\n",
       "        0.03135947,        nan, 0.03888046, 0.03377983, 0.03829943,\n",
       "        0.05670858,        nan,        nan, 0.02256308,        nan,\n",
       "        0.02832319, 0.031265  , 0.03681717, 0.05670858, 0.04038832,\n",
       "        0.04038832, 0.04038832, 0.03484348, 0.03484348, 0.03484348,\n",
       "        0.04336833, 0.04257034, 0.04184649, 0.04145313, 0.05000324,\n",
       "        0.03997117, 0.04231994, 0.0446403 , 0.04113651, 0.05152069,\n",
       "        0.05585427, 0.04372971, 0.0487899 , 0.05011003, 0.03952332,\n",
       "        0.0450169 , 0.05104443, 0.03906026, 0.04605474, 0.05157169,\n",
       "        0.04304586]),\n",
       " 'rank_test_score': array([91, 70, 52, 68, 39, 49, 51, 57, 69, 71, 56, 81, 24, 48, 43, 57, 89,\n",
       "        87, 49, 84, 17, 42, 35, 57, 80, 79, 15, 77, 18, 20, 13, 57, 74, 72,\n",
       "         9, 73, 14, 18,  9, 57, 75, 76, 11, 78,  5, 15,  6, 57, 82, 90,  3,\n",
       "        83,  7, 12,  8, 57, 85, 86,  2, 88,  1, 25,  4, 57, 65, 65, 65, 53,\n",
       "        53, 53, 26, 21, 32, 22, 40, 27, 30, 27, 30, 27, 37, 23, 34, 46, 32,\n",
       "        44, 46, 41, 45, 38, 36])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9846153846153847\n",
      "Test: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {grid2.best_estimator_.score(X_train, y_train)}\")\n",
    "print(f\"Test: {grid2.best_estimator_.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Utiliza lo que hemos denominado como \"Next level\" (nombre inventado para hacer referencia a ese estilo de búsqueda de hiperparámetros) para encontrar el mejor de cada uno de los algoritmos de clasificación que hemos visto hasta la fecha, con su mejor combinación, incluyendo etapas extra en el preprocesamiento de datos como un escalado (es decir, las etapas del pipeline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "pipe_dt = Pipeline(steps=[(\"scaler\", StandardScaler()),\n",
    "                       (\"selector\", SelectKBest()),\n",
    "                       (\"modelo\", DecisionTreeClassifier())])\n",
    "\n",
    "pipe_lr = Pipeline(steps=[(\"scaler\", MinMaxScaler()),\n",
    "                       (\"selector\", SelectFromModel(estimator=dt)),\n",
    "                       (\"modelo\", LogisticRegression())])\n",
    "\n",
    "pipe_dt_params = {\n",
    "    'selector__k': np.arange(1, len(X.columns)),\n",
    "    'modelo': [DecisionTreeClassifier()],\n",
    "    'modelo__max_depth': np.arange(1, 10),\n",
    "    'modelo__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "pipe_lg_params = {\n",
    "    'modelo': [LogisticRegression()],\n",
    "    'modelo__penalty': ['l1', 'l2'],\n",
    "    'modelo__C': [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 100],\n",
    "    'modelo__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag']\n",
    "}\n",
    "\n",
    "\n",
    "# Nos creamos iterador basado en cross validation:\n",
    "grid_dt = GridSearchCV(\n",
    "    estimator = pipe_dt,\n",
    "    param_grid = pipe_dt_params,\n",
    "    n_jobs = -1,\n",
    "    scoring = 'accuracy',\n",
    "    cv = 10)\n",
    "\n",
    "grid_lr = GridSearchCV(\n",
    "    estimator = pipe_lr,\n",
    "    param_grid = pipe_lg_params,\n",
    "    n_jobs = -1,\n",
    "    scoring = 'accuracy',\n",
    "    cv = 10)\n",
    "\n",
    "grids3 = {\n",
    "    'gs_dt': grid_dt,\n",
    "    'gs_lr': grid_lr\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando gs_dt\n",
      "Calculando gs_lr\n"
     ]
    }
   ],
   "source": [
    "for nombre, grid_search in grids3.items():\n",
    "    print(f\"Calculando {nombre}\")\n",
    "    grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT: 0.9298245614035088\n",
      "LR: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "print(f\"DT: {grids3['gs_dt'].best_estimator_.score(X_test, y_test)}\")\n",
    "print(f\"LR: {grids3['gs_lr'].best_estimator_.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejores opciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Comenzamos definiendo los pipelines principales:\n",
    "reg_log = Pipeline(steps = [\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"selecModel\",SelectFromModel(DecisionTreeClassifier(max_depth=10, random_state=17))),\n",
    "    (\"reglog\", LogisticRegression())\n",
    "])\n",
    "svc = Pipeline(steps =[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"selectkbest\", SelectKBest()),\n",
    "    (\"svc\", svm.SVC())\n",
    "])\n",
    "decision_tree = Pipeline(steps =[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"selectkbest\", SelectKBest()),\n",
    "    ('decision_tree', DecisionTreeClassifier()),\n",
    "     ])\n",
    "K_nearest = Pipeline(steps =[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"selectkbest\", SelectKBest()),\n",
    "    ('KNeighbor',KNeighborsClassifier())\n",
    "    ])\n",
    "# Y definimos sus parámetros:\n",
    "re_log_param = {\n",
    "    \"reglog__penalty\": [\"l1\", \"l2\"],\n",
    "    \"reglog__C\": np.arange(0, 4, 0.5)\n",
    "}\n",
    "svc_param = {\n",
    "    \"selectkbest__k\": list(range(8,25)),\n",
    "    \"svc__C\": np.arange(0.1, 0.9, 0.1),\n",
    "    \"svc__kernel\": ['linear', 'poly', 'rbf']\n",
    "}\n",
    "decision_tree_params = {\n",
    "    \"selectkbest__k\": list(range(2,10)),\n",
    "    'decision_tree__max_depth': [10, 100, 500, 1000],\n",
    "    'decision_tree__criterion': ['gini', 'entropy']\n",
    "}\n",
    "knn_params = {\n",
    "    \"selectkbest__k\": [2, 3, 4],\n",
    "    'KNeighbor__n_neighbors': list(range(4,10)),\n",
    "}\n",
    "# Nos creamos los grids de cada uno:\n",
    "gs_reg_log = GridSearchCV(reg_log,\n",
    "                         re_log_param,\n",
    "                         cv = 10,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=-1,\n",
    "                         verbose=1)\n",
    "gs_svm = GridSearchCV(svc,\n",
    "                         svc_param,\n",
    "                         cv = 10,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=-1,\n",
    "                         verbose=1)\n",
    "gs_decision_tree = GridSearchCV(decision_tree,\n",
    "                         decision_tree_params,\n",
    "                         cv = 10,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=-1,\n",
    "                         verbose=1)\n",
    "gs_K_nearest = GridSearchCV(K_nearest,\n",
    "                         knn_params,\n",
    "                         cv = 10,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=-1,\n",
    "                         verbose=1)\n",
    "grids = {\n",
    "    \"gs_reg_log\": gs_reg_log,\n",
    "    \"gs_svm\": gs_svm,\n",
    "    \"gs_rand_forest\": gs_decision_tree,\n",
    "    'gs_K_nearest': gs_K_nearest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 408 candidates, totalling 4080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1200 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3200 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4080 out of 4080 | elapsed:   15.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 640 out of 640 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos:\n",
    "for nombre, grid_search in grids.items():\n",
    "    grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grid</th>\n",
       "      <th>Best score</th>\n",
       "      <th>Test Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs_svm</td>\n",
       "      <td>0.978019</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs_reg_log</td>\n",
       "      <td>0.953865</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gs_K_nearest</td>\n",
       "      <td>0.947198</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs_rand_forest</td>\n",
       "      <td>0.938454</td>\n",
       "      <td>0.956140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Grid  Best score  Test Score\n",
       "1          gs_svm    0.978019    0.973684\n",
       "0      gs_reg_log    0.953865    0.982456\n",
       "3    gs_K_nearest    0.947198    0.921053\n",
       "2  gs_rand_forest    0.938454    0.956140"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grids = [(i, j.best_score_) for i, j in grids.items()]\n",
    "best_grids\n",
    "test_score =[]\n",
    "for i, j in grids.items():\n",
    "    test_score.append(j.score(X_test, y_test))\n",
    "    best_grids = pd.DataFrame(best_grids, columns = ['Grid', 'Best score'])\n",
    "results = best_grids.sort_values(by='Best score', ascending=False)\n",
    "results['Test Score']= test_score\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo en el que ejecutamos todas las cominaciones como una sola, sobre un pipline común, sin diferenciar si es LogisticRegression o DecisionTreeClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('selector', SelectKBest()),\n",
       "                                       ('modelo',\n",
       "                                        DecisionTreeClassifier(max_depth=5))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'modelo': [LogisticRegression(C=0.1,\n",
       "                                                        solver='newton-cg')],\n",
       "                          'modelo__C': [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 100],\n",
       "                          'modelo__penalty': ['l1', 'l2'],\n",
       "                          'modelo__solver': ['newton-cg', 'lbfgs', 'liblinear',\n",
       "                                             'sag'],\n",
       "                          'selector__k': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])},\n",
       "                         {'modelo': [DecisionTreeClassifier()],\n",
       "                          'modelo__max_depth': array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                          'modelo__min_samples_split': [2, 5, 10],\n",
       "                          'selector__k': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "pipe_dt = Pipeline(steps=[(\"scaler\", StandardScaler()),\n",
    "                       (\"selector\", SelectKBest()),\n",
    "                       (\"modelo\", dt)])\n",
    "\n",
    "pipe_dt_params = {\n",
    "    'selector__k': np.arange(1, len(X.columns)),\n",
    "    'modelo': [DecisionTreeClassifier()],\n",
    "    'modelo__max_depth': np.arange(1, 10),\n",
    "    'modelo__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "pipe_lg_params = {\n",
    "    'selector__k': np.arange(1, len(X.columns)),\n",
    "    'modelo': [LogisticRegression()],\n",
    "    'modelo__penalty': ['l1', 'l2'],\n",
    "    'modelo__C': [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 100],\n",
    "    'modelo__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag']\n",
    "}\n",
    "\n",
    "\n",
    "search_space = [pipe_lg_params, pipe_dt_params]\n",
    "\n",
    "# Nos creamos iterador basado en cross validation:\n",
    "grid3 = GridSearchCV(\n",
    "    estimator = pipe_dt,\n",
    "    param_grid = search_space,\n",
    "    n_jobs = -1,\n",
    "    scoring = 'accuracy',\n",
    "    cv = 10)\n",
    "\n",
    "grid3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('selector', SelectKBest(k=28)),\n",
       "                ('modelo', LogisticRegression(C=0.1, solver='newton-cg'))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9824561403508771"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid3.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3.breast_cancer_sol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
