{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2O0nELPy1Gy"
   },
   "source": [
    "# Feature Engineering: Variables de texto\n",
    "-----\n",
    "\n",
    "## Introducción\n",
    "\n",
    "Hasta ahora, hemos visto variables numéricas, numéricas categóricas, temporales... Incluso hemos visto variables de texto con muy pocas palabras y que hacían referencia a una categoría, por lo que las hemos tratado como categóricas. Sin embargo, las variables de texto no siempre siguen esta estructura, algunas veces pueden ser mucho más ricas, pudiendo llegar a contener significado propio más allá de una categoría. Podemos llegar a tener párrafos completos de texto que nos transmitan múltiples ideas.\n",
    "\n",
    "Por ejemplo, podemos llegar a tener cosas como esta:\n",
    "\n",
    "    Emma knocked on the door. No answer. She knocked again and waited. There was a large maple tree next to the house. Emma looked up the tree and saw a giant raven perched at the treetop. Under the afternoon sun, the raven gleamed magnificently. Its beak was hard and pointed, its claws sharp and strong. It looked regal and imposing. It reigned the tree it stood on. The raven was looking straight at Emma with its beady black eyes. Emma felt slightly intimidated. She took a step back from the door and tentatively said, “Hello?”\n",
    "    \n",
    "El párrafo contiene mucha información. Sabemos que se trata de una persona llamada Emma y un cuervo. Hay una casa y un árbol, y Emma está tratando de entrar en la casa, pero en su lugar ve al cuervo. El cuervo es magnífico y se ha dado cuenta de la presencia de Emma, que está un poco asustada pero está intentando comunicarse.\n",
    "\n",
    "Entonces, ¿qué partes de este bloque de información son las características destacadas que debemos extraer? Para empezar, parece una buena idea extraer los nombres de los personajes principales, Emma y el cuervo. A continuación, también puede ser bueno anotar que el escenario donde se produce el encuentro es en el recibidor de una casa, siendo los elementos más relevantes una puerta y un árbol. ¿Y qué hay de las descripciones del cuervo? ¿Qué hay de las acciones de Emma (llamar a la puerta, dar un paso atrás y saludar)?\n",
    "\n",
    "Este capítulo presenta los conceptos básicos del Feature Engineering para texto. Comenzaremos con el _bag of words_, que es la representación más simple basada en estadísticas de conteo de palabras. Una transformación relacionada muy utilizada es la conocida como _TF-IDF_, que es esencialmente una técnica de escalado de características. Después profundizaremos sobre otras técnicas como _stemming_ o \"tokenización\", para terminar profundizando sobre cómo filtrar y limpiar las diferentes características que hemos extraído.\n",
    "\n",
    "Además, introduciremos las librerías ``spacy`` y ``TextBlob``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2TIF9lMy1Gz"
   },
   "source": [
    "## Bag-of-X: Convirtiendo texto natural en vectores (flat vectors)\n",
    "\n",
    "Ya sea que construyamos modelos de machine learning o solamente realicemos feature engineering, es bueno que el resultado sea simple e interpretable. Las cosas simples son fáciles de probar y las características y modelos interpretables son más fáciles de depurar que los complejos. Las características simples e interpretables no siempre conducen al modelo más preciso, pero es una buena idea comenzar, entender qué está pasando, y ya agregaremos complejidad cuando sea estrictamente necesario.\n",
    "\n",
    "Para los datos de texto, podemos comenzar con una lista de estadísticas de recuento de palabras llamada _bag of words_ (bolsa de palabras). Una lista de recuentos de palabras es algo muy básico y no sigue ningún mecanismo especial para encontrar las entidades interesantes, como Emma o el cuervo. Pero esas dos palabras se mencionan repetidamente en nuestro párrafo de muestra, por lo que tienen un recuento más alto que cualquier palabra aleatoria, como puede ser \"hello\". Para tareas sencillas como clasificar un documento, las estadísticas de recuento de palabras suelen ser suficientes. Esta técnica también se puede utilizar en la recuperación de información, donde el objetivo es recuperar el conjunto de documentos que son relevantes para una consulta de texto concreto (generalmente, esta consulta será una palabra, y se obtendrán los documentos relacionados con ella). Ambas tareas trabajan bien con funciones a nivel de palabra porque la presencia o ausencia de ciertas palabras es un gran indicador del contenido del tema del documento.\n",
    "\n",
    "### Bag-of-Words\n",
    "\n",
    "En la técnica bag-of-words (BoW), un documento de texto se convierte en un vector de recuentos (recuerda que un vector es solo una colección de n números, pues en este caso cada uno de los números harán representación del número de apariciones de cada palabra). El vector contiene una entrada para cada palabra posible en el vocabulario. Si la palabra, digamos, \"amapola\", aparece tres veces en el documento, entonces el vector de características tiene una cuenta de 3 en la posición correspondiente a esa palabra. Si una palabra del vocabulario no aparece en el documento, entonces cuenta con 0. Por ejemplo, en el texto “it is a puppy and it is extremely cute”, la representación del vector tras aplicar el BoW sería la siguiente:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZG2s2_51y1G0"
   },
   "source": [
    "<img src=\"../../../imagenes/imagen1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gplms5HDy1G0"
   },
   "source": [
    "Bag-of-words convierte un documento de texto (que introduciremos como una variable string, por ejemplo) en un vector, que en inglés recibe el nombre de \"flat vector\", donde el \"flat\" hace referencia a que no contiene ninguna de las estructuras textuales originales. El texto original es una secuencia de palabras, con sus espacios, signos de puntuación, etc. Pero nuestro _bag-of-words_ no tiene secuencia; simplemente recuerda cuántas veces aparece cada palabra en el texto.\n",
    "\n",
    "Por lo tanto, como demuestra la figura que veremos a continuación, el orden de las palabras en el vector no es importante, siempre que sea coherente para todos los documentos del conjunto de datos. La _bag-of-words_ tampoco representa ningún concepto de jerarquía de palabras. Por ejemplo, el concepto de \"animal\" incluye \"perro\", \"gato\", \"cuervo\", etc. Pero en una representación _bag-of-words_, estas palabras son todos elementos al mismo nivel en vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "568KZ9p6y1G1"
   },
   "source": [
    "<img src=\"../../../imagenes/imagen2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2F-3oF-ty1G2"
   },
   "source": [
    "Lo importante aquí es la geometría de los datos en el espacio generado por las diferentes palabras que hemos identificado. En un vector de _bag-of-words_, cada palabra se convierte en una dimensión del vector. Si hay n palabras en el vocabulario, entonces un documento se convierte en un punto dentro de este espacio n-dimensional. Es difícil visualizar la geometría de algo más allá de dos o tres dimensiones, así que tendremos que usar nuestra imaginación.\n",
    "\n",
    "La siguiente figura muestra cómo se ve la frase que estamos utilizando de ejemplo en el espacio de características bidimensional correspondiente a las palabras \"puppy\" y \"cute\".\n",
    "\n",
    "<img src=\"../../../imagenes/imagen3.png\">\n",
    "\n",
    "Si ampliamos la representación del espacio para incluir, además, la palabra \"extremely\", quedaría una representación en 3D como se muestra a continuación:\n",
    "\n",
    "<img src=\"../../../imagenes/imagen4.png\">\n",
    "\n",
    "Pero recuerda que el espacio real sería con tantas dimensiones como palabras haya en nuestro vocabulario (que dependerá de cuántas haya en nuestro/s texto/s bajo estudio).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cYHN-3OTy1G2"
   },
   "source": [
    "Ambas figuras representan vectores de datos en el espacio de palabras. Los ejes denotan palabras individuales, que son características en la representación de la _bag-of-words_, y los puntos en el espacio denotan puntos de datos (documentos de texto, es decir, las frases).\n",
    "\n",
    "A veces también es útil observar los vectores de características en el espacio de datos, que es un concepto complementario a lo que hemos acabamos de ver. Un vector de características contiene el valor de la característica en cada punto de datos. Los ejes denotan puntos de datos individuales y los puntos del espacio denotan vectores de características.\n",
    "\n",
    "La siguiente figura muestra un ejemplo que nos ayudará a entender de lo que estamos hablando. En él, representamos una frase frente a otra, que serán los ejes de la gráfica. Cada punto que aparece en esta gráfica se corresponde con una palabra, y sus valores serán, para cada eje, el número de veces que aparece esa palabra en la frase de cada eje. Por ejemplo, la palabra \"I\" aparece 1 vez en la frase \"I have a cat\" (que está en el eje X) y 2 veces en la frase \"I have a puppy and I am happy\" (que está en el eje Y), por lo que sus coordenadas en esta gráfica serán las correspondientes al punto (1, 2).\n",
    "\n",
    "<img src=\"../../../imagenes/imagen5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag-ofwords no es una técnica perfecta. Dividir una oración en palabras simples puede destruir el significado semántico. Por ejemplo, \"no está mal\" semánticamente significa \"decente\" o incluso \"bueno\". Pero \"no\" y \"malo\" representan un sentimiento negativo. \"Perro de juguete\" y \"juguete de perro\" pueden ser cosas muy diferentes (a menos que el perro de juguete sea un juguete para el perro), y el significado se pierde con las palabras simples \"juguete\" y \"perro\". Es fácil encontrar muchos ejemplos de este tipo. Bag-of-n-Grams, que discutiremos a continuación, es una variación de esta técnica que soluciona parte del problema, pero tampoco será algo perfecto. Es bueno tener en cuenta que _bag-of-words_ es una técnica simple y útil, pero está lejos de ser una comprensión semántica perfecta del texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO\n",
    "\n",
    "¿Te has enterado de cómo funciona la técnica _bag of words_? Prueba a implementarla tú mismo. Para ello, haz una función que reciba un texto completo y analice las diferentes palabras que tiene y haga un conteo de cada una de ellas. Tendrá que almacenarlo en un diccionario, donde las claves serán las palabras y los valores serán los conteos de cada una de las palabras:\n",
    "\n",
    "_TIP: puedes utilizar una función de los strings que servía para separar en función de algún caracter y otra para eliminar elementos que no aportan información, como ``.`` o ``,``._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAAAAAAAAAAAA'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'AaAaAAaaaaAAa'.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texto' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f7203916c33b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnonalpha_chars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mchar\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexto\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misalnum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnonalpha_chars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnonalpha_chars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnonalpha_chars\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnonalpha_chars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'texto' is not defined"
     ]
    }
   ],
   "source": [
    "nonalpha_chars = [char for char in texto if not char.isalnum() and char != ' ']\n",
    "nonalpha_chars = set(nonalpha_chars)\n",
    "nonalpha_chars\n",
    "\n",
    "for char in nonalpha_chars:\n",
    "    texto = texto.replace(char, \"\")\n",
    "    \n",
    "texto\n",
    "\n",
    "# words = texto.split(\" \")\n",
    "# words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Emma': 4,\n",
       " 'knocked': 2,\n",
       " 'on': 2,\n",
       " 'the': 8,\n",
       " 'door': 2,\n",
       " 'No': 1,\n",
       " 'answer': 1,\n",
       " 'She': 2,\n",
       " 'again': 1,\n",
       " 'and': 6,\n",
       " 'waited': 1,\n",
       " 'There': 1,\n",
       " 'was': 3,\n",
       " 'a': 3,\n",
       " 'large': 1,\n",
       " 'maple': 1,\n",
       " 'tree': 3,\n",
       " 'next': 1,\n",
       " 'to': 1,\n",
       " 'house': 1,\n",
       " 'looked': 2,\n",
       " 'up': 1,\n",
       " 'saw': 1,\n",
       " 'giant': 1,\n",
       " 'raven': 3,\n",
       " 'perched': 1,\n",
       " 'at': 2,\n",
       " 'treetop': 1,\n",
       " 'Under': 1,\n",
       " 'afternoon': 1,\n",
       " 'sun': 1,\n",
       " 'gleamed': 1,\n",
       " 'magnificently': 1,\n",
       " 'Its': 1,\n",
       " 'beak': 1,\n",
       " 'hard': 1,\n",
       " 'pointed': 1,\n",
       " 'its': 2,\n",
       " 'claws': 1,\n",
       " 'sharp': 1,\n",
       " 'strong': 1,\n",
       " 'It': 2,\n",
       " 'regal': 1,\n",
       " 'imposing': 1,\n",
       " 'reigned': 1,\n",
       " 'it': 1,\n",
       " 'stood': 1,\n",
       " 'The': 1,\n",
       " 'looking': 1,\n",
       " 'straight': 1,\n",
       " 'with': 1,\n",
       " 'beady': 1,\n",
       " 'black': 1,\n",
       " 'eyes': 1,\n",
       " 'felt': 1,\n",
       " 'slightly': 1,\n",
       " 'intimidated': 1,\n",
       " 'took': 1,\n",
       " 'step': 1,\n",
       " 'back': 1,\n",
       " 'from': 1,\n",
       " 'tentatively': 1,\n",
       " 'said': 1,\n",
       " 'Hello': 1}"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = \"\"\"Emma knocked on the door. No answer. She knocked again and waited. There was a large maple tree next to the house. Emma looked up the tree and saw a giant raven perched at the treetop. Under the afternoon sun, the raven gleamed magnificently. Its beak was hard and pointed, its claws sharp and strong. It looked regal and imposing. It reigned the tree it stood on. The raven was looking straight at Emma with its beady black eyes. Emma felt slightly intimidated. She took a step back from the door and tentatively said, “Hello?”\"\"\"\n",
    "\n",
    "def bagofwords(texto):\n",
    "    nonalpha_chars = [char for char in texto if not char.isalnum() and char != ' ']\n",
    "    nonalpha_chars = set(nonalpha_chars)\n",
    "    nonalpha_chars\n",
    "\n",
    "    for char in nonalpha_chars:\n",
    "        texto = texto.replace(char, \"\")\n",
    "        \n",
    "    keys = texto.split()\n",
    "    values = [keys.count(i) for i in keys]\n",
    "    diccionario= dict(zip(keys, values))\n",
    "    return diccionario\n",
    "\n",
    "bagofwords(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analiza_texto(texto):\n",
    "    palabras = {}\n",
    "    l = [letter for letter in texto if letter.isalnum() or letter == ' ']\n",
    "    l = ''.join(l).lower()\n",
    "    texto = l.split(' ')\n",
    "    \n",
    "    for word in texto:\n",
    "        palabras[word] = texto.count(word)\n",
    "    return palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Emma',\n",
       " 'knocked',\n",
       " 'on',\n",
       " 'the',\n",
       " 'door',\n",
       " 'No',\n",
       " 'answer',\n",
       " 'She',\n",
       " 'knocked',\n",
       " 'again',\n",
       " 'and',\n",
       " 'waited',\n",
       " 'There',\n",
       " 'was',\n",
       " 'a',\n",
       " 'large',\n",
       " 'maple',\n",
       " 'tree',\n",
       " 'next',\n",
       " 'to',\n",
       " 'the',\n",
       " 'house',\n",
       " 'Emma',\n",
       " 'looked',\n",
       " 'up',\n",
       " 'the',\n",
       " 'tree',\n",
       " 'and',\n",
       " 'saw',\n",
       " 'a',\n",
       " 'giant',\n",
       " 'raven',\n",
       " 'perched',\n",
       " 'at',\n",
       " 'the',\n",
       " 'treetop',\n",
       " 'Under',\n",
       " 'the',\n",
       " 'afternoon',\n",
       " 'sun',\n",
       " 'the',\n",
       " 'raven',\n",
       " 'gleamed',\n",
       " 'magnificently',\n",
       " 'Its',\n",
       " 'beak',\n",
       " 'was',\n",
       " 'hard',\n",
       " 'and',\n",
       " 'pointed',\n",
       " 'its',\n",
       " 'claws',\n",
       " 'sharp',\n",
       " 'and',\n",
       " 'strong',\n",
       " 'It',\n",
       " 'looked',\n",
       " 'regal',\n",
       " 'and',\n",
       " 'imposing',\n",
       " 'It',\n",
       " 'reigned',\n",
       " 'the',\n",
       " 'tree',\n",
       " 'it',\n",
       " 'stood',\n",
       " 'on',\n",
       " 'The',\n",
       " 'raven',\n",
       " 'was',\n",
       " 'looking',\n",
       " 'straight',\n",
       " 'at',\n",
       " 'Emma',\n",
       " 'with',\n",
       " 'its',\n",
       " 'beady',\n",
       " 'black',\n",
       " 'eyes',\n",
       " 'Emma',\n",
       " 'felt',\n",
       " 'slightly',\n",
       " 'intimidated',\n",
       " 'She',\n",
       " 'took',\n",
       " 'a',\n",
       " 'step',\n",
       " 'back',\n",
       " 'from',\n",
       " 'the',\n",
       " 'door',\n",
       " 'and',\n",
       " 'tentatively',\n",
       " 'said',\n",
       " '“Hello?”']"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = \"\"\"Emma knocked on the door. No answer. She knocked again and waited. There was a large maple tree next to the house. Emma looked up the tree and saw a giant raven perched at the treetop. Under the afternoon sun, the raven gleamed magnificently. Its beak was hard and pointed, its claws sharp and strong. It looked regal and imposing. It reigned the tree it stood on. The raven was looking straight at Emma with its beady black eyes. Emma felt slightly intimidated. She took a step back from the door and tentatively said, “Hello?”\"\"\"\n",
    "\n",
    "texto.replace(\",\", \"\").replace(\".\", \"\").split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Emma': 4,\n",
       " 'knocked': 2,\n",
       " 'on': 2,\n",
       " 'the': 8,\n",
       " 'door': 2,\n",
       " 'No': 1,\n",
       " 'answer': 1,\n",
       " 'She': 2,\n",
       " 'again': 1,\n",
       " 'and': 6,\n",
       " 'waited': 1,\n",
       " 'There': 1,\n",
       " 'was': 3,\n",
       " 'a': 3,\n",
       " 'large': 1,\n",
       " 'maple': 1,\n",
       " 'tree': 3,\n",
       " 'next': 1,\n",
       " 'to': 1,\n",
       " 'house': 1,\n",
       " 'looked': 2,\n",
       " 'up': 1,\n",
       " 'saw': 1,\n",
       " 'giant': 1,\n",
       " 'raven': 3,\n",
       " 'perched': 1,\n",
       " 'at': 2,\n",
       " 'treetop': 1,\n",
       " 'Under': 1,\n",
       " 'afternoon': 1,\n",
       " 'sun': 1,\n",
       " 'gleamed': 1,\n",
       " 'magnificently': 1,\n",
       " 'Its': 1,\n",
       " 'beak': 1,\n",
       " 'hard': 1,\n",
       " 'pointed': 1,\n",
       " 'its': 2,\n",
       " 'claws': 1,\n",
       " 'sharp': 1,\n",
       " 'strong': 1,\n",
       " 'It': 2,\n",
       " 'regal': 1,\n",
       " 'imposing': 1,\n",
       " 'reigned': 1,\n",
       " 'it': 1,\n",
       " 'stood': 1,\n",
       " 'The': 1,\n",
       " 'looking': 1,\n",
       " 'straight': 1,\n",
       " 'with': 1,\n",
       " 'beady': 1,\n",
       " 'black': 1,\n",
       " 'eyes': 1,\n",
       " 'felt': 1,\n",
       " 'slightly': 1,\n",
       " 'intimidated': 1,\n",
       " 'took': 1,\n",
       " 'step': 1,\n",
       " 'back': 1,\n",
       " 'from': 1,\n",
       " 'tentatively': 1,\n",
       " 'said': 1,\n",
       " 'Hello': 1}"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analiza_texto(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes observar, nos pueden surgir muchas dudas a la hora de realizar nuestro contador. ¿Qué caracteres quitar? ¿Ordenar la salida? ¿Qué hago con las tildes? ¿Y con las mayúsculas?\n",
    "\n",
    "Todas estas cuestiones no siempre tendrán la misma solución, por lo que como ves es un tema más complejo que lo que podría parecer uinicialmente. Para hacer una función que se adapte a todo esto, deberíamos estar trabajando en ello muchas más horas, y aun así nos dejaríamos cosas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WUR9ybpTy1G3"
   },
   "source": [
    "### Bag-of-n-Grams\n",
    "\n",
    "Bag-of-n-Grams, es una extensión natural de bag-of-words. Un n-grama es una secuencia de n tokens, que en este caso se corresponderán con las palabras. Es decir, una palabra es esencialmente un 1-gram, también conocido como unigram. Después de la tokenización, el mecanismo de conteo puede clasificar tokens individuales en conteos de palabras o contar secuencias superpuestas como n-gramas. Por ejemplo, la oración “Emma knocked on the door” genera los n-gramas (con n=2) \"Emma knocked\", \"knocked on\", \"on the\" y \"the door\".\n",
    "\n",
    "Los n-gramas retienen más de la estructura de secuencia original del texto y, por lo tanto, la representación del _bag-of-n-grams_ puede darnos más información. Sin embargo, esto tiene un costo. En teoría, con $k$ palabras únicas, podría haber $k^2$ 2-gram únicos (también llamados bigramas). En la práctica, no hay tantos, porque no todas las palabras pueden seguir a las demás. Sin embargo, normalmente hay muchos más n-gramas distintos (para $n > 1$) que palabras. Esto significa que bag-of-n -grams es un espacio de características mucho más grande y con valores menores. También significa que los n-gramas son más costosos de calcular, almacenar y modelar. Cuanto más grande es n, más rica es la información y mayor es el costo.\n",
    "\n",
    "\n",
    "### Pasando a la acción\n",
    "\n",
    "Para implementar esto en Python, tenemos 2 opciones: crearnos nuestras propias funciones o utilizar algo que alguien ya haya reaizado previamente.\n",
    "\n",
    "Para la primera opción, ya hemos visto cómo podíamos hacer el conteo para 1-grams y extenderlo a n-grams podríamos hacerlo. Sin embargo, si ya existe algo mejor diseñado y con más cosas en cuenta, con una comunidad por detrás, mejor utilizar eso. Si buscamos por Internet, veremos diferentes formas de hacerlo, en este caso haremos uso de una de las más utilziadas, que es el objeto ``CountVectorizer`` de nuestra cada vez más querida librería scikit-learn.\n",
    "\n",
    "Para ello, nos basaremos en el csv de esta carpeta llamado \"yelp_academic_dataset_review.csv\", que recoge diferentes opiniones sobre diversos establecimientos, con un texto del comentario en cuestión, que será lo que analizaremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26256,
     "status": "ok",
     "timestamp": 1600932020607,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "_g2co9boy1G4"
   },
   "outputs": [],
   "source": [
    "# importamos librerías\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35344,
     "status": "ok",
     "timestamp": 1600932029757,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "2xZN2wy1y1HD",
    "outputId": "7c508d93-870b-4847-ca41-49b4f2e0872a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>business_id</th>\n",
       "      <th>funny</th>\n",
       "      <th>useful</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>_eqQoPtQ3e3UxLE4faT6ow</td>\n",
       "      <td>Ubyfp2RSDYW0g7Mbr8N3iA</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-07-28</td>\n",
       "      <td>First visit...Had lunch here today - used my G...</td>\n",
       "      <td>review</td>\n",
       "      <td>VY_tvNUCCXGXQeSvJl757Q</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>ROru4uk5SaYc3rg8IU7SQw</td>\n",
       "      <td>2XyIOQKbVFb6uXQdJ0RzlQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-01-18</td>\n",
       "      <td>Should be called house of deliciousness!\\n\\nI ...</td>\n",
       "      <td>review</td>\n",
       "      <td>EKzMHI1tip8rC1-ZAy64yg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>gGbN1aKQHMgfQZkqlsuwzg</td>\n",
       "      <td>jyznYkIbpqVmlsZxSDSypA</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-11-16</td>\n",
       "      <td>I recently visited Olive and Ivy for business ...</td>\n",
       "      <td>review</td>\n",
       "      <td>53YGfwmbW73JhFiemNeyzQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0lyVoNazXa20WzUyZPLaQQ</td>\n",
       "      <td>5UKq9WQE1qQbJ0DJbc-B6Q</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-12-02</td>\n",
       "      <td>My nephew just moved to Scottsdale recently so...</td>\n",
       "      <td>review</td>\n",
       "      <td>9SKdOoDHcFoxK5ZtsgHJoA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>KSBFytcdjPKZgXKQnYQdkA</td>\n",
       "      <td>vWSmOhg2ID1MNZHaWapGbA</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-10-16</td>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>review</td>\n",
       "      <td>pF7uRzygyZsltbmVpjIyvw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user_id               review_id  stars        date  \\\n",
       "0     rLtl8ZkDX5vH5nAx9C3q5Q  fWKvX83p0-ka4JS3dc6E5A      5  2011-01-26   \n",
       "1     0a2KyEL0d3Yb1V6aivbIuQ  IjZ33sJrzXqU-0X6U8NwyA      5  2011-07-27   \n",
       "2     0hT2KtfLiobPvh6cDC8JQg  IESLBzqUCLdSzSqm0eCSxQ      4  2012-06-14   \n",
       "3     uZetl9T0NcROGOyFfughhg  G-WvGaISbqqaMHlNnByodA      5  2010-05-27   \n",
       "4     vYmM4KTsC8ZfQBg-j5MWkw  1uJFq2r5QfJG_6ExMRCaGw      5  2012-01-05   \n",
       "...                      ...                     ...    ...         ...   \n",
       "9995  _eqQoPtQ3e3UxLE4faT6ow  Ubyfp2RSDYW0g7Mbr8N3iA      3  2012-07-28   \n",
       "9996  ROru4uk5SaYc3rg8IU7SQw  2XyIOQKbVFb6uXQdJ0RzlQ      4  2012-01-18   \n",
       "9997  gGbN1aKQHMgfQZkqlsuwzg  jyznYkIbpqVmlsZxSDSypA      4  2010-11-16   \n",
       "9998  0lyVoNazXa20WzUyZPLaQQ  5UKq9WQE1qQbJ0DJbc-B6Q      2  2012-12-02   \n",
       "9999  KSBFytcdjPKZgXKQnYQdkA  vWSmOhg2ID1MNZHaWapGbA      5  2010-10-16   \n",
       "\n",
       "                                                   text    type  \\\n",
       "0     My wife took me here on my birthday for breakf...  review   \n",
       "1     I have no idea why some people give bad review...  review   \n",
       "2     love the gyro plate. Rice is so good and I als...  review   \n",
       "3     Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4     General Manager Scott Petello is a good egg!!!...  review   \n",
       "...                                                 ...     ...   \n",
       "9995  First visit...Had lunch here today - used my G...  review   \n",
       "9996  Should be called house of deliciousness!\\n\\nI ...  review   \n",
       "9997  I recently visited Olive and Ivy for business ...  review   \n",
       "9998  My nephew just moved to Scottsdale recently so...  review   \n",
       "9999  4-5 locations.. all 4.5 star average.. I think...  review   \n",
       "\n",
       "                 business_id  funny  useful  cool  \n",
       "0     9yKzy9PApeiPPOUJEtnvkg      0       5     2  \n",
       "1     ZRJwVLyzEJq1VAihDhYiow      0       0     0  \n",
       "2     6oRAC4uyJCsJl1X0WZpVSA      0       1     0  \n",
       "3     _1QQZuf4zZOyFCvXc0o6Vg      0       2     1  \n",
       "4     6ozycU1RpktNG2-1BroVtw      0       0     0  \n",
       "...                      ...    ...     ...   ...  \n",
       "9995  VY_tvNUCCXGXQeSvJl757Q      0       2     1  \n",
       "9996  EKzMHI1tip8rC1-ZAy64yg      0       0     0  \n",
       "9997  53YGfwmbW73JhFiemNeyzQ      0       0     0  \n",
       "9998  9SKdOoDHcFoxK5ZtsgHJoA      0       0     0  \n",
       "9999  pF7uRzygyZsltbmVpjIyvw      0       0     0  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df = pd.read_csv(\"yelp_academic_dataset_review.csv\")\n",
    "review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35328,
     "status": "ok",
     "timestamp": 1600932029757,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "07mKeA-ry1HF",
    "outputId": "6c443116-065e-41b5-c576-0693f0caccff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\\n\\nDo yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I\\'ve ever had.  I\\'m pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\\n\\nWhile EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I\\'ve ever had.\\n\\nAnyway, I can\\'t wait to go back!'"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veamos un registro concreto para la columna de los comentarios:\n",
    "review_df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35698,
     "status": "ok",
     "timestamp": 1600932030138,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "yFLbM0jry1HI"
   },
   "outputs": [],
   "source": [
    "# Importamos el objeto que vamos a usar: CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma de llamar al CountVectorizer se basa en expresiones regulares, las cuales, como hemos dicho en la parte de tratamiento Series de strings, no veremos porque nos lelvaría mucho tiempo. En caso de querer profundizar o tener un caso particular que analizar, se podría consultar la documentación necesaria para entender qué se necesita pasar como patrón.\n",
    "\n",
    "En este caso, como lo vamos a utilizar para contar siempre lo mismo, que serán unidades mínimas de significado (palabras eliminando puntos, comas y demás elementos ortográficos que no paorten valor), pues dejaremos la expresión como necesaria para que funcinoes y, por defecto, siempre utilizaremos la misma.\n",
    "\n",
    "Esta expresión es la siguiente ``'(?u)\\\\b\\\\w+\\\\b'``, donde:\n",
    "  - ``(?u)`` hace referencia a que busque cosas unicode (para que pueda interpretar palabras con tildes, por ejemplo)\n",
    "  - ``\\\\b\\\\w+\\\\b`` sirve para identificar las secuencias de caracteres que se corresponden con una palabra\n",
    "  \n",
    "Es decir, con esto le estamos diciendo al ``CountVectorizer`` que haga el conteo de todas las palabras del texto.\n",
    "\n",
    "Para entender su funcionamiento, hagamos la prueba solo con el primer texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36593,
     "status": "ok",
     "timestamp": 1600932031068,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "1DX1OjyHy1HM",
    "outputId": "3e98fd9f-0235-4b62-96f3-c854432de8a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 29222)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_converter = CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "x = bow_converter.fit_transform(review_df['text'])\n",
    "x.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La varaible ``x`` ahora almacena el vector con las apariciones de las diferentes palabras. El formato es como el que hemos visto en otros objetos, como la salida de la función de Hash, ya que nos permiten ahorrar mucho espacio. En este caso, no tiene mucho sentido, ya que estamos hablando de un texto, sin embargo, como vamos a hacer en un par de celdas, esto se utiliza con todos los textos de un dataset, donde la compresión de datos es algo muy necesario.\n",
    "\n",
    "Podemos ver qué palabras se han detectado mediante un método del ``CountVectorizer`` creado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36571,
     "status": "ok",
     "timestamp": 1600932031068,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "u_3Xg2O7y1HO",
    "outputId": "babc1b92-d0b5-4ad6-a5d9-893af15baff8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29222"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = bow_converter.get_feature_names()\n",
    "# Hemos detectado un total de las siguientes palabras (1-grams) distintas:\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36557,
     "status": "ok",
     "timestamp": 1600932031069,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "ZLDYBINRy1HR",
    "outputId": "3b70182c-0734-4f44-ba58-5b05390b19b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '00', '000', '007', '00a', '00am', '00pm', '01', '02', '03']"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]\n",
    "# los 10 primeros elementos de la lista, de 0 a 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1,  1,  2,  1,  8,  1,  1,  1,  2,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  1,  3,  1,  1,  1,  1,\n",
       "         1,  1,  1,  2,  1,  1,  1,  3,  2,  5,  1,  9,  1,  1,  1,  1,\n",
       "         2,  1,  1,  1,  1,  1,  2,  1,  3,  1,  1,  2,  1,  1,  1,  1,\n",
       "         1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 10,\n",
       "         4,  1,  1,  1,  1,  1,  1,  1,  1,  2,  1,  1,  1,  8,  1,  1,\n",
       "         1,  1,  1,  1,  2,  2,  1]], dtype=int64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores para todas las palabras según el orden alfabético:\n",
    "x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'my': 54,\n",
       " 'wife': 99,\n",
       " 'took': 85,\n",
       " 'me': 50,\n",
       " 'here': 40,\n",
       " 'on': 56,\n",
       " 'birthday': 12,\n",
       " 'for': 31,\n",
       " 'breakfast': 16,\n",
       " 'and': 6,\n",
       " 'it': 43,\n",
       " 'was': 93,\n",
       " 'excellent': 27,\n",
       " 'the': 79,\n",
       " 'weather': 94,\n",
       " 'perfect': 62,\n",
       " 'which': 96,\n",
       " 'made': 48,\n",
       " 'sitting': 73,\n",
       " 'outside': 60,\n",
       " 'overlooking': 61,\n",
       " 'their': 80,\n",
       " 'grounds': 38,\n",
       " 'an': 5,\n",
       " 'absolute': 2,\n",
       " 'pleasure': 66,\n",
       " 'our': 59,\n",
       " 'waitress': 92,\n",
       " 'food': 30,\n",
       " 'arrived': 8,\n",
       " 'quickly': 68,\n",
       " 'semi': 71,\n",
       " 'busy': 17,\n",
       " 'saturday': 69,\n",
       " 'morning': 53,\n",
       " 'looked': 45,\n",
       " 'like': 44,\n",
       " 'place': 65,\n",
       " 'fills': 29,\n",
       " 'up': 87,\n",
       " 'pretty': 67,\n",
       " 'so': 75,\n",
       " 'earlier': 23,\n",
       " 'you': 101,\n",
       " 'get': 35,\n",
       " 'better': 11,\n",
       " 'do': 22,\n",
       " 'yourself': 102,\n",
       " 'a': 1,\n",
       " 'favor': 28,\n",
       " 'bloody': 14,\n",
       " 'mary': 49,\n",
       " 'phenomenal': 63,\n",
       " 'simply': 72,\n",
       " 'best': 10,\n",
       " 'i': 41,\n",
       " 've': 89,\n",
       " 'ever': 25,\n",
       " 'had': 39,\n",
       " 'm': 47,\n",
       " 'sure': 76,\n",
       " 'they': 82,\n",
       " 'only': 57,\n",
       " 'use': 88,\n",
       " 'ingredients': 42,\n",
       " 'from': 33,\n",
       " 'garden': 34,\n",
       " 'blend': 13,\n",
       " 'them': 81,\n",
       " 'fresh': 32,\n",
       " 'when': 95,\n",
       " 'order': 58,\n",
       " 'amazing': 4,\n",
       " 'while': 97,\n",
       " 'everything': 26,\n",
       " 'menu': 52,\n",
       " 'looks': 46,\n",
       " 'white': 98,\n",
       " 'truffle': 86,\n",
       " 'scrambled': 70,\n",
       " 'eggs': 24,\n",
       " 'vegetable': 90,\n",
       " 'skillet': 74,\n",
       " 'tasty': 78,\n",
       " 'delicious': 21,\n",
       " 'came': 18,\n",
       " 'with': 100,\n",
       " '2': 0,\n",
       " 'pieces': 64,\n",
       " 'of': 55,\n",
       " 'griddled': 37,\n",
       " 'bread': 15,\n",
       " 'absolutely': 3,\n",
       " 'meal': 51,\n",
       " 'complete': 20,\n",
       " 'toast': 84,\n",
       " 'anyway': 7,\n",
       " 'can': 19,\n",
       " 't': 77,\n",
       " 'wait': 91,\n",
       " 'to': 83,\n",
       " 'go': 36,\n",
       " 'back': 9}"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si queremos un diccionario con clave:valor n-gram:posición en el vector anterior, sería esto:\n",
    "bow_converter.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del mismo modo que hemos sacado los 1-grams, también podemos hacer lo propio para el resto de n-grams. Por ejemplo, 2-grams (bigramas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39682,
     "status": "ok",
     "timestamp": 1600932034204,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "rZZTnmvwy1HT"
   },
   "outputs": [],
   "source": [
    "bigram_converter = CountVectorizer(ngram_range=(2,2), token_pattern= '(?u)\\\\b\\\\w+\\\\b')\n",
    "x2 = bigram_converter.fit_transform(review_df['text'])\n",
    "# tomamos las palabras solo de 2 en 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39672,
     "status": "ok",
     "timestamp": 1600932034206,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "VEfqqsFny1HV",
    "outputId": "6aabf05f-1d4f-4223-e487-af03ad0cda52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368943"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = bigram_converter.get_feature_names()\n",
    "len(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39655,
     "status": "ok",
     "timestamp": 1600932034206,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "R2Rkf4H2y1HX",
    "outputId": "3a1ea27e-5649-49a9-b5b1-9c1aaf6c000f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 0', '0 20', '0 39', '0 5', '0 50', '0 6', '0 75', '0 90', '0 95', '0 99']"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sacamos los primeros bigramas:\n",
    "bigrams[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO 1\n",
    "\n",
    "¿Cómo crees que sería para 3-grams? ¿Podrías replicar lo que hemos visto de los 2-grams pero para los 3-grams? Solamente saca el número de 3-grams que detectamos en ese primer texto y muestra los 10 primeros 3-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45154,
     "status": "ok",
     "timestamp": 1600932039720,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "tymksgvRy1HZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2 pieces of',\n",
       " 'a favor and',\n",
       " 'absolute pleasure our',\n",
       " 'absolutely made the',\n",
       " 'amazing and it',\n",
       " 'amazing while everything',\n",
       " 'an absolute pleasure',\n",
       " 'and blend them',\n",
       " 'and delicious it',\n",
       " 'and get their']"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_converter = CountVectorizer(ngram_range=(3,3), token_pattern= '(?u)\\\\b\\\\w+\\\\b')\n",
    "x2 = trigram_converter.fit_transform(review_df['text'].iloc[:1])\n",
    "trigrams = trigram_converter.get_feature_names()\n",
    "print(len(trigrams))\n",
    "trigrams[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO 2\n",
    "\n",
    "Como te habrás podido fijar, nuestro objeto ``CountVectorizer`` funciona con DataFrames, solo que para entenderlo de una forma más sencilla, en cada paso lo limitábamos a solo 1 registro mediante la sentencia ``review_df['text'].iloc[:1]``. Sin embargo, esto está pensado para tratar con datasets enteros, ya que ahí es donde reside la verdadera utilidad, permitiéndonos hacer ordenaciones y agrupaciones en función del texto, dentro de un conjunto de textos.\n",
    "\n",
    "Para ello, deberíamos utilizar el DataFrame completo. A continuación, repite los pasos anteiores para obtener la longitud de los n-grams diferentes y muestra por pantalla cuánto es esa longitud para el DataFrame completo para: 1-gram, 2-gram y 3-gram. Es decir, repite lo que hemos hecho antes (los 3 casos: 1-gram, 2-gram y 3-gram) pero ahora con el DataFrame completo, y almacena en 3 variables diferentes las combinaciones de ngramas obtenidas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes observar, a medida que aumentamos el número de n, van aumentando el número de n-grams posibles.\n",
    "\n",
    "### Entendiendo los monogramas, bigramas y trigramas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se muestra un ejemplo para un texto concreto. En él podemos observar que el objeto elimina las palabras de 1 solo caracter ya que, por defecto, la expresión regular toma palabras de al menos 2 caracteres de longitud. Además, accederemos al atributo ``vocabulary_`` que, como hemos visto antes, nos devuelve un diccionario con las palbras identificadas y su posición alfabética respecto al total de palabras identificadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46230,
     "status": "ok",
     "timestamp": 1600932040856,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "uMTx-NPXk35m",
    "outputId": "4e3d4afb-e365-4ce6-a6fd-71684060187f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'an': 0, 'apple': 1, 'day': 3, 'keeps': 5, 'the': 6, 'doctor': 4, 'away': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 1, 2, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo_n_gramas = CountVectorizer(ngram_range=(1,1))\n",
    "print(ejemplo_n_gramas.fit([\"an apple a day keeps the doctor away\"]).vocabulary_)\n",
    "ejemplo_n_gramas.transform([\"an apple a day keeps the day doctor away an\"]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podríamos obtener combinaciones de n-grams mediante el parámetro ``ngram_range``, que es una tupla donde el primer valor identifica el mínimo número de palabras (el n del n-gram) y el segundo, el máximo (ambos incluidos). Por ejemplo, si queremos obtener monogramas y bigramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46215,
     "status": "ok",
     "timestamp": 1600932040856,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "DbGhd75Xk35t",
    "outputId": "80a7b7da-8902-4d97-81a2-3ed6f531b13a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'an': 0, 'apple': 2, 'day': 5, 'keeps': 9, 'the': 11, 'doctor': 7, 'away': 4, 'an apple': 1, 'apple day': 3, 'day keeps': 6, 'keeps the': 10, 'the doctor': 12, 'doctor away': 8}\n"
     ]
    }
   ],
   "source": [
    "ejemplo_n_gramas = CountVectorizer(ngram_range=(1,2))\n",
    "print(ejemplo_n_gramas.fit([\"an apple a day keeps the doctor away\"]).vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y si queremos monogramas, bigramas y trigramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46198,
     "status": "ok",
     "timestamp": 1600932040857,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "_IgcngOmk35y",
    "outputId": "7e17edd7-95d5-4456-bf86-a7b9bc16640a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'an': 0, 'apple': 3, 'day': 7, 'keeps': 12, 'the': 15, 'doctor': 10, 'away': 6, 'an apple': 1, 'apple day': 4, 'day keeps': 8, 'keeps the': 13, 'the doctor': 16, 'doctor away': 11, 'an apple day': 2, 'apple day keeps': 5, 'day keeps the': 9, 'keeps the doctor': 14, 'the doctor away': 17}\n"
     ]
    }
   ],
   "source": [
    "ejemplo_n_gramas = CountVectorizer(ngram_range=(1,3))\n",
    "print(ejemplo_n_gramas.fit([\"an apple a day keeps the doctor away\"]).vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volviendo sobre los resultados que hemos sacado en el último ejercicio, también podría resultar interesante representar el número de n-grams en función de la n para todo el DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46584,
     "status": "ok",
     "timestamp": 1600932041260,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "DXeh7ui_y1Hi",
    "outputId": "c500d115-a727-4789-a252-ed3822d0567e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46568,
     "status": "ok",
     "timestamp": 1600932041260,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "EWo__Xoxy1Hk",
    "outputId": "15920c9f-3b35-4a62-a957-6c793f923054"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nos creamos una lista para la representación en nase a las longitudes que hemos sacado anteriormente:\n",
    "counts = [len_ngram_1, len_ngram_2, len_ngram_3]\n",
    "plt.plot(counts, color='b', alpha=0.25)\n",
    "plt.plot(counts, 'bo')\n",
    "plt.margins(0.1)\n",
    "plt.xticks(range(3), ['unigram', 'bigram', 'trigram'])\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.title('Nº n-grams en las reviews de Yelp', {'fontsize':16})\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSEanGNOy1Hl"
   },
   "source": [
    "## Limpiando nuestras features\n",
    "\n",
    "Al igual que en las numéricas, como podría ser la medida de algún experimento, es posible que se nos cuele algo de ruido en nuestros datos. Pero en el caso de estar trabajando con palabras, ¿cómo separamos limpiamente la señal del ruido? La respuesta es sencilla, a través del filtrado, ya que nos permitirá que técnicas basadas en la tokenización (sobre los datos sin procesar) y el conteo (para generar listas de palabras simples o n-gramas) se vuelvan más utilizables. La detección de frases, que discutiremos a continuación, puede verse como un filtro de bigrama particular.\n",
    "\n",
    "A continuación, se recogen algunas formas más de realizar este filtrado.\n",
    "\n",
    "\n",
    "### Stopwords\n",
    "\n",
    "Tanto la clasificación como la recuperación de textos no suelen requerir una comprensión profunda del texto. Por ejemplo, en la oración \"Emma knocked on the door\", las palabras \"on\" y \"the\" no cambian el hecho de que esta oración trata sobre una persona y una puerta. Para tareas de grano grueso como la clasificación, los pronombres, artículos y preposiciones pueden no agregar mucho valor. Estas palabras que no paortan valor se denominan _stopwords_. Cabe destacar que el caso puede ser muy diferente en el análisis de sentimientos, que requiere un conocimiento detallado de la semántica, por lo que sí le estarían aportando información.\n",
    "\n",
    "\n",
    "El popular paquete Python de Procesamiento de Lenguaje Natural (NLP, del inglés Natural Langauge Processing), llamado NLTK contiene una lista de stopwords definidas por lingüistas para muchos idiomas. (Para esto necesitaremos instalar NLTK y ejecutar ``nltk.download()`` del lenguaje que vayamos a usar para obtener todas las ventajas). También se pueden encontrar varias listas de stopwords en Internet.\n",
    "\n",
    "Por ejemplo, a continuación se muestran algunas palabras de muestra de la lista de stopwords en inglés:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47445,
     "status": "ok",
     "timestamp": 1600932042153,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "Qq7BEgiXy1Hm",
    "outputId": "66490902-4a28-44f9-9617-d8382f4393f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\TheBridge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos la librería nltk para procesamiento de lenguaje natural\n",
    "import nltk\n",
    "# Importamos las stopwords\n",
    "from nltk.corpus import stopwords\n",
    "# Nos desacargamos la información:\n",
    "nltk.download('stopwords')\n",
    "# Leemos la primeras 10 stopwords del idioma inglés:\n",
    "stopwords.words('english')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fíjate que la lista contiene apóstrofos y las palabras no están en mayúscula. Para usarlo tal como está, el proceso de tokenización no debe comerse apóstrofos y las palabras deben convertirse a minúsculas.\n",
    "\n",
    "Por otra parte, también podríamos obtener las stopowords del castellano si cambiamos el parámetro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se']"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('spanish')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04kSK7ISy1Ho"
   },
   "source": [
    "## Filtrado basado en la frecuencia\n",
    "\n",
    "Las listas de palabras irrelevantes son una forma de eliminar las palabras comunes que generan características vacías. Hay otras formas más estadísticas de llegar al concepto de \"palabras comunes\". Existen métodos que dependen de definiciones manuales y otros que se basan en estadísticas. La misma idea se aplica al filtrado de palabras. Aquí también podemos usar estadísticas de frecuencia.\n",
    "\n",
    "\n",
    "### Palabras frecuentes\n",
    "\n",
    "Las estadísticas de frecuencia son excelentes para filtrar palabras comunes específicas del corpus (el vocabulario, nuestro espacio de palabras), así como palabras vacías de propósito general. Por ejemplo, la frase \"New York Times\" y cada una de las palabras individuales que contiene aparecen con frecuencia en el conjunto de datos de todos los artículos del New York Times (New York Times Annotated Corpus). De manera similar, la palabra \"house\" aparece a menudo en la frase \"House of Commons\" en el corpus de los debates del parlamento canadiense, un conjunto de datos que se usa popularmente para la traducción automática estadística porque contiene una versión en inglés y otra en francés de todos los documentos. Estas palabras son significativas en general, pero no dentro de esos corpus particulares. Una lista típica de stopwords capturará las stopwords generales, pero no las específicas del corpus.\n",
    "\n",
    "Observar las palabras más frecuentes puede revelar problemas de análisis y resaltar palabras normalmente útiles que aparecen demasiadas veces en el corpus. Por ejemplo, la siguiente imagen muestra una tabla que enumera las 40 palabras más frecuentes en el conjunto completo de datos de reseñas de Yelp (aquí estamos con una versión muy reducida de 10 mil registros para poder realizar los ejemplos sin problemas de rendimiento).\n",
    "\n",
    "En este caso, la frecuencia se basa en la cantidad de documentos (reseñas) en los que aparecen, no en su recuento dentro de un documento. Como podemos ver, la lista incluye muchas stopwords. También contiene algunas sorpresas: \"s\" y \"t\" están en la lista porque usamos el apóstrofe como un delimitador de tokenización, y palabras como \"Mary’s\" o \"didn’t\" se analizaron como \"Mary s\" y \"didn t\". Además, las palabras \"good\", \"food\" y \"great\" aparecen cada una en alrededor de un tercio de las reseñas, pero es posible que deseemos mantenerlas porque son muy útiles para tareas como el análisis de sentimientos o la categorización empresarial.\n",
    "\n",
    "<img src=\"../../imagenes/imagen6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VgLLbbshy1Ho"
   },
   "source": [
    "En la práctica, es útil combinar el filtrado basado en frecuencia con una lista de stopwords. También está la delicada cuestión de dónde colocar el límite. Desafortunadamente, no existe una respuesta universal. La mayoría de las veces, el límite debe determinarse manualmente, a base de prubea y error, y es posible que deba volver a examinarse cuando cambie el conjunto de datos.\n",
    "\n",
    "\n",
    "### Palabras raras\n",
    "\n",
    "Dependiendo del caso de uso, también es posible que debamos filtrar las palabras raras. Estas pueden ser palabras que realmente no se suelen usar o errores ortográficos de palabras comunes. Para un modelo estadístico, una palabra que aparece en solo uno o dos documentos es más ruido que información útil. Por ejemplo, supongamos que la tarea consiste en clasificar las empresas en función de sus reseñas de Yelp, y una sola reseña contiene la palabra \"gobbledygook\". ¿Cómo se puede saber, basándose en esta palabra, si el negocio es un restaurante, un salón de belleza o un bar? Incluso en el caso que conociéramos el negocio al que hace referencia la reseña completa, que en este caso era un bar, probablemente sería un error clasificarlo como tal para otras reseñas que contengan la palabra \"gobbledygook\".\n",
    "\n",
    "Las palabras raras no solo son poco fiables como predictores, sino que también generan un coste computacional extra. El conjunto de 1,6 millones de reseñas de Yelp contiene 357.481 palabras únicas (tokenizadas por espacios y caracteres de puntuación), de las cuales 189.915 aparecen en una sola reseña y 41,162 en dos reseñas. Más del 60% del vocabulario ocurre raramente. Esta es la denominada distribución de cola pesada y es muy común en los datos del mundo real. El tiempo de entrenamiento de muchos modelos estadísticos de aprendizaje automático se escala linealmente con el número de características o varaibles (que en este caso serán las palabras únicas), y algunos modelos crecen de forma cuadrática con ellas, o incluso peor. Por lo tanto, nos interesará eliminar las palabras raras ya que implican un gran costo de cálculo y almacenamiento a cambio de no mucha ganancia adicional.\n",
    "\n",
    "Las palabras raras se pueden identificar y recortar fácilmente según las estadísticas de recuento de palabras. Alternativamente, sus recuentos se pueden agregar a un contenedor de basura especial, que puede servir como una característica adicional. La siguiente figura muestra esta representación en un documento corto que contiene un montón de palabras habituales y dos palabras raras, \"gobbledygook\" y \"zylophant\". Las palabras habituales conservan sus propios recuentos, que se pueden filtrar aún más mediante listas de stopwords u otros métodos basados en las frecuencias. Las palabras raras pierden su identidad y se agrupan en una nueva característica denominada ``GARBAGE``.\n",
    "\n",
    "<img src=\"../../imagenes/imagen7.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que uno no sabrá qué palabras son raras hasta que se haya contado todo el corpus, la función del contenedor de basura deberá recopilarse como un paso posterior al procesamiento inicial.\n",
    "\n",
    "Si un documento de texto es muy corto, es probable que no contenga información útil y no debería utilizarse al entrenar un modelo. Sin embargo, hay que tener cuidado al aplicar esta regla. El volcado de Wikipedia contiene muchas páginas que son apéndices incompletos, que probablemente sean seguros para filtrar. Los tweets, por otro lado, son intrínsecamente cortos y requieren otros trucos de caracterización y modelado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO\n",
    "\n",
    "Al igual que hemos hecho antes con el contador de palabras, diseña una función que implemente el contador de palabras con el acumulador de basura. Te puedes basar el la función que has creado antes, ya que la mayor parte de la funcionalidad es compartida entre ambas funciones.\n",
    "\n",
    "A diferencia de antes, ahora necesitaremos la lista de todos los textos que están en el DataFrame para extraer la información sobre las palabras raras. Para simplificarlo todo, supongamos que lo que nos pasan en este parámetro es la columna 'text', es decir, un Series de strings. Por lo tanto, los parámetros de entrada de nuestra función serán:\n",
    "  - texto: al igual que antes, el texto que convertir a un vector de apariciones\n",
    "  - col: columna del DataFrame donde están todos los textos\n",
    "  - umbral: número de 0 a 100 que nos indicará el máximo porcentaje de apariciones de una palabra en todos los textos para ser considerada rara. Por defecto, hacer que valga 0.01 (1 palabra de cada 10.000).\n",
    "  \n",
    "La función debera, por tanto, hacer lo siguiente:\n",
    "1. Leer la columna de textos y sacar el conteo de cada palabra en el total. Para ello, podrías hacer varias cosas, como:\n",
    "    - Concatenar todos los textos en 1 solo y hacerle el conteo de palabras\n",
    "    - Hacer el conteo de palabras para cada fila de la columna de textos, y luego sumar los diccionarios\n",
    "    - Otra que se te ocurra\n",
    "2. Sacar las palabras GARBAGE, para lo que tendrás que, una vez tengas el conteo, sumar todas las apariciones para sacar el total de palabras que tiene el texto, y sacar el porcentaje particular de cada palabra. Luego, si es menor que el porcentaje umbral, será considerada GARBAGE. Si no, no. (Puede que sea mejor hacerlo con Series de Pandas).\n",
    "3. Hacer el conteo de texto\n",
    "4. Convertir el diccionario a Series\n",
    "5. Hacer el mapeo de las palabras GARBAGE dentro del conteo\n",
    "6. agrupar por palabra y sumar para que garbage obtenga lo suyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras = analiza_texto(' '.join(df['text'].iloc[:50].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'My': 7,\n",
       " 'wife': 3,\n",
       " 'took': 5,\n",
       " 'me': 27,\n",
       " 'here': 24,\n",
       " 'on': 49,\n",
       " 'my': 49,\n",
       " 'birthday': 1,\n",
       " 'for': 77,\n",
       " 'breakfast': 2,\n",
       " 'and': 245,\n",
       " 'it': 62,\n",
       " 'was': 113,\n",
       " 'excellent': 6,\n",
       " '': 192,\n",
       " 'The': 59,\n",
       " 'weather': 1,\n",
       " 'perfect': 3,\n",
       " 'which': 8,\n",
       " 'made': 8,\n",
       " 'sitting': 3,\n",
       " 'outside': 6,\n",
       " 'overlooking': 1,\n",
       " 'their': 25,\n",
       " 'grounds': 1,\n",
       " 'an': 13,\n",
       " 'absolute': 1,\n",
       " 'pleasure': 1,\n",
       " 'Our': 2,\n",
       " 'waitress': 3,\n",
       " 'our': 14,\n",
       " 'food': 20,\n",
       " 'arrived': 3,\n",
       " 'quickly': 4,\n",
       " 'the': 277,\n",
       " 'semibusy': 1,\n",
       " 'Saturday': 2,\n",
       " 'morning': 3,\n",
       " 'It': 20,\n",
       " 'looked': 3,\n",
       " 'like': 16,\n",
       " 'place': 30,\n",
       " 'fills': 1,\n",
       " 'up': 17,\n",
       " 'pretty': 11,\n",
       " 'so': 22,\n",
       " 'earlier': 3,\n",
       " 'you': 38,\n",
       " 'get': 19,\n",
       " 'betterDo': 1,\n",
       " 'yourself': 2,\n",
       " 'a': 157,\n",
       " 'favor': 1,\n",
       " 'Bloody': 1,\n",
       " 'Mary': 1,\n",
       " 'phenomenal': 1,\n",
       " 'simply': 2,\n",
       " 'best': 9,\n",
       " 'Ive': 7,\n",
       " 'ever': 4,\n",
       " 'had': 38,\n",
       " 'Im': 13,\n",
       " 'sure': 3,\n",
       " 'they': 37,\n",
       " 'only': 9,\n",
       " 'use': 1,\n",
       " 'ingredients': 1,\n",
       " 'from': 16,\n",
       " 'garden': 1,\n",
       " 'blend': 1,\n",
       " 'them': 20,\n",
       " 'fresh': 8,\n",
       " 'when': 13,\n",
       " 'order': 5,\n",
       " 'amazingWhile': 1,\n",
       " 'EVERYTHING': 1,\n",
       " 'menu': 7,\n",
       " 'looks': 2,\n",
       " 'I': 199,\n",
       " 'white': 1,\n",
       " 'truffle': 1,\n",
       " 'scrambled': 1,\n",
       " 'eggs': 3,\n",
       " 'vegetable': 1,\n",
       " 'skillet': 1,\n",
       " 'tasty': 4,\n",
       " 'delicious': 9,\n",
       " 'came': 8,\n",
       " 'with': 55,\n",
       " '2': 9,\n",
       " 'pieces': 1,\n",
       " 'of': 93,\n",
       " 'griddled': 1,\n",
       " 'bread': 8,\n",
       " 'amazing': 6,\n",
       " 'absolutely': 3,\n",
       " 'meal': 2,\n",
       " 'complete': 1,\n",
       " 'toast': 1,\n",
       " 'hadAnyway': 1,\n",
       " 'cant': 7,\n",
       " 'wait': 6,\n",
       " 'to': 143,\n",
       " 'go': 19,\n",
       " 'back': 18,\n",
       " 'have': 46,\n",
       " 'no': 10,\n",
       " 'idea': 1,\n",
       " 'why': 2,\n",
       " 'some': 17,\n",
       " 'people': 11,\n",
       " 'give': 5,\n",
       " 'bad': 11,\n",
       " 'reviews': 5,\n",
       " 'about': 16,\n",
       " 'this': 31,\n",
       " 'goes': 3,\n",
       " 'show': 4,\n",
       " 'can': 20,\n",
       " 'please': 1,\n",
       " 'everyone': 1,\n",
       " 'They': 18,\n",
       " 'are': 27,\n",
       " 'probably': 4,\n",
       " 'griping': 1,\n",
       " 'something': 7,\n",
       " 'that': 40,\n",
       " 'own': 2,\n",
       " 'faultthere': 1,\n",
       " 'many': 6,\n",
       " 'thatIn': 1,\n",
       " 'any': 4,\n",
       " 'case': 2,\n",
       " 'friend': 7,\n",
       " 'at': 24,\n",
       " '550': 1,\n",
       " 'PM': 1,\n",
       " 'past': 1,\n",
       " 'Sunday': 2,\n",
       " 'crowded': 2,\n",
       " 'more': 11,\n",
       " 'than': 8,\n",
       " 'thought': 6,\n",
       " 'evening': 4,\n",
       " 'we': 23,\n",
       " 'would': 13,\n",
       " 'forever': 2,\n",
       " 'seat': 2,\n",
       " 'but': 62,\n",
       " 'said': 4,\n",
       " 'well': 9,\n",
       " 'be': 20,\n",
       " 'seated': 6,\n",
       " 'girl': 1,\n",
       " 'comes': 2,\n",
       " 'seating': 2,\n",
       " 'someone': 2,\n",
       " 'else': 3,\n",
       " 'We': 16,\n",
       " 'were': 35,\n",
       " '552': 1,\n",
       " 'waiter': 4,\n",
       " 'got': 12,\n",
       " 'drink': 2,\n",
       " 'orders': 3,\n",
       " 'Everyone': 1,\n",
       " 'very': 26,\n",
       " 'pleasant': 3,\n",
       " 'host': 1,\n",
       " 'us': 11,\n",
       " 'server': 1,\n",
       " 'prices': 3,\n",
       " 'good': 33,\n",
       " 'as': 30,\n",
       " 'placed': 1,\n",
       " 'once': 3,\n",
       " 'decided': 1,\n",
       " 'what': 19,\n",
       " 'wanted': 3,\n",
       " '602': 1,\n",
       " 'shared': 1,\n",
       " 'baked': 2,\n",
       " 'spaghetti': 1,\n",
       " 'calzone': 4,\n",
       " 'small': 8,\n",
       " 'Heres': 2,\n",
       " 'Beef': 1,\n",
       " 'pizza': 12,\n",
       " 'both': 4,\n",
       " 'try': 9,\n",
       " 'huge': 2,\n",
       " 'smallest': 1,\n",
       " 'one': 12,\n",
       " 'personal': 1,\n",
       " '11': 1,\n",
       " 'Both': 2,\n",
       " 'awesome': 4,\n",
       " 'liked': 6,\n",
       " 'better': 8,\n",
       " 'does': 3,\n",
       " 'sweetish': 1,\n",
       " 'sauce': 5,\n",
       " 'thats': 3,\n",
       " 'how': 7,\n",
       " 'sauceWe': 1,\n",
       " 'box': 1,\n",
       " 'part': 1,\n",
       " 'take': 4,\n",
       " 'home': 1,\n",
       " 'out': 22,\n",
       " 'door': 2,\n",
       " 'by': 12,\n",
       " '642': 1,\n",
       " 'So': 4,\n",
       " 'everything': 3,\n",
       " 'great': 20,\n",
       " 'not': 25,\n",
       " 'these': 5,\n",
       " 'reviewers': 3,\n",
       " 'That': 1,\n",
       " 'things': 4,\n",
       " 'because': 10,\n",
       " 'all': 25,\n",
       " 'serious': 2,\n",
       " 'issues': 2,\n",
       " 'love': 8,\n",
       " 'gyro': 1,\n",
       " 'plate': 3,\n",
       " 'Rice': 1,\n",
       " 'is': 69,\n",
       " 'also': 8,\n",
       " 'dig': 1,\n",
       " 'candy': 1,\n",
       " 'selection': 4,\n",
       " 'Rosie': 2,\n",
       " 'Dakota': 1,\n",
       " 'LOVE': 2,\n",
       " 'Chaparral': 1,\n",
       " 'Dog': 1,\n",
       " 'Park': 2,\n",
       " 'Its': 8,\n",
       " 'convenient': 1,\n",
       " 'surrounded': 1,\n",
       " 'lot': 6,\n",
       " 'paths': 1,\n",
       " 'desert': 1,\n",
       " 'xeriscape': 1,\n",
       " 'baseball': 1,\n",
       " 'fields': 1,\n",
       " 'ballparks': 1,\n",
       " 'lake': 1,\n",
       " 'ducksThe': 1,\n",
       " 'Scottsdale': 3,\n",
       " 'Rec': 1,\n",
       " 'Dept': 1,\n",
       " 'wonderful': 1,\n",
       " 'job': 3,\n",
       " 'keeping': 3,\n",
       " 'park': 2,\n",
       " 'clean': 6,\n",
       " 'shaded': 1,\n",
       " 'You': 1,\n",
       " 'find': 3,\n",
       " 'trash': 1,\n",
       " 'cans': 1,\n",
       " 'poopypick': 1,\n",
       " 'mitts': 1,\n",
       " 'located': 1,\n",
       " 'over': 11,\n",
       " 'pathsThe': 1,\n",
       " 'fenced': 1,\n",
       " 'in': 53,\n",
       " 'area': 3,\n",
       " 'let': 4,\n",
       " 'dogs': 2,\n",
       " 'run': 4,\n",
       " 'play': 2,\n",
       " 'sniff': 1,\n",
       " 'General': 1,\n",
       " 'Manager': 1,\n",
       " 'Scott': 3,\n",
       " 'Petello': 1,\n",
       " 'egg': 2,\n",
       " 'Not': 3,\n",
       " 'into': 9,\n",
       " 'detail': 1,\n",
       " 'assure': 1,\n",
       " 'if': 18,\n",
       " 'albeit': 1,\n",
       " 'rare': 2,\n",
       " 'speak': 2,\n",
       " 'treat': 1,\n",
       " 'guy': 5,\n",
       " 'respect': 1,\n",
       " 'state': 1,\n",
       " 'your': 7,\n",
       " 'Id': 4,\n",
       " 'surprised': 3,\n",
       " 'dont': 7,\n",
       " 'walk': 3,\n",
       " 'totally': 2,\n",
       " 'satisfied': 2,\n",
       " 'just': 20,\n",
       " 'did': 8,\n",
       " 'Like': 2,\n",
       " 'always': 9,\n",
       " 'say': 6,\n",
       " 'Mistakes': 1,\n",
       " 'inevitable': 1,\n",
       " 'its': 6,\n",
       " 'recover': 1,\n",
       " 'importantThanks': 1,\n",
       " 'his': 4,\n",
       " 'staff': 7,\n",
       " 'Youve': 1,\n",
       " 'customer': 3,\n",
       " 'life': 3,\n",
       " 'Quiessence': 1,\n",
       " 'put': 5,\n",
       " 'beautiful': 1,\n",
       " 'Full': 1,\n",
       " 'windows': 1,\n",
       " 'earthy': 1,\n",
       " 'wooden': 1,\n",
       " 'walls': 1,\n",
       " 'feeling': 2,\n",
       " 'warmth': 1,\n",
       " 'inside': 3,\n",
       " 'restaurant': 5,\n",
       " 'perched': 1,\n",
       " 'middle': 1,\n",
       " 'farm': 1,\n",
       " 'seemed': 3,\n",
       " 'fairly': 3,\n",
       " 'full': 1,\n",
       " 'even': 6,\n",
       " 'Tuesday': 2,\n",
       " 'secured': 1,\n",
       " 'reservations': 1,\n",
       " 'couple': 3,\n",
       " 'days': 2,\n",
       " 'beforeMy': 1,\n",
       " 'sampled': 1,\n",
       " 'sandwiches': 3,\n",
       " 'Farm': 1,\n",
       " 'Kitchen': 1,\n",
       " 'week': 1,\n",
       " 'impressed': 2,\n",
       " 'enough': 9,\n",
       " 'want': 8,\n",
       " 'eat': 5,\n",
       " 'crisp': 3,\n",
       " 'veggies': 3,\n",
       " 'didnt': 12,\n",
       " 'disappoint': 1,\n",
       " 'ordered': 16,\n",
       " 'salad': 9,\n",
       " 'orange': 1,\n",
       " 'grapefruit': 1,\n",
       " 'slices': 3,\n",
       " 'crudites': 1,\n",
       " 'start': 1,\n",
       " 'know': 6,\n",
       " 'much': 11,\n",
       " 'raw': 1,\n",
       " 'radishes': 1,\n",
       " 'turnips': 1,\n",
       " 'until': 6,\n",
       " 'tried': 4,\n",
       " 'pesto': 2,\n",
       " 'aioli': 1,\n",
       " 'saucesFor': 1,\n",
       " 'entrees': 7,\n",
       " 'lamb': 1,\n",
       " 'pork': 2,\n",
       " 'shoulder': 1,\n",
       " 'Service': 2,\n",
       " 'started': 3,\n",
       " 'trailed': 1,\n",
       " 'off': 7,\n",
       " 'Waiting': 1,\n",
       " 'long': 3,\n",
       " 'time': 15,\n",
       " 'after': 5,\n",
       " 'received': 3,\n",
       " 'finished': 3,\n",
       " 'before': 6,\n",
       " 'ours': 1,\n",
       " 'bothered': 1,\n",
       " 'explain': 1,\n",
       " 'situation': 1,\n",
       " 'maitred': 1,\n",
       " 'apologized': 2,\n",
       " 'almost': 1,\n",
       " '45': 2,\n",
       " 'minutes': 4,\n",
       " 'later': 1,\n",
       " 'Apparently': 1,\n",
       " 'chef': 3,\n",
       " 'unhappy': 1,\n",
       " 'entree': 3,\n",
       " 'he': 6,\n",
       " 'anew': 1,\n",
       " 'This': 8,\n",
       " 'isnt': 2,\n",
       " 'really': 17,\n",
       " 'problem': 2,\n",
       " 'should': 3,\n",
       " 'communicated': 1,\n",
       " 'For': 3,\n",
       " 'troubles': 1,\n",
       " 'comped': 1,\n",
       " 'glass': 2,\n",
       " 'wine': 4,\n",
       " 'forgot': 2,\n",
       " 'bring': 4,\n",
       " 'requested': 1,\n",
       " 'Also': 2,\n",
       " 'offer': 3,\n",
       " 'will': 7,\n",
       " 'echo': 1,\n",
       " 'lady': 1,\n",
       " 'who': 7,\n",
       " 'whispered': 1,\n",
       " 'her': 3,\n",
       " 'way': 5,\n",
       " 'ask': 3,\n",
       " 'warm': 4,\n",
       " 'foccacia': 1,\n",
       " 'apple': 2,\n",
       " 'walnut': 1,\n",
       " 'pomegranate': 1,\n",
       " 'wonder': 1,\n",
       " 'honey': 1,\n",
       " 'butter': 3,\n",
       " 'YUMThe': 1,\n",
       " 'solid': 1,\n",
       " 'quite': 5,\n",
       " 'live': 3,\n",
       " 'innovation': 1,\n",
       " 'freshness': 1,\n",
       " 'vegetables': 1,\n",
       " 'lambs': 1,\n",
       " 'meat': 3,\n",
       " 'tough': 1,\n",
       " 'Maybe': 2,\n",
       " 'vegetarian': 1,\n",
       " 'But': 4,\n",
       " 'dessert': 1,\n",
       " 'gingerbread': 1,\n",
       " 'pear': 1,\n",
       " 'cake': 1,\n",
       " 'yet': 2,\n",
       " 'another': 4,\n",
       " 'winnerIf': 1,\n",
       " 'tad': 1,\n",
       " 'inspired': 1,\n",
       " 'or': 14,\n",
       " 'service': 12,\n",
       " 'werent': 2,\n",
       " 'spotty': 1,\n",
       " 'definitely': 5,\n",
       " 'warranted': 1,\n",
       " 'five': 1,\n",
       " 'stars': 4,\n",
       " 'If': 6,\n",
       " 'return': 1,\n",
       " '75': 1,\n",
       " 'tasting': 2,\n",
       " 'bill': 1,\n",
       " '100': 1,\n",
       " 'two': 3,\n",
       " 'including': 2,\n",
       " 'tip': 1,\n",
       " 'drinks': 1,\n",
       " 'Drop': 1,\n",
       " 'youre': 4,\n",
       " 'doing': 3,\n",
       " 'drive': 1,\n",
       " 'After': 10,\n",
       " 'ate': 3,\n",
       " 'next': 9,\n",
       " 'day': 10,\n",
       " 'goodThis': 1,\n",
       " 'cute': 1,\n",
       " 'little': 12,\n",
       " 'green': 1,\n",
       " 'building': 1,\n",
       " 'may': 1,\n",
       " 'gone': 4,\n",
       " 'competely': 1,\n",
       " 'unoticed': 1,\n",
       " 'hadnt': 1,\n",
       " 'been': 13,\n",
       " 'driving': 1,\n",
       " 'down': 6,\n",
       " 'Palm': 1,\n",
       " 'Rd': 1,\n",
       " 'avoid': 1,\n",
       " 'construction': 1,\n",
       " 'While': 2,\n",
       " 'waiting': 5,\n",
       " 'turn': 2,\n",
       " 'onto': 1,\n",
       " '16th': 1,\n",
       " 'Street': 1,\n",
       " 'Grand': 1,\n",
       " 'Opening': 1,\n",
       " 'sign': 3,\n",
       " 'caught': 2,\n",
       " 'eye': 1,\n",
       " 'yelping': 1,\n",
       " 'soul': 1,\n",
       " 'leaped': 1,\n",
       " 'joy': 1,\n",
       " 'A': 5,\n",
       " 'new': 4,\n",
       " 'tryIt': 1,\n",
       " 'desolate': 1,\n",
       " 'opened': 2,\n",
       " 'easy': 2,\n",
       " 'decor': 2,\n",
       " 'smell': 1,\n",
       " 'cleanliness': 1,\n",
       " 'dinner': 7,\n",
       " 'loved': 2,\n",
       " 'seeing': 1,\n",
       " 'variety': 2,\n",
       " 'poblano': 1,\n",
       " 'peppers': 4,\n",
       " 'mole': 2,\n",
       " 'mahi': 4,\n",
       " 'mushroomssomething': 1,\n",
       " 'wrapped': 1,\n",
       " 'banana': 1,\n",
       " 'leaves': 1,\n",
       " 'difficult': 2,\n",
       " 'choose': 2,\n",
       " 'far': 2,\n",
       " 'La': 1,\n",
       " 'Condesa': 1,\n",
       " 'Shrimp': 2,\n",
       " 'Burro': 1,\n",
       " 'Baja': 1,\n",
       " 'Sur': 1,\n",
       " 'Dogfish': 1,\n",
       " 'Shark': 1,\n",
       " 'Taco': 1,\n",
       " 'meals': 1,\n",
       " 'shrimp': 1,\n",
       " 'burro': 1,\n",
       " 'stole': 1,\n",
       " 'flavor': 5,\n",
       " 'snagged': 1,\n",
       " 'bites': 1,\n",
       " 'hubbys': 1,\n",
       " 'burros': 1,\n",
       " 'mmmm': 1,\n",
       " 'such': 1,\n",
       " 'delight': 1,\n",
       " 'salsa': 6,\n",
       " 'bar': 7,\n",
       " 'endless': 2,\n",
       " 'stocked': 1,\n",
       " 'excited': 1,\n",
       " 'strawberry': 1,\n",
       " 'too': 12,\n",
       " 'hot': 8,\n",
       " 'fact': 1,\n",
       " 'big': 4,\n",
       " 'wimp': 1,\n",
       " 'horchata': 1,\n",
       " 'handmade': 1,\n",
       " 'throw': 3,\n",
       " 'pecans': 1,\n",
       " 'fruit': 2,\n",
       " 'there': 21,\n",
       " 'yummy': 3,\n",
       " 'bonusAs': 1,\n",
       " 'wasnt': 5,\n",
       " 'win': 2,\n",
       " 'art': 3,\n",
       " 'sho': 1,\n",
       " 'sucker': 2,\n",
       " 'Mexican': 4,\n",
       " 'folk': 1,\n",
       " 'Frida': 1,\n",
       " 'Kahlo': 1,\n",
       " 'Oprah': 1,\n",
       " 'Theres': 2,\n",
       " 'painting': 1,\n",
       " 'Diego': 1,\n",
       " 'hanging': 2,\n",
       " 'All': 5,\n",
       " 'paintings': 1,\n",
       " 'artist': 1,\n",
       " 'Luckily': 1,\n",
       " 'travel': 1,\n",
       " 'make': 5,\n",
       " 'connecting': 1,\n",
       " 'flight': 2,\n",
       " 'And': 4,\n",
       " 'thank': 1,\n",
       " 'PhoenixMy': 1,\n",
       " 'brief': 1,\n",
       " 'layover': 1,\n",
       " 'employees': 3,\n",
       " 'kind': 4,\n",
       " 'Hopefully': 1,\n",
       " 'grace': 1,\n",
       " 'Phoenix': 7,\n",
       " 'presence': 1,\n",
       " 'while': 5,\n",
       " 'longer': 3,\n",
       " 'Definitely': 1,\n",
       " 'come': 3,\n",
       " 'Happy': 1,\n",
       " 'hour': 1,\n",
       " 'Prices': 2,\n",
       " 'sake': 1,\n",
       " 'bombers': 1,\n",
       " '3Great': 1,\n",
       " 'atmosphere': 4,\n",
       " 'incredibly': 2,\n",
       " 'nice': 10,\n",
       " 'right': 2,\n",
       " 'needs': 3,\n",
       " 'thing': 4,\n",
       " 'spot': 2,\n",
       " 'onPlace': 1,\n",
       " 'gets': 1,\n",
       " 'especially': 1,\n",
       " 'plan': 2,\n",
       " 'wish': 2,\n",
       " 'Apollo': 1,\n",
       " 'Beach': 1,\n",
       " 'Brandon': 1,\n",
       " 'Nobuo': 1,\n",
       " 'shows': 1,\n",
       " 'unique': 1,\n",
       " 'talents': 1,\n",
       " 'Carefully': 1,\n",
       " 'crafted': 1,\n",
       " 'features': 1,\n",
       " 'Start': 1,\n",
       " 'belly': 1,\n",
       " 'buns': 1,\n",
       " 'stout': 1,\n",
       " 'Then': 2,\n",
       " 'oldish': 1,\n",
       " 'man': 2,\n",
       " 'owns': 1,\n",
       " 'store': 11,\n",
       " 'sweet': 6,\n",
       " 'Perhaps': 1,\n",
       " 'sweeter': 1,\n",
       " 'cookies': 3,\n",
       " 'ice': 9,\n",
       " 'creamHeres': 1,\n",
       " 'lowdown': 1,\n",
       " 'Giant': 1,\n",
       " 'cream': 11,\n",
       " 'cookie': 1,\n",
       " 'super': 3,\n",
       " 'cheap': 2,\n",
       " 'permutations': 1,\n",
       " 'basically': 1,\n",
       " 'snickerdoodle': 1,\n",
       " 'marvelous': 1,\n",
       " 'Wonderful': 1,\n",
       " 'Vietnamese': 1,\n",
       " 'sandwich': 12,\n",
       " 'shoppe': 1,\n",
       " 'Their': 2,\n",
       " 'baguettes': 1,\n",
       " 'oven': 1,\n",
       " 'choices': 1,\n",
       " 'modest': 1,\n",
       " 'goods': 1,\n",
       " 'along': 1,\n",
       " 'rolls': 1,\n",
       " 'around': 12,\n",
       " 'Bring': 1,\n",
       " 'cash': 1,\n",
       " 'ATM': 2,\n",
       " 'card': 1,\n",
       " 'credit': 1,\n",
       " 'cards': 1,\n",
       " 'accepted': 1,\n",
       " 'premises': 1,\n",
       " 'limited': 2,\n",
       " 'going': 8,\n",
       " 'now': 7,\n",
       " 'BBQ': 2,\n",
       " 'chicken': 9,\n",
       " 'last': 6,\n",
       " 'Probably': 1,\n",
       " 'THE': 1,\n",
       " 'Chicken': 3,\n",
       " 'other': 11,\n",
       " 'tomato': 3,\n",
       " 'basil': 1,\n",
       " 'soup': 2,\n",
       " 'every': 3,\n",
       " '5': 3,\n",
       " 'rate': 1,\n",
       " 'Jasons': 1,\n",
       " 'Deli': 1,\n",
       " '4': 3,\n",
       " 'Good': 4,\n",
       " 'tattoo': 1,\n",
       " 'shop': 1,\n",
       " 'Clean': 1,\n",
       " 'space': 1,\n",
       " 'multiple': 1,\n",
       " 'artists': 1,\n",
       " 'books': 1,\n",
       " 'work': 7,\n",
       " 'available': 1,\n",
       " 'look': 3,\n",
       " 'though': 5,\n",
       " 'decide': 2,\n",
       " 'whos': 1,\n",
       " 'style': 5,\n",
       " 'most': 3,\n",
       " 'mirrors': 1,\n",
       " 'looking': 5,\n",
       " 'chose': 2,\n",
       " 'Jet': 1,\n",
       " 'do': 3,\n",
       " 'coverup': 1,\n",
       " 'worked': 1,\n",
       " 'design': 1,\n",
       " 'ideas': 1,\n",
       " 'communication': 1,\n",
       " 'flowed': 1,\n",
       " 'Hes': 2,\n",
       " 'personable': 1,\n",
       " 'friendly': 8,\n",
       " 'keeps': 1,\n",
       " 'conversation': 2,\n",
       " 'hes': 1,\n",
       " 'working': 4,\n",
       " 'doesnt': 3,\n",
       " 'dick': 1,\n",
       " 'read': 4,\n",
       " 'He': 2,\n",
       " 'starts': 1,\n",
       " 'continues': 1,\n",
       " 'done': 1,\n",
       " 'professional': 2,\n",
       " 'informative': 1,\n",
       " 'combines': 1,\n",
       " 'talent': 1,\n",
       " 'craft': 1,\n",
       " 'weeks': 2,\n",
       " 'Irish': 1,\n",
       " 'bars': 1,\n",
       " 'town': 1,\n",
       " 'found': 1,\n",
       " 'Rosies': 1,\n",
       " 'ambience': 1,\n",
       " 'outstanding': 2,\n",
       " 'went': 9,\n",
       " 'myself': 3,\n",
       " 'Wednesday': 1,\n",
       " 'night': 3,\n",
       " 'hopes': 1,\n",
       " 'finding': 1,\n",
       " 'folks': 1,\n",
       " 'exactly': 2,\n",
       " 'happened': 1,\n",
       " 'Marcy': 1,\n",
       " 'bartender': 1,\n",
       " 'she': 6,\n",
       " 'helpful': 2,\n",
       " 'introduced': 1,\n",
       " 'whole': 5,\n",
       " 'bunch': 4,\n",
       " 'Rueben': 1,\n",
       " 'large': 3,\n",
       " 'side': 8,\n",
       " 'lettuce': 2,\n",
       " 'iceburg': 1,\n",
       " 'bacon': 2,\n",
       " 'toppings': 1,\n",
       " 'helped': 4,\n",
       " 'drank': 2,\n",
       " 'cold': 2,\n",
       " 'Smithwicks': 1,\n",
       " 'tap': 1,\n",
       " 'Followed': 1,\n",
       " 'vodka': 1,\n",
       " 'tonics': 1,\n",
       " 'tab': 1,\n",
       " 'under': 1,\n",
       " '25': 1,\n",
       " 'basketball': 1,\n",
       " 'game': 2,\n",
       " 'first': 3,\n",
       " 'jukebox': 1,\n",
       " 'playing': 1,\n",
       " 'fabulous': 2,\n",
       " 'mix': 1,\n",
       " 'oldies': 1,\n",
       " 'Around': 1,\n",
       " '10pm': 1,\n",
       " 'band': 1,\n",
       " 'played': 1,\n",
       " 'catch': 1,\n",
       " 'performance': 1,\n",
       " 'notice': 1,\n",
       " 'singers': 1,\n",
       " 'voice': 1,\n",
       " 'since': 6,\n",
       " 'typically': 1,\n",
       " 'care': 2,\n",
       " 'female': 1,\n",
       " 'vocalistsAll': 1,\n",
       " 'spoke': 2,\n",
       " 'welcoming': 1,\n",
       " 'am': 9,\n",
       " 'see': 7,\n",
       " 'again': 4,\n",
       " 'forward': 1,\n",
       " 'Was': 1,\n",
       " 'worth': 1,\n",
       " '21': 1,\n",
       " 'Absolutely': 1,\n",
       " 'Bad': 1,\n",
       " 'guys': 3,\n",
       " 'grandma': 1,\n",
       " 'died': 1,\n",
       " 'tell': 3,\n",
       " 'mad': 2,\n",
       " 'experience': 2,\n",
       " 'could': 5,\n",
       " 'cared': 1,\n",
       " 'less': 2,\n",
       " 'sat': 3,\n",
       " 'hmm': 1,\n",
       " 'theres': 1,\n",
       " 'saying': 2,\n",
       " 'x': 1,\n",
       " '23': 1,\n",
       " 'Wow': 1,\n",
       " 'told': 2,\n",
       " 'left': 1,\n",
       " 'hungry': 2,\n",
       " 'unsatisfied': 1,\n",
       " 'To': 1,\n",
       " 'owner': 1,\n",
       " 'teach': 1,\n",
       " 'value': 2,\n",
       " 'upselling': 1,\n",
       " 'telling': 1,\n",
       " 'specials': 3,\n",
       " 'Something': 1,\n",
       " 'affect': 1,\n",
       " 'customers': 2,\n",
       " 'negatively': 1,\n",
       " 'salads': 2,\n",
       " 'severely': 1,\n",
       " 'overpriced': 1,\n",
       " 'Wont': 1,\n",
       " 'unless': 1,\n",
       " 'desperate': 1,\n",
       " 'afternoon': 1,\n",
       " 'empty': 2,\n",
       " 'brunch': 1,\n",
       " 'bloody': 2,\n",
       " 'marys': 1,\n",
       " 'mimosas': 1,\n",
       " 'mood': 2,\n",
       " 'lunch': 9,\n",
       " 'Except': 1,\n",
       " 'mary': 1,\n",
       " 'highballsized': 1,\n",
       " 'Boo': 1,\n",
       " 'Yay': 1,\n",
       " 'hubby': 1,\n",
       " 'remembered': 1,\n",
       " 'few': 5,\n",
       " 'Arrogant': 1,\n",
       " 'Bastard': 1,\n",
       " '22': 1,\n",
       " 'oz': 1,\n",
       " 'bottle': 1,\n",
       " '475': 1,\n",
       " 'Hey': 1,\n",
       " 'fairNext': 1,\n",
       " 'wings': 4,\n",
       " 'bit': 8,\n",
       " 'hesitant': 1,\n",
       " 'informed': 1,\n",
       " 'seasoned': 1,\n",
       " 'sauced': 1,\n",
       " 'crispy': 3,\n",
       " 'asked': 3,\n",
       " 'cooks': 1,\n",
       " 'visibly': 1,\n",
       " 'These': 1,\n",
       " 'nontraditional': 1,\n",
       " 'actually': 1,\n",
       " 'damn': 1,\n",
       " 'seasoning': 1,\n",
       " 'spicy': 2,\n",
       " 'salty': 1,\n",
       " 'hint': 1,\n",
       " 'tang': 1,\n",
       " 'kick': 2,\n",
       " 'Franks': 1,\n",
       " 'Hot': 1,\n",
       " 'Sauce': 1,\n",
       " 'wouldnt': 2,\n",
       " 'cut': 1,\n",
       " 'otherwise': 1,\n",
       " 'forMy': 1,\n",
       " 'Tilapia': 1,\n",
       " 'disappointed': 3,\n",
       " 'fish': 5,\n",
       " 'dry': 2,\n",
       " 'uninspired': 1,\n",
       " 'greens': 2,\n",
       " 'underneath': 2,\n",
       " 'overdressed': 1,\n",
       " 'wilted': 1,\n",
       " 'picked': 2,\n",
       " 'almonds': 1,\n",
       " 'Mandarin': 1,\n",
       " 'oranges': 1,\n",
       " 'leave': 2,\n",
       " 'mush': 1,\n",
       " 'hiding': 1,\n",
       " 'fishIt': 1,\n",
       " 'wont': 2,\n",
       " 'anxiously': 1,\n",
       " 'awaiting': 1,\n",
       " 'trip': 1,\n",
       " 'okay': 3,\n",
       " 'EVER': 1,\n",
       " 'i': 7,\n",
       " 'grew': 1,\n",
       " 'shopping': 1,\n",
       " 'los': 1,\n",
       " 'gatos': 1,\n",
       " 'Oakville': 1,\n",
       " 'shock': 1,\n",
       " 'saw': 1,\n",
       " 'world': 1,\n",
       " 'then': 7,\n",
       " 'stuff': 8,\n",
       " 'cheese': 15,\n",
       " 'happy': 1,\n",
       " 'Arizona': 1,\n",
       " 'dean': 1,\n",
       " 'deluca': 1,\n",
       " 'met': 2,\n",
       " 'yesterday': 3,\n",
       " 'Loved': 1,\n",
       " 'water': 1,\n",
       " 'feature': 1,\n",
       " 'patio': 5,\n",
       " 'walking': 1,\n",
       " 'warmer': 1,\n",
       " 'Inside': 1,\n",
       " 'dark': 2,\n",
       " 'guess': 3,\n",
       " 'bats': 1,\n",
       " 'reminded': 1,\n",
       " 'Dusk': 1,\n",
       " 'Till': 1,\n",
       " 'Dawn': 1,\n",
       " 'hope': 1,\n",
       " 'hoping': 2,\n",
       " 'chips': 3,\n",
       " 'serve': 3,\n",
       " 'offered': 2,\n",
       " 'ones': 1,\n",
       " 'declined': 1,\n",
       " 'anyway': 4,\n",
       " 'complimentary': 1,\n",
       " 'Anyhow': 1,\n",
       " 'Fresh': 1,\n",
       " 'Snapper': 1,\n",
       " 'Tacos': 1,\n",
       " 'pics': 2,\n",
       " 'There': 4,\n",
       " 'being': 3,\n",
       " 'smothered': 1,\n",
       " 'those': 4,\n",
       " 'getFor': 1,\n",
       " '15': 1,\n",
       " 'TBSP': 1,\n",
       " 'each': 2,\n",
       " 'rice': 2,\n",
       " 'beans': 2,\n",
       " 'DEFINITELY': 1,\n",
       " 'teaspoon': 1,\n",
       " 'sour': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabras = pd.Series(palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GARBAGE': 2, 'I': 1, 'a': 1, 'have': 1, 'in': 1, 'my': 1}"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conteo_palabras_raras(\n",
    "    text = 'I have a snake in my boot',\n",
    "    col = df['text'],\n",
    "    umbral = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JeLaC3qZy1Ho"
   },
   "source": [
    "## Stemming\n",
    "\n",
    "Un problema del análisis simple que estamos viendo es que las diferentes variaciones de la misma palabra se cuentan como palabras separadas. Por ejemplo, \"flor\" y \"flores\" son símbolos técnicamente diferentes, y también lo son las palabras en inglés \"swimmer\", \"swimming\" y \"swim\", aunque tienen un significado muy parecido. Sería bueno si todas estas variaciones diferentes se asignaran a la misma palabra.\n",
    "\n",
    "Stemming es una técnica de NLP que intenta reducir cada palabra a su fomra más básica, su raíz. Existen diferentes enfoques. Algunos se basan en reglas lingüísticas, otros en estadísticas observadas. Una subclase de algoritmos incorpora el etiquetado de palabras y las reglas lingüísticas en un proceso conocido como lematización.\n",
    "\n",
    "La mayoría de las herramientas de stemming se centran en el idioma inglés, aunque se están realizando esfuerzos para otros idiomas, por lo que seguiremos con nuestros ejemplos en inglés. El lematizador Porter es la herramienta de lematización gratuita más utilizada para este idioma. El programa original está escrito en ANSI C, pero muchos otros paquetes implemntan un wrapper para proporcionar acceso a otros lenguajes.\n",
    "\n",
    "A continuación, se muestra un ejemplo de ejecución del lematizador Porter a través del paquete NLTK de Python. Como se puede observar, manejamos una gran cantidad de casos, pero no es perfecto. La palabra \"goes\" se asigna a \"goe\", mientras que \"go\" se asigna a sí misma:\n",
    "\n",
    "\n",
    "<!-- <img src=\"../../imagenes/imagen8.png\"> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flowers -> flower\n",
      "zeroes -> zero\n",
      "stemmer -> stemmer\n",
      "sixties -> sixti\n",
      "sixty -> sixti\n",
      "goes -> goe\n",
      "go -> go\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "print(f\"flowers -> {stemmer.stem('flowers')}\")\n",
    "print(f\"zeroes -> {stemmer.stem('zeroes')}\")\n",
    "print(f\"stemmer -> {stemmer.stem('stemmer')}\")\n",
    "print(f\"sixties -> {stemmer.stem('sixties')}\")\n",
    "print(f\"sixty -> {stemmer.stem('sixty')}\")\n",
    "print(f\"goes -> {stemmer.stem('goes')}\")\n",
    "print(f\"go -> {stemmer.stem('go')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO\n",
    "\n",
    "Crea una función que compare el significado de 2 palabras basándose en el stemmer y diga si tienen la misma raíz o no. Compruébalo con las palabras:\n",
    "  - \"saltar\" vs \"salto\"\n",
    "  - \"cantar\" vs \"canto\"\n",
    "  - \"azul\" vs \"rojo\"\n",
    "  \n",
    "Para ello, tendrás que usar un stemmer diferente, el SnowballStemmer, que puede ser utilziado para castellano, y el cual se utiliza como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'salt'"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "stemmer.stem(\"salto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raiz(palabra1, palabra2):\n",
    "    stemmer = SnowballStemmer('spanish')\n",
    "    \n",
    "    raiz1 = stemmer.stem(palabra1)\n",
    "    raiz2 = stemmer.stem(palabra2)\n",
    "    \n",
    "    if raiz1 == raiz2:\n",
    "        return f\"Su raíz {raiz1} es la misma\"\n",
    "    else:\n",
    "        return f\"La raíz {raiz1} es diferente a {raiz2}\"\n",
    "        \n",
    "sol = raiz(\"cantando\", \"cantaré\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Su raíz cant es la misma'"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LgSOAY6Py1Hp"
   },
   "source": [
    "Stemming tiene un costo de cálculo que hay que tener en cuenta. Si el beneficio final supera el costo o no, dependerá básicamente de la aplicación que se le vaya a dar. También vale la pena señalar que la reducción podría suponer un empeoramiento del sistema total en lugar de mejorar el rendimiento. Las palabras \"new\" y \"news\" tienen significados muy diferentes, pero ambas se derivarían de \"new\". Abundan los ejemplos similares. Por esta razón, no siempre se utiliza la derivación.\n",
    "\n",
    "\n",
    "## Átomos del significado: Palabras -> N-Grams -> Frases\n",
    "\n",
    "El concepto de _bag-of-words_ es sencillo. Pero, ¿cómo sabe una computadora qué es una palabra? Un documento de texto se representa digitalmente como una cadena, que es básicamente una secuencia de caracteres. También se puede encontrar texto semiestructurado en forma de JSON blobs o páginas HTML. Pero incluso con las etiquetas y la estructura agregadas, la unidad básica sigue siendo una cadena. ¿Cómo se convierte una cadena en una secuencia de palabras? Esto involucra las tareas de análisis y tokenización, que discutiremos a continuación.\n",
    "\n",
    "\n",
    "### _Parsing_ y Tokenización\n",
    "\n",
    "El _parsing_ es necesario cuando la cadena de texto contiene algo más que texto plano. Por ejemplo, si los datos sin procesar son una página web, un correo electrónico o un registro de algún tipo, entonces contienen alguna estructura adicional. Es necesario decidir cómo manejar el marcado, los encabezados y pies de página, o las secciones del log que no aporten información. Si el documento es una página web, el analizador debe manejar las URL. Si se trata de un correo electrónico, los campos como \"De\", \"Para\" y \"Asunto\" pueden requerir un manejo especial; de lo contrario, estos encabezados terminarán como palabras normales en el recuento final, que no es lo que queremos.\n",
    "\n",
    "Después de un parsing ligero, la parte de texto plano del documento puede pasar por la tokenización. Esto convierte la cadena (una secuencia de caracteres) en una secuencia de tokens. Cada uno de estos tokens se puede contar como una palabra. El tokenizador necesita saber qué caracteres indican que un token ha finalizado y otro está comenzando. Los caracteres de espacio suelen ser buenos separadores, al igual que los caracteres de puntuación. Si el texto contiene tweets, habrá que tener cuidado con las marcas e los hashtags (#), que no deben usarse como separadores (también conocidos como delimitadores).\n",
    "\n",
    "A veces, el análisis debe ser realizado a partir de frases u oraciones en vez de utilizar el documento completo. Por ejemplo, los n-gramas, una generalización del concepto de palabra, no debe extenderse más allá de los límites de las oraciones. Los métodos de caracterización de texto más complejos como ``word2vec`` también funcionan con frases u oraciones. En estos casos, primero es necesario analizar el documento en oraciones y luego convertir cada oración en palabras.\n",
    "\n",
    "Al hacer el ``split()`` de una cadena de texto también estamos haciendo una tokenización, pero como veremos, la función ``tokenize()`` nos aporta muchas más [ventajas](https://www.tothenew.com/blog/groovy-tokenize-vs-split/#:~:text=tokenize()%20%2Cwhich%20returns%20a,split()%20keeps%20such%20string.&text=The%20split()%20can%20take,where%20as%20tokenize%20does%20not.)\n",
    "\n",
    "\n",
    "### Collocation Extraction para la detección de frases\n",
    "\n",
    "Una secuencia de tokens produce una lista de palabras y n-gramas. Sin embargo, hablando semánticamente, estamos acostumbrados a comprender frases, no n-gramas. En el procesamiento de lenguaje natural (NLP), el concepto de una frase útil se llama ``collocation``. En palabras de Manning y Schütze (1999: 151), \"Una collocation es una expresión que consta de dos o más palabras que corresponden a alguna forma convencional de decir las cosas\".\n",
    "\n",
    "Las collocations son más significativas que la suma de sus partes. Por ejemplo, \"strong tea\" tiene un significado diferente más allá de \"great physical strength\" y \"tea\"; por lo tanto, se considera una collocation. La frase \"cute puppy\", por otro lado, significa exactamente la suma de sus partes: \"cute\" y \"puppy\". Por tanto, no se considera una collocation.\n",
    "\n",
    "Las collocations no tienen que ser secuencias consecutivas. Por ejemplo, se considera que la oración \"Emma knocked on the door\" contiene la colocación \"knock door\". Por tanto, no todas las collocations son n-gramas. Por el contrario, no todos los n-gramas se consideran una collocation significativa.\n",
    "\n",
    "Debido a que las collocations son más que la suma de sus partes, su significado no puede ser capturado adecuadamente por conteos de palabras individuales. La bag-of-words se queda corta como representación. La bag-of-n-grams- también es problemática ya que captura demasiadas secuencias sin sentido (considera \"this is\" en el ejemplo de la bolsa de n-gramas) y no suficientes de las significativas (como \"knock door).\n",
    "\n",
    "Las collocations son útiles como características. Pero, ¿cómo se descubren y se extraen del texto? Una forma es predefinirlos. Si nos esforzáramos mucho, probablemente podríamos encontrar listas completas de modismos en varios idiomas, y podríamos buscar en el texto cualquier coincidencia. Sería muy caro, pero funcionaría. Si el corpus es muy específico de un dominio y contiene jerga propia del mismo, este podría ser el método preferido. Pero la lista requeriría una gran cantidad de curación manual y tendría que actualizarse constantemente para los corpus en evolución. Por ejemplo, probablemente no sería muy realista para analizar tweets, blogs o artículos.\n",
    "\n",
    "Desde la llegada del NLP estadístico hace 2 décadas, la gente ha optado cada vez más por métodos estadísticos para encontrar frases. En lugar de establecer una lista fija de frases y refranes idiomáticos, los métodos de extracción de Collocation Extraction se basan en los datos en constante evolución para revelar los dichos populares del día.\n",
    "\n",
    "\n",
    "### Métodos basados en frecuencias\n",
    "\n",
    "Un truco simple es mirar los n-gramas que ocurren con mayor frecuencia. El problema con este enfoque es que los que ocurren con más frecuencia pueden no ser los más útiles. La siguiente tabla muestra los bigramas más populares (n = 2) en todo el conjunto de datos de reseñas de Yelp (el de 1,6 millones de registros, no nuestra muestra de 10 mil). Como podemos ver, los 10 bigramas más frecuentes por recuento de documentos son términos muy genéricos que no contienen mucho significado.\n",
    "\n",
    "\n",
    "<img src=\"../../imagenes/imagen9.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XKpifucIy1Hp"
   },
   "source": [
    "### Chunking y etiquetado de parte del texto (part-of-speech)\n",
    "\n",
    "\n",
    "Chunking es un poco más sofisticado que encontrar n-gramas, ya que forma secuencias de tokens basadas en partes del texto, utilizando modelos basados en reglas.\n",
    "\n",
    "Por ejemplo, podríamos estar más interesados en encontrar todas las frases nominales en un problema donde la entidad (en este caso, el tema de un texto) es la más interesante para nosotros. Para encontrar esto, tokenizamos cada palabra con una parte del texto y luego examinamos las posiciones vecinas del token para buscar agrupaciones de partes de texto, o \"chunks\". Los modelos que asignan palabras a partes del habla generalmente son específicos del idioma. Varias bibliotecas de Python de código abierto, como NLTK, spaCy y TextBlob, tienen varios modelos de lenguaje disponibles.\n",
    "\n",
    "Para ilustrar cómo varias bibliotecas en Python hacen que la fragmentación (chunking) mediante el etiquetado de part-of-speech sea bastante sencilla, usemos nuevamente el conjunto de datos de reseñas de Yelp. En el siguiente ejemplo, evaluamos las partes de la oración para encontrar las frases nominales usando spaCy y TextBlob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47428,
     "status": "ok",
     "timestamp": 1600932042153,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "ubFxtO5Yy1Hp",
    "outputId": "3c63dd4f-383c-496b-baaf-1a5054ea189d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>business_id</th>\n",
       "      <th>funny</th>\n",
       "      <th>useful</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>_eqQoPtQ3e3UxLE4faT6ow</td>\n",
       "      <td>Ubyfp2RSDYW0g7Mbr8N3iA</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-07-28</td>\n",
       "      <td>First visit...Had lunch here today - used my G...</td>\n",
       "      <td>review</td>\n",
       "      <td>VY_tvNUCCXGXQeSvJl757Q</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>ROru4uk5SaYc3rg8IU7SQw</td>\n",
       "      <td>2XyIOQKbVFb6uXQdJ0RzlQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-01-18</td>\n",
       "      <td>Should be called house of deliciousness!\\n\\nI ...</td>\n",
       "      <td>review</td>\n",
       "      <td>EKzMHI1tip8rC1-ZAy64yg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>gGbN1aKQHMgfQZkqlsuwzg</td>\n",
       "      <td>jyznYkIbpqVmlsZxSDSypA</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-11-16</td>\n",
       "      <td>I recently visited Olive and Ivy for business ...</td>\n",
       "      <td>review</td>\n",
       "      <td>53YGfwmbW73JhFiemNeyzQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0lyVoNazXa20WzUyZPLaQQ</td>\n",
       "      <td>5UKq9WQE1qQbJ0DJbc-B6Q</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-12-02</td>\n",
       "      <td>My nephew just moved to Scottsdale recently so...</td>\n",
       "      <td>review</td>\n",
       "      <td>9SKdOoDHcFoxK5ZtsgHJoA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>KSBFytcdjPKZgXKQnYQdkA</td>\n",
       "      <td>vWSmOhg2ID1MNZHaWapGbA</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-10-16</td>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>review</td>\n",
       "      <td>pF7uRzygyZsltbmVpjIyvw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user_id               review_id  stars        date  \\\n",
       "0     rLtl8ZkDX5vH5nAx9C3q5Q  fWKvX83p0-ka4JS3dc6E5A      5  2011-01-26   \n",
       "1     0a2KyEL0d3Yb1V6aivbIuQ  IjZ33sJrzXqU-0X6U8NwyA      5  2011-07-27   \n",
       "2     0hT2KtfLiobPvh6cDC8JQg  IESLBzqUCLdSzSqm0eCSxQ      4  2012-06-14   \n",
       "3     uZetl9T0NcROGOyFfughhg  G-WvGaISbqqaMHlNnByodA      5  2010-05-27   \n",
       "4     vYmM4KTsC8ZfQBg-j5MWkw  1uJFq2r5QfJG_6ExMRCaGw      5  2012-01-05   \n",
       "...                      ...                     ...    ...         ...   \n",
       "9995  _eqQoPtQ3e3UxLE4faT6ow  Ubyfp2RSDYW0g7Mbr8N3iA      3  2012-07-28   \n",
       "9996  ROru4uk5SaYc3rg8IU7SQw  2XyIOQKbVFb6uXQdJ0RzlQ      4  2012-01-18   \n",
       "9997  gGbN1aKQHMgfQZkqlsuwzg  jyznYkIbpqVmlsZxSDSypA      4  2010-11-16   \n",
       "9998  0lyVoNazXa20WzUyZPLaQQ  5UKq9WQE1qQbJ0DJbc-B6Q      2  2012-12-02   \n",
       "9999  KSBFytcdjPKZgXKQnYQdkA  vWSmOhg2ID1MNZHaWapGbA      5  2010-10-16   \n",
       "\n",
       "                                                   text    type  \\\n",
       "0     My wife took me here on my birthday for breakf...  review   \n",
       "1     I have no idea why some people give bad review...  review   \n",
       "2     love the gyro plate. Rice is so good and I als...  review   \n",
       "3     Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4     General Manager Scott Petello is a good egg!!!...  review   \n",
       "...                                                 ...     ...   \n",
       "9995  First visit...Had lunch here today - used my G...  review   \n",
       "9996  Should be called house of deliciousness!\\n\\nI ...  review   \n",
       "9997  I recently visited Olive and Ivy for business ...  review   \n",
       "9998  My nephew just moved to Scottsdale recently so...  review   \n",
       "9999  4-5 locations.. all 4.5 star average.. I think...  review   \n",
       "\n",
       "                 business_id  funny  useful  cool  \n",
       "0     9yKzy9PApeiPPOUJEtnvkg      0       5     2  \n",
       "1     ZRJwVLyzEJq1VAihDhYiow      0       0     0  \n",
       "2     6oRAC4uyJCsJl1X0WZpVSA      0       1     0  \n",
       "3     _1QQZuf4zZOyFCvXc0o6Vg      0       2     1  \n",
       "4     6ozycU1RpktNG2-1BroVtw      0       0     0  \n",
       "...                      ...    ...     ...   ...  \n",
       "9995  VY_tvNUCCXGXQeSvJl757Q      0       2     1  \n",
       "9996  EKzMHI1tip8rC1-ZAy64yg      0       0     0  \n",
       "9997  53YGfwmbW73JhFiemNeyzQ      0       0     0  \n",
       "9998  9SKdOoDHcFoxK5ZtsgHJoA      0       0     0  \n",
       "9999  pF7uRzygyZsltbmVpjIyvw      0       0     0  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"yelp_academic_dataset_review.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "he56IUUfy1Hs"
   },
   "source": [
    "### Usando spaCy: \n",
    "\n",
    "Para usar spaCy tendremos que realizar su [instalación](https://spacy.io/docs/usage/) previa. En este caso, debería bastar con descomentar y ejecutar las siguientes celdas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47418,
     "status": "ok",
     "timestamp": 1600932042154,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "Ss9_u5wfy1Hs"
   },
   "outputs": [],
   "source": [
    "# !pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Loading compatibility table...\n",
      "/ Loading compatibility table...\n",
      "- Loading compatibility table...\n",
      "\\ Loading compatibility table...\n",
      "| Loading compatibility table...\n",
      "\u001b[2K[+] Loaded compatibility table\n",
      "\u001b[1m\n",
      "====================== Installed models (spaCy v2.3.5) ======================\u001b[0m\n",
      "[i] spaCy installation: C:\\Users\\TheBridge\\anaconda3\\lib\\site-packages\\spacy\n",
      "\n",
      "TYPE      NAME             MODEL            VERSION            \n",
      "package   en-core-web-sm   en_core_web_sm   2.2.0     --> 2.3.1\n",
      "\n",
      "\u001b[1m\n",
      "============================== Install updates ==============================\u001b[0m\n",
      "Use the following commands to update the model packages:\n",
      "python -m spacy download en_core_web_sm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !python -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.3.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from en_core_web_sm==2.3.1) (2.3.5)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.18.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.47.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (49.2.0.post20200714)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py): started\n",
      "  Building wheel for en-core-web-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047114 sha256=539469e2846ea14a9a802d45b691e71a2febc16c6e5584201147e7d133202e97\n",
      "  Stored in directory: C:\\Users\\TheBridge\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-77y7v1dv\\wheels\\ee\\4d\\f7\\563214122be1540b5f9197b52cb3ddb9c4a8070808b22d5a84\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Attempting uninstall: en-core-web-sm\n",
      "    Found existing installation: en-core-web-sm 2.2.0\n",
      "    Uninstalling en-core-web-sm-2.2.0:\n",
      "      Successfully uninstalled en-core-web-sm-2.2.0\n",
      "Successfully installed en-core-web-sm-2.3.1\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todo ha ido correctamente, podremos importar la librería y empezar a trabajar con ella, como pone su [documentación]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48198,
     "status": "ok",
     "timestamp": 1600932042940,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "z5h0B-wek36Y"
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49349,
     "status": "ok",
     "timestamp": 1600932044096,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "ZhJPJ7rPk36d"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 49340,
     "status": "ok",
     "timestamp": 1600932044097,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "rdXZbLgMy1Hu",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "eec8243f-5570-494b-c72b-3484ced876d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "===================== Info about model 'en_core_web_sm' =====================\u001b[0m\n",
      "\n",
      "lang             en                            \n",
      "name             core_web_sm                   \n",
      "license          MIT                           \n",
      "author           Explosion                     \n",
      "url              https://explosion.ai          \n",
      "email            contact@explosion.ai          \n",
      "description      English multi-task CNN trained on OntoNotes. Assigns context-specific token vectors, POS tags, dependency parse and named entities.\n",
      "sources          [{'name': 'OntoNotes 5', 'url': 'https://catalog.ldc.upenn.edu/LDC2013T19', 'license': 'commercial (licensed by Explosion)'}]\n",
      "pipeline         ['tagger', 'parser', 'ner']   \n",
      "version          2.3.1                         \n",
      "spacy_version    >=2.3.0,<2.4.0                \n",
      "parent_package   spacy                         \n",
      "labels           {'tagger': ['$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'ADD', 'AFX', 'CC', 'CD', 'DT', 'EX', 'FW', 'HYPH', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NFP', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', 'XX', '_SP', '``'], 'parser': ['ROOT', 'acl', 'acomp', 'advcl', 'advmod', 'agent', 'amod', 'appos', 'attr', 'aux', 'auxpass', 'case', 'cc', 'ccomp', 'compound', 'conj', 'csubj', 'csubjpass', 'dative', 'dep', 'det', 'dobj', 'expl', 'intj', 'mark', 'meta', 'neg', 'nmod', 'npadvmod', 'nsubj', 'nsubjpass', 'nummod', 'oprd', 'parataxis', 'pcomp', 'pobj', 'poss', 'preconj', 'predet', 'prep', 'prt', 'punct', 'quantmod', 'relcl', 'xcomp'], 'ner': ['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART']}\n",
      "source           C:\\Users\\TheBridge\\anaconda3\\lib\\site-packages\\en_core_web_sm\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lang': 'en',\n",
       " 'name': 'core_web_sm',\n",
       " 'license': 'MIT',\n",
       " 'author': 'Explosion',\n",
       " 'url': 'https://explosion.ai',\n",
       " 'email': 'contact@explosion.ai',\n",
       " 'description': 'English multi-task CNN trained on OntoNotes. Assigns context-specific token vectors, POS tags, dependency parse and named entities.',\n",
       " 'sources': [{'name': 'OntoNotes 5',\n",
       "   'url': 'https://catalog.ldc.upenn.edu/LDC2013T19',\n",
       "   'license': 'commercial (licensed by Explosion)'}],\n",
       " 'pipeline': ['tagger', 'parser', 'ner'],\n",
       " 'version': '2.3.1',\n",
       " 'spacy_version': '>=2.3.0,<2.4.0',\n",
       " 'parent_package': 'spacy',\n",
       " 'accuracy': {'las': 89.7572754092,\n",
       "  'uas': 91.6570115569,\n",
       "  'token_acc': 99.756964111,\n",
       "  'las_per_type': {'advmod': {'p': 85.6065101297,\n",
       "    'r': 84.9512113055,\n",
       "    'f': 85.2776018577},\n",
       "   'aux': {'p': 97.9464841319, 'r': 98.0772654442, 'f': 98.0118311613},\n",
       "   'nsubj': {'p': 95.530627567, 'r': 94.7522887555, 'f': 95.1398662913},\n",
       "   'root': {'p': 89.5162856958, 'r': 91.1692936754, 'f': 90.3352283866},\n",
       "   'compound': {'p': 90.4871122761, 'r': 92.2811316552, 'f': 91.3753170839},\n",
       "   'poss': {'p': 97.0346623923, 'r': 97.4838969404, 'f': 97.2587609198},\n",
       "   'case': {'p': 97.927972373, 'r': 99.3493493493, 'f': 98.6335403727},\n",
       "   'dobj': {'p': 92.4513496547, 'r': 93.8729981675, 'f': 93.1567503459},\n",
       "   'prep': {'p': 85.6642170718, 'r': 86.2427438631, 'f': 85.9525069954},\n",
       "   'pobj': {'p': 96.0694769711, 'r': 96.6428459243, 'f': 96.3553084873},\n",
       "   'relcl': {'p': 76.5768958186, 'r': 78.3538796229, 'f': 77.4551971326},\n",
       "   'det': {'p': 97.7105145232, 'r': 97.7901904024, 'f': 97.7503362269},\n",
       "   'amod': {'p': 91.5748754262, 'r': 90.4891480402, 'f': 91.0287743996},\n",
       "   'attr': {'p': 90.4294478528, 'r': 92.9772918419, 'f': 91.6856728177},\n",
       "   'cc': {'p': 83.8244137102, 'r': 83.3532647692, 'f': 83.5881753313},\n",
       "   'mark': {'p': 90.3421052632, 'r': 90.9644939057, 'f': 90.6522313177},\n",
       "   'nmod': {'p': 76.3772954925, 'r': 55.7586837294, 'f': 64.4593166608},\n",
       "   'conj': {'p': 76.8877867328, 'r': 78.0490874764, 'f': 77.4640849469},\n",
       "   'advcl': {'p': 68.9203354298, 'r': 66.2301687232, 'f': 67.548478233},\n",
       "   'pcomp': {'p': 85.2515506547, 'r': 86.6246498599, 'f': 85.9326154915},\n",
       "   'nummod': {'p': 93.1951089846, 'r': 88.5353535354, 'f': 90.8054908055},\n",
       "   'nsubjpass': {'p': 92.4265842349, 'r': 92.0, 'f': 92.2127987664},\n",
       "   'quantmod': {'p': 85.3463587922, 'r': 78.0666125102, 'f': 81.5443360204},\n",
       "   'auxpass': {'p': 94.7204968944, 'r': 97.2665148064, 'f': 95.9766239604},\n",
       "   'ccomp': {'p': 79.9260844194, 'r': 83.6863543788, 'f': 81.7630086559},\n",
       "   'npadvmod': {'p': 76.8636539204, 'r': 70.6927175844, 'f': 73.6491487787},\n",
       "   'appos': {'p': 70.0960219479, 'r': 66.5075921909, 'f': 68.2546749777},\n",
       "   'neg': {'p': 94.5082376435, 'r': 94.9824385349, 'f': 94.7447447447},\n",
       "   'xcomp': {'p': 88.2854100106, 'r': 89.2677674085, 'f': 88.7738711405},\n",
       "   'predet': {'p': 85.2459016393, 'r': 89.2703862661, 'f': 87.2117400419},\n",
       "   'acomp': {'p': 90.3553299492, 'r': 88.717716357, 'f': 89.529035208},\n",
       "   'acl': {'p': 75.6578947368, 'r': 69.012547736, 'f': 72.182596291},\n",
       "   'oprd': {'p': 81.0810810811, 'r': 71.6417910448, 'f': 76.0697305864},\n",
       "   'dative': {'p': 73.9659367397, 'r': 69.7247706422, 'f': 71.7827626919},\n",
       "   'agent': {'p': 88.5328836425, 'r': 94.0860215054, 'f': 91.2250217202},\n",
       "   'meta': {'p': 94.7368421053, 'r': 34.615384615400004, 'f': 50.7042253521},\n",
       "   'dep': {'p': 40.329218107, 'r': 15.9090909091, 'f': 22.8172293364},\n",
       "   'prt': {'p': 81.9166666667, 'r': 88.082437276, 'f': 84.8877374784},\n",
       "   'expl': {'p': 98.3014861996, 'r': 99.1434689507, 'f': 98.7206823028},\n",
       "   'parataxis': {'p': 63.9240506329, 'r': 43.8177874187, 'f': 51.9948519949},\n",
       "   'intj': {'p': 69.387755102, 'r': 59.7802197802, 'f': 64.2266824085},\n",
       "   'csubj': {'p': 70.5882352941, 'r': 71.0059171598, 'f': 70.796460177},\n",
       "   'preconj': {'p': 57.4468085106, 'r': 62.7906976744, 'f': 60.0},\n",
       "   'csubjpass': {'p': 44.4444444444, 'r': 66.6666666667, 'f': 53.3333333333}},\n",
       "  'tags_acc': 97.056555292,\n",
       "  'ents_f': 85.4306864065,\n",
       "  'ents_p': 85.7239322492,\n",
       "  'ents_r': 85.1394400045,\n",
       "  'ents_per_type': {'ORG': {'p': 83.3194096352,\n",
       "    'r': 82.8808864266,\n",
       "    'f': 83.0995695042},\n",
       "   'CARDINAL': {'p': 83.9554682384, 'r': 86.32996633, 'f': 85.1261620186},\n",
       "   'DATE': {'p': 84.6522781775, 'r': 86.1275705821, 'f': 85.3835521769},\n",
       "   'GPE': {'p': 92.5831202046, 'r': 90.2180685358, 'f': 91.3852950458},\n",
       "   'PERSON': {'p': 88.0239520958, 'r': 92.0908379013, 'f': 90.0114810563},\n",
       "   'MONEY': {'p': 92.9181929182, 'r': 91.4663461538, 'f': 92.1865536039},\n",
       "   'PRODUCT': {'p': 52.1276595745, 'r': 24.1379310345, 'f': 32.9966329966},\n",
       "   'TIME': {'p': 70.1886792453, 'r': 70.9923664122, 'f': 70.5882352941},\n",
       "   'PERCENT': {'p': 91.8566775244, 'r': 88.125, 'f': 89.95215311},\n",
       "   'WORK_OF_ART': {'p': 48.1481481481, 'r': 38.8059701493, 'f': 42.9752066116},\n",
       "   'QUANTITY': {'p': 78.1954887218, 'r': 65.4088050314, 'f': 71.2328767123},\n",
       "   'NORP': {'p': 88.682581786, 'r': 89.2348754448, 'f': 88.9578713969},\n",
       "   'LOC': {'p': 70.8154506438, 'r': 66.0, 'f': 68.3229813665},\n",
       "   'EVENT': {'p': 63.2911392405, 'r': 37.037037037, 'f': 46.7289719626},\n",
       "   'ORDINAL': {'p': 80.0, 'r': 83.9694656489, 'f': 81.9366852886},\n",
       "   'FAC': {'p': 34.8623853211, 'r': 46.9135802469, 'f': 40.0},\n",
       "   'LAW': {'p': 62.962962963, 'r': 56.6666666667, 'f': 59.649122807},\n",
       "   'LANGUAGE': {'p': 75.0, 'r': 65.2173913043, 'f': 69.7674418605}}},\n",
       " 'speed': {'cpu': 6107.3535050376, 'gpu': None, 'nwords': 291315},\n",
       " 'labels': {'tagger': ['$',\n",
       "   \"''\",\n",
       "   ',',\n",
       "   '-LRB-',\n",
       "   '-RRB-',\n",
       "   '.',\n",
       "   ':',\n",
       "   'ADD',\n",
       "   'AFX',\n",
       "   'CC',\n",
       "   'CD',\n",
       "   'DT',\n",
       "   'EX',\n",
       "   'FW',\n",
       "   'HYPH',\n",
       "   'IN',\n",
       "   'JJ',\n",
       "   'JJR',\n",
       "   'JJS',\n",
       "   'LS',\n",
       "   'MD',\n",
       "   'NFP',\n",
       "   'NN',\n",
       "   'NNP',\n",
       "   'NNPS',\n",
       "   'NNS',\n",
       "   'PDT',\n",
       "   'POS',\n",
       "   'PRP',\n",
       "   'PRP$',\n",
       "   'RB',\n",
       "   'RBR',\n",
       "   'RBS',\n",
       "   'RP',\n",
       "   'SYM',\n",
       "   'TO',\n",
       "   'UH',\n",
       "   'VB',\n",
       "   'VBD',\n",
       "   'VBG',\n",
       "   'VBN',\n",
       "   'VBP',\n",
       "   'VBZ',\n",
       "   'WDT',\n",
       "   'WP',\n",
       "   'WP$',\n",
       "   'WRB',\n",
       "   'XX',\n",
       "   '_SP',\n",
       "   '``'],\n",
       "  'parser': ['ROOT',\n",
       "   'acl',\n",
       "   'acomp',\n",
       "   'advcl',\n",
       "   'advmod',\n",
       "   'agent',\n",
       "   'amod',\n",
       "   'appos',\n",
       "   'attr',\n",
       "   'aux',\n",
       "   'auxpass',\n",
       "   'case',\n",
       "   'cc',\n",
       "   'ccomp',\n",
       "   'compound',\n",
       "   'conj',\n",
       "   'csubj',\n",
       "   'csubjpass',\n",
       "   'dative',\n",
       "   'dep',\n",
       "   'det',\n",
       "   'dobj',\n",
       "   'expl',\n",
       "   'intj',\n",
       "   'mark',\n",
       "   'meta',\n",
       "   'neg',\n",
       "   'nmod',\n",
       "   'npadvmod',\n",
       "   'nsubj',\n",
       "   'nsubjpass',\n",
       "   'nummod',\n",
       "   'oprd',\n",
       "   'parataxis',\n",
       "   'pcomp',\n",
       "   'pobj',\n",
       "   'poss',\n",
       "   'preconj',\n",
       "   'predet',\n",
       "   'prep',\n",
       "   'prt',\n",
       "   'punct',\n",
       "   'quantmod',\n",
       "   'relcl',\n",
       "   'xcomp'],\n",
       "  'ner': ['CARDINAL',\n",
       "   'DATE',\n",
       "   'EVENT',\n",
       "   'FAC',\n",
       "   'GPE',\n",
       "   'LANGUAGE',\n",
       "   'LAW',\n",
       "   'LOC',\n",
       "   'MONEY',\n",
       "   'NORP',\n",
       "   'ORDINAL',\n",
       "   'ORG',\n",
       "   'PERCENT',\n",
       "   'PERSON',\n",
       "   'PRODUCT',\n",
       "   'QUANTITY',\n",
       "   'TIME',\n",
       "   'WORK_OF_ART']},\n",
       " 'source': 'C:\\\\Users\\\\TheBridge\\\\anaconda3\\\\lib\\\\site-packages\\\\en_core_web_sm'}"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model meta data\n",
    "spacy.info('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       M\n",
       "1       I\n",
       "2       l\n",
       "3       R\n",
       "4       G\n",
       "       ..\n",
       "9995    F\n",
       "9996    S\n",
       "9997    I\n",
       "9998    M\n",
       "9999    4\n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x[0]\n",
    "\n",
    "df['text'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'took'"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_df[0][2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49325,
     "status": "ok",
     "timestamp": 1600932044102,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "Crcw9hW2y1Hy",
    "outputId": "80f605e5-5c7a-4fa5-ec1a-fe7cecb0e062"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keeping it in a pandas dataframe\n",
    "doc_df = df['text'].apply(nlp)\n",
    "\n",
    "type(doc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49693,
     "status": "ok",
     "timestamp": 1600932044483,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "ptcmeIO-y1Hz",
    "outputId": "ccd56103-25c4-4066-897c-81f4bdfaddee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49681,
     "status": "ok",
     "timestamp": 1600932044483,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "zBOS4XxBk362",
    "outputId": "819e7428-794f-4a51-ec54-cfa7826227d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rosie, Dakota, and I LOVE Chaparral Dog Park!!! It's very convenient and surrounded by a lot of paths, a desert xeriscape, baseball fields, ballparks, and a lake with ducks.\n",
       "\n",
       "The Scottsdale Park and Rec Dept. does a wonderful job of keeping the park clean and shaded.  You can find trash cans and poopy-pick up mitts located all over the park and paths.\n",
       "\n",
       "The fenced in area is huge to let the dogs run, play, and sniff!"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_df[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este objeto nos viene muy bien por lo que nos permite hacer con él, que nos detallará, en función de sus atributos:\n",
    "  - ``text``: string con la partícula de texto en sí\n",
    "  - ``pos_``: análisis sintáctico a primer nivel de esa palabra (sustantivo, adjetivo, determinante...)\n",
    "  - ``tag_``: complemento a ``pos_``, detalla con mayor precisión el análisis de la palabra\n",
    "\n",
    "Para más detalle de cómo interpretar los resultados, accede a este [enlace](https://ashutoshtripathi.com/2020/04/13/parts-of-speech-tagging-and-dependency-parsing-using-spacy-nlp/#Fine-grained-Part-of-speech-Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 49670,
     "status": "ok",
     "timestamp": 1600932044484,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "yBh2DQmny1H4",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "1cfd36cd-2b67-45be-d7e5-ed339147013d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General PROPN NNP\n",
      "Manager PROPN NNP\n",
      "Scott PROPN NNP\n",
      "Petello PROPN NNP\n",
      "is AUX VBZ\n",
      "a DET DT\n",
      "good ADJ JJ\n",
      "egg NOUN NN\n",
      "! PUNCT .\n",
      "! PUNCT .\n",
      "! PUNCT .\n",
      "Not PART RB\n",
      "to PART TO\n",
      "go VERB VB\n",
      "into ADP IN\n",
      "detail NOUN NN\n",
      ", PUNCT ,\n",
      "but CCONJ CC\n",
      "let VERB VB\n",
      "me PRON PRP\n",
      "assure VERB VB\n",
      "you PRON PRP\n",
      "if SCONJ IN\n",
      "you PRON PRP\n",
      "have AUX VBP\n",
      "any DET DT\n",
      "issues NOUN NNS\n",
      "( PUNCT -LRB-\n",
      "albeit SCONJ IN\n",
      "rare ADJ JJ\n",
      ") PUNCT -RRB-\n",
      "speak VERB VBP\n",
      "with ADP IN\n",
      "Scott PROPN NNP\n",
      "and CCONJ CC\n",
      "treat VERB VB\n",
      "the DET DT\n",
      "guy NOUN NN\n",
      "with ADP IN\n",
      "some DET DT\n",
      "respect NOUN NN\n",
      "as SCONJ IN\n",
      "you PRON PRP\n",
      "state VERB VBP\n",
      "your DET PRP$\n",
      "case NOUN NN\n",
      "and CCONJ CC\n",
      "I PRON PRP\n",
      "'d VERB MD\n",
      "be AUX VB\n",
      "surprised ADJ JJ\n",
      "if SCONJ IN\n",
      "you PRON PRP\n",
      "do AUX VBP\n",
      "n't PART RB\n",
      "walk VERB VB\n",
      "out ADP RP\n",
      "totally ADV RB\n",
      "satisfied ADJ JJ\n",
      "as SCONJ IN\n",
      "I PRON PRP\n",
      "just ADV RB\n",
      "did AUX VBD\n",
      ". PUNCT .\n",
      "Like INTJ UH\n",
      "I PRON PRP\n",
      "always ADV RB\n",
      "say VERB VBP\n",
      "..... PUNCT NFP\n",
      "\" PUNCT ``\n",
      "Mistakes NOUN NNS\n",
      "are AUX VBP\n",
      "inevitable ADJ JJ\n",
      ", PUNCT ,\n",
      "it PRON PRP\n",
      "'s AUX VBZ\n",
      "how ADV WRB\n",
      "we PRON PRP\n",
      "recover VERB VBP\n",
      "from ADP IN\n",
      "them PRON PRP\n",
      "that DET WDT\n",
      "is AUX VBZ\n",
      "important ADJ JJ\n",
      "\" PUNCT ''\n",
      "! PUNCT .\n",
      "! PUNCT .\n",
      "! PUNCT .\n",
      "\n",
      "\n",
      " SPACE _SP\n",
      "Thanks NOUN NNS\n",
      "to ADP IN\n",
      "Scott PROPN NNP\n",
      "and CCONJ CC\n",
      "his DET PRP$\n",
      "awesome ADJ JJ\n",
      "staff NOUN NN\n",
      ". PUNCT .\n",
      "You PRON PRP\n",
      "'ve AUX VB\n",
      "got VERB VBN\n",
      "a DET DT\n",
      "customer NOUN NN\n",
      "for ADP IN\n",
      "life NOUN NN\n",
      "! PUNCT .\n",
      "! PUNCT .\n",
      ".......... PUNCT NFP\n",
      ": PUNCT :\n",
      "^ PROPN NNP\n",
      ") PUNCT -RRB-\n"
     ]
    }
   ],
   "source": [
    "for doc in doc_df[4]:\n",
    "    print(doc.text, doc.pos_, doc.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O si queremos consultarlo directamente con la propia librería, podemos usar la función ``spacy.explain()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49657,
     "status": "ok",
     "timestamp": 1600932044484,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "FaC3G5Hck37F",
    "outputId": "ec23e333-eda5-489d-b807-bbd5950962cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun, proper singular'"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('NNP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, ``spaCy`` también se encargará por nosotros de trocear los textos en función del elemento que nosotros le digamos, como sacar los sustantivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49645,
     "status": "ok",
     "timestamp": 1600932044485,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "Hqvy2dtby1H5",
    "outputId": "acb58a04-6810-4298-90d2-92b1e3e715eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[General Manager Scott Petello, a good egg, detail, me, you, you, any issues, Scott, the guy, some respect, you, your case, I, you, I, I, Mistakes, it, we, them, Thanks, Scott, his awesome staff, You, a customer, life, :^]\n"
     ]
    }
   ],
   "source": [
    "# spaCy also does noun chunking for us\n",
    "\n",
    "print([chunk for chunk in doc_df[4].noun_chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por si fuera poco, también tenemos un objeto para visualizar las relaciones entre palabras que nos haya detectado, explicado con más detalle en la [documentación](https://spacy.io/usage/visualizers):\n",
    "\n",
    "_NOTA: Con el visualizador, el kernel se queda trabajando de continuo hasta que le demos al botón de stop de la barra de ayuda de arriba del todo)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"b0fde0a1dc444395aa533e71ddb1eeba-0\" class=\"displacy\" width=\"15800\" height=\"749.5\" direction=\"ltr\" style=\"max-width: none; height: 749.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">General</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Manager</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Scott</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Petello</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">good</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">egg!!!</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">Not</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">go</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">into</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">detail,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">but</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">let</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">me</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">assure</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">you</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">if</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">you</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">have</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">any</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">issues (</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">albeit</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">rare)</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">speak</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4600\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4600\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4775\">Scott</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4775\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4950\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4950\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5125\">treat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5125\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5300\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5300\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5475\">guy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5475\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5650\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5650\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5825\">some</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5825\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6000\">respect</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6000\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6175\">as</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6175\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6350\">you</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6350\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6525\">state</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6525\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6700\">your</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6700\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6875\">case</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6875\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7050\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7050\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7225\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7225\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7400\">'d</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7575\">be</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7575\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7750\">surprised</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7750\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7925\">if</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7925\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"8100\">you</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"8100\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"8275\">do</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"8275\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"8450\">n't</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"8450\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"8625\">walk</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"8625\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"8800\">out</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"8800\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"8975\">totally</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"8975\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"9150\">satisfied</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"9150\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"9325\">as</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"9325\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"9500\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"9500\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"9675\">just</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"9675\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"9850\">did.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"9850\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"10025\">Like</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"10025\">INTJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"10200\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"10200\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"10375\">always</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"10375\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"10550\">say..... &quot;</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"10550\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"10725\">Mistakes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"10725\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"10900\">are</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"10900\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"11075\">inevitable,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"11075\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"11250\">it</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"11250\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"11425\">'s</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"11425\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"11600\">how</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"11600\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"11775\">we</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"11775\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"11950\">recover</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"11950\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"12125\">from</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"12125\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"12300\">them</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"12300\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"12475\">that</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"12475\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"12650\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"12650\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"12825\">important&quot;!!!</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"12825\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"13000\">\n",
       "\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"13000\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"13175\">Thanks</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"13175\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"13350\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"13350\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"13525\">Scott</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"13525\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"13700\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"13700\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"13875\">his</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"13875\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"14050\">awesome</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"14050\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"14225\">staff.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"14225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"14400\">You</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"14400\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"14575\">'ve</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"14575\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"14750\">got</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"14750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"14925\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"14925\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"15100\">customer</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"15100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"15275\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"15275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"15450\">life!! .......... :</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"15450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"15625\">^)</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"15625\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-0\" stroke-width=\"2px\" d=\"M70,614.5 C70,527.0 195.0,527.0 195.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,616.5 L62,604.5 78,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-1\" stroke-width=\"2px\" d=\"M245,614.5 C245,439.5 550.0,439.5 550.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,616.5 L237,604.5 253,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-2\" stroke-width=\"2px\" d=\"M420,614.5 C420,527.0 545.0,527.0 545.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,616.5 L412,604.5 428,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-3\" stroke-width=\"2px\" d=\"M595,614.5 C595,527.0 720.0,527.0 720.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,616.5 L587,604.5 603,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-4\" stroke-width=\"2px\" d=\"M945,614.5 C945,439.5 1250.0,439.5 1250.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,616.5 L937,604.5 953,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-5\" stroke-width=\"2px\" d=\"M1120,614.5 C1120,527.0 1245.0,527.0 1245.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,616.5 L1112,604.5 1128,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-6\" stroke-width=\"2px\" d=\"M770,614.5 C770,352.0 1255.0,352.0 1255.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1255.0,616.5 L1263.0,604.5 1247.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-7\" stroke-width=\"2px\" d=\"M1470,614.5 C1470,439.5 1775.0,439.5 1775.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,616.5 L1462,604.5 1478,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-8\" stroke-width=\"2px\" d=\"M1645,614.5 C1645,527.0 1770.0,527.0 1770.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,616.5 L1637,604.5 1653,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-9\" stroke-width=\"2px\" d=\"M1820,614.5 C1820,527.0 1945.0,527.0 1945.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1945.0,616.5 L1953.0,604.5 1937.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-10\" stroke-width=\"2px\" d=\"M1995,614.5 C1995,527.0 2120.0,527.0 2120.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2120.0,616.5 L2128.0,604.5 2112.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-11\" stroke-width=\"2px\" d=\"M1820,614.5 C1820,352.0 2305.0,352.0 2305.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2305.0,616.5 L2313.0,604.5 2297.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-12\" stroke-width=\"2px\" d=\"M1820,614.5 C1820,264.5 2485.0,264.5 2485.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2485.0,616.5 L2493.0,604.5 2477.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-13\" stroke-width=\"2px\" d=\"M2695,614.5 C2695,527.0 2820.0,527.0 2820.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2695,616.5 L2687,604.5 2703,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-14\" stroke-width=\"2px\" d=\"M2520,614.5 C2520,439.5 2825.0,439.5 2825.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2825.0,616.5 L2833.0,604.5 2817.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-15\" stroke-width=\"2px\" d=\"M2870,614.5 C2870,527.0 2995.0,527.0 2995.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2995.0,616.5 L3003.0,604.5 2987.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-16\" stroke-width=\"2px\" d=\"M3220,614.5 C3220,439.5 3525.0,439.5 3525.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3220,616.5 L3212,604.5 3228,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-17\" stroke-width=\"2px\" d=\"M3395,614.5 C3395,527.0 3520.0,527.0 3520.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3395,616.5 L3387,604.5 3403,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-18\" stroke-width=\"2px\" d=\"M2870,614.5 C2870,264.5 3535.0,264.5 3535.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3535.0,616.5 L3543.0,604.5 3527.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-19\" stroke-width=\"2px\" d=\"M3745,614.5 C3745,527.0 3870.0,527.0 3870.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3745,616.5 L3737,604.5 3753,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-20\" stroke-width=\"2px\" d=\"M3570,614.5 C3570,439.5 3875.0,439.5 3875.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3875.0,616.5 L3883.0,604.5 3867.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-21\" stroke-width=\"2px\" d=\"M4095,614.5 C4095,527.0 4220.0,527.0 4220.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4095,616.5 L4087,604.5 4103,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-22\" stroke-width=\"2px\" d=\"M3920,614.5 C3920,439.5 4225.0,439.5 4225.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4225.0,616.5 L4233.0,604.5 4217.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-23\" stroke-width=\"2px\" d=\"M3920,614.5 C3920,352.0 4405.0,352.0 4405.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4405.0,616.5 L4413.0,604.5 4397.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-24\" stroke-width=\"2px\" d=\"M4445,614.5 C4445,527.0 4570.0,527.0 4570.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4570.0,616.5 L4578.0,604.5 4562.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-25\" stroke-width=\"2px\" d=\"M4620,614.5 C4620,527.0 4745.0,527.0 4745.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4745.0,616.5 L4753.0,604.5 4737.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-26\" stroke-width=\"2px\" d=\"M4445,614.5 C4445,352.0 4930.0,352.0 4930.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4930.0,616.5 L4938.0,604.5 4922.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-27\" stroke-width=\"2px\" d=\"M4445,614.5 C4445,264.5 5110.0,264.5 5110.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-27\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5110.0,616.5 L5118.0,604.5 5102.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-28\" stroke-width=\"2px\" d=\"M5320,614.5 C5320,527.0 5445.0,527.0 5445.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-28\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5320,616.5 L5312,604.5 5328,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-29\" stroke-width=\"2px\" d=\"M5145,614.5 C5145,439.5 5450.0,439.5 5450.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-29\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5450.0,616.5 L5458.0,604.5 5442.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-30\" stroke-width=\"2px\" d=\"M5145,614.5 C5145,352.0 5630.0,352.0 5630.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-30\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5630.0,616.5 L5638.0,604.5 5622.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-31\" stroke-width=\"2px\" d=\"M5845,614.5 C5845,527.0 5970.0,527.0 5970.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-31\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5845,616.5 L5837,604.5 5853,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-32\" stroke-width=\"2px\" d=\"M5670,614.5 C5670,439.5 5975.0,439.5 5975.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-32\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5975.0,616.5 L5983.0,604.5 5967.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-33\" stroke-width=\"2px\" d=\"M6195,614.5 C6195,439.5 6500.0,439.5 6500.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-33\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M6195,616.5 L6187,604.5 6203,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-34\" stroke-width=\"2px\" d=\"M6370,614.5 C6370,527.0 6495.0,527.0 6495.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-34\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M6370,616.5 L6362,604.5 6378,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-35\" stroke-width=\"2px\" d=\"M5145,614.5 C5145,2.0 6525.0,2.0 6525.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-35\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M6525.0,616.5 L6533.0,604.5 6517.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-36\" stroke-width=\"2px\" d=\"M6720,614.5 C6720,527.0 6845.0,527.0 6845.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-36\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M6720,616.5 L6712,604.5 6728,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-37\" stroke-width=\"2px\" d=\"M6545,614.5 C6545,439.5 6850.0,439.5 6850.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-37\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M6850.0,616.5 L6858.0,604.5 6842.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-38\" stroke-width=\"2px\" d=\"M7070,614.5 C7070,352.0 7555.0,352.0 7555.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-38\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M7070,616.5 L7062,604.5 7078,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-39\" stroke-width=\"2px\" d=\"M7245,614.5 C7245,439.5 7550.0,439.5 7550.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-39\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M7245,616.5 L7237,604.5 7253,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-40\" stroke-width=\"2px\" d=\"M7420,614.5 C7420,527.0 7545.0,527.0 7545.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-40\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M7420,616.5 L7412,604.5 7428,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-41\" stroke-width=\"2px\" d=\"M7595,614.5 C7595,527.0 7720.0,527.0 7720.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-41\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M7720.0,616.5 L7728.0,604.5 7712.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-42\" stroke-width=\"2px\" d=\"M7945,614.5 C7945,264.5 8610.0,264.5 8610.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-42\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M7945,616.5 L7937,604.5 7953,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-43\" stroke-width=\"2px\" d=\"M8120,614.5 C8120,352.0 8605.0,352.0 8605.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-43\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M8120,616.5 L8112,604.5 8128,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-44\" stroke-width=\"2px\" d=\"M8295,614.5 C8295,439.5 8600.0,439.5 8600.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-44\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M8295,616.5 L8287,604.5 8303,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-45\" stroke-width=\"2px\" d=\"M8470,614.5 C8470,527.0 8595.0,527.0 8595.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-45\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M8470,616.5 L8462,604.5 8478,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-46\" stroke-width=\"2px\" d=\"M7595,614.5 C7595,177.0 8615.0,177.0 8615.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-46\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M8615.0,616.5 L8623.0,604.5 8607.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-47\" stroke-width=\"2px\" d=\"M8645,614.5 C8645,527.0 8770.0,527.0 8770.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-47\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prt</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M8770.0,616.5 L8778.0,604.5 8762.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-48\" stroke-width=\"2px\" d=\"M8995,614.5 C8995,527.0 9120.0,527.0 9120.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-48\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M8995,616.5 L8987,604.5 9003,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-49\" stroke-width=\"2px\" d=\"M8645,614.5 C8645,352.0 9130.0,352.0 9130.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-49\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M9130.0,616.5 L9138.0,604.5 9122.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-50\" stroke-width=\"2px\" d=\"M9345,614.5 C9345,352.0 9830.0,352.0 9830.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-50\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M9345,616.5 L9337,604.5 9353,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-51\" stroke-width=\"2px\" d=\"M9520,614.5 C9520,439.5 9825.0,439.5 9825.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-51\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M9520,616.5 L9512,604.5 9528,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-52\" stroke-width=\"2px\" d=\"M9695,614.5 C9695,527.0 9820.0,527.0 9820.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-52\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M9695,616.5 L9687,604.5 9703,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-53\" stroke-width=\"2px\" d=\"M8645,614.5 C8645,89.5 9845.0,89.5 9845.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-53\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M9845.0,616.5 L9853.0,604.5 9837.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-54\" stroke-width=\"2px\" d=\"M10045,614.5 C10045,352.0 10530.0,352.0 10530.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-54\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">intj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M10045,616.5 L10037,604.5 10053,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-55\" stroke-width=\"2px\" d=\"M10220,614.5 C10220,439.5 10525.0,439.5 10525.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-55\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M10220,616.5 L10212,604.5 10228,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-56\" stroke-width=\"2px\" d=\"M10395,614.5 C10395,527.0 10520.0,527.0 10520.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-56\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M10395,616.5 L10387,604.5 10403,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-57\" stroke-width=\"2px\" d=\"M10745,614.5 C10745,527.0 10870.0,527.0 10870.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-57\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M10745,616.5 L10737,604.5 10753,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-58\" stroke-width=\"2px\" d=\"M10920,614.5 C10920,352.0 11405.0,352.0 11405.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-58\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M10920,616.5 L10912,604.5 10928,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-59\" stroke-width=\"2px\" d=\"M10920,614.5 C10920,527.0 11045.0,527.0 11045.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-59\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M11045.0,616.5 L11053.0,604.5 11037.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-60\" stroke-width=\"2px\" d=\"M11270,614.5 C11270,527.0 11395.0,527.0 11395.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-60\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M11270,616.5 L11262,604.5 11278,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-61\" stroke-width=\"2px\" d=\"M11620,614.5 C11620,439.5 11925.0,439.5 11925.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-61\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M11620,616.5 L11612,604.5 11628,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-62\" stroke-width=\"2px\" d=\"M11795,614.5 C11795,527.0 11920.0,527.0 11920.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-62\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M11795,616.5 L11787,604.5 11803,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-63\" stroke-width=\"2px\" d=\"M11445,614.5 C11445,352.0 11930.0,352.0 11930.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-63\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M11930.0,616.5 L11938.0,604.5 11922.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-64\" stroke-width=\"2px\" d=\"M11970,614.5 C11970,527.0 12095.0,527.0 12095.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-64\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M12095.0,616.5 L12103.0,604.5 12087.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-65\" stroke-width=\"2px\" d=\"M12145,614.5 C12145,527.0 12270.0,527.0 12270.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-65\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M12270.0,616.5 L12278.0,604.5 12262.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-66\" stroke-width=\"2px\" d=\"M12495,614.5 C12495,527.0 12620.0,527.0 12620.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-66\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M12495,616.5 L12487,604.5 12503,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-67\" stroke-width=\"2px\" d=\"M11970,614.5 C11970,264.5 12635.0,264.5 12635.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-67\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M12635.0,616.5 L12643.0,604.5 12627.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-68\" stroke-width=\"2px\" d=\"M11445,614.5 C11445,2.0 12825.0,2.0 12825.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-68\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M12825.0,616.5 L12833.0,604.5 12817.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-69\" stroke-width=\"2px\" d=\"M12845,614.5 C12845,527.0 12970.0,527.0 12970.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-69\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"></textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M12970.0,616.5 L12978.0,604.5 12962.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-70\" stroke-width=\"2px\" d=\"M13195,614.5 C13195,527.0 13320.0,527.0 13320.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-70\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M13320.0,616.5 L13328.0,604.5 13312.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-71\" stroke-width=\"2px\" d=\"M13370,614.5 C13370,527.0 13495.0,527.0 13495.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-71\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M13495.0,616.5 L13503.0,604.5 13487.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-72\" stroke-width=\"2px\" d=\"M13545,614.5 C13545,527.0 13670.0,527.0 13670.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-72\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M13670.0,616.5 L13678.0,604.5 13662.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-73\" stroke-width=\"2px\" d=\"M13895,614.5 C13895,439.5 14200.0,439.5 14200.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-73\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M13895,616.5 L13887,604.5 13903,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-74\" stroke-width=\"2px\" d=\"M14070,614.5 C14070,527.0 14195.0,527.0 14195.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-74\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M14070,616.5 L14062,604.5 14078,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-75\" stroke-width=\"2px\" d=\"M13545,614.5 C13545,264.5 14210.0,264.5 14210.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-75\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M14210.0,616.5 L14218.0,604.5 14202.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-76\" stroke-width=\"2px\" d=\"M14420,614.5 C14420,439.5 14725.0,439.5 14725.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-76\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M14420,616.5 L14412,604.5 14428,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-77\" stroke-width=\"2px\" d=\"M14595,614.5 C14595,527.0 14720.0,527.0 14720.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-77\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M14595,616.5 L14587,604.5 14603,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-78\" stroke-width=\"2px\" d=\"M14945,614.5 C14945,527.0 15070.0,527.0 15070.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-78\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M14945,616.5 L14937,604.5 14953,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-79\" stroke-width=\"2px\" d=\"M14770,614.5 C14770,439.5 15075.0,439.5 15075.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-79\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M15075.0,616.5 L15083.0,604.5 15067.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-80\" stroke-width=\"2px\" d=\"M15120,614.5 C15120,527.0 15245.0,527.0 15245.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b0fde0a1dc444395aa533e71ddb1eeba-0-80\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M15245.0,616.5 L15253.0,604.5 15237.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.serve(doc_df[4], style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UpFwoavpy1H7"
   },
   "source": [
    "### Usando Textblob:\n",
    "\n",
    "Por otra parte, también tenemos ``TextBlob``, que nos permitirá cosas parecidas, tal como muestra en su [documentación](https://textblob.readthedocs.io/en/dev/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49636,
     "status": "ok",
     "timestamp": 1600932044485,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "vZk8yu9Mk37P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: textblob in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.47.0)\n",
      "Requirement already satisfied: regex in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2020.6.8)\n",
      "Requirement already satisfied: click in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\thebridge\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 50210,
     "status": "ok",
     "timestamp": 1600932045099,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "I7RvQOyrBsz3",
    "outputId": "e9893181-c68d-4acb-fd22-a6ad9d9cc385"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\TheBridge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\TheBridge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49630,
     "status": "ok",
     "timestamp": 1600932044485,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "RTCz0Q_Ty1H7"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EpIJX8L-y1H8"
   },
   "source": [
    "El mecanismo de etiquetado por defecto de TextBlob utiliza PatternTagger, lo cual es bueno para nuestro ejemplo. Para usar el NLTK tagger, podemos especificar el  pos_tagger cuando llamamos a TextBlob. Más detalle de estas acciones avanzadas en su [documentación avanzada](http://textblob.readthedocs.io/en/dev/advanced_usage.html#advanced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49622,
     "status": "ok",
     "timestamp": 1600932044486,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "ph5GAFaIy1H9",
    "outputId": "26d339d0-f3a1-4110-ad19-d5d66097ce4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_df = review_df['text'].iloc[:100].apply(TextBlob)\n",
    "type(blob_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49609,
     "status": "ok",
     "timestamp": 1600932044486,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "bNTIxc1_y1H-",
    "outputId": "e56603d3-8989-4f40-dc27-e6a7477206e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob.blob.TextBlob"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(blob_df[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 50606,
     "status": "ok",
     "timestamp": 1600932045508,
     "user": {
      "displayName": "Alberto Romero",
      "photoUrl": "",
      "userId": "13942113647740663414"
     },
     "user_tz": -120
    },
    "id": "i2vgNTXHy1IA",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "ed653587-1a0d-4211-fa6a-d17abb0f0d42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('General', 'NNP'),\n",
       " ('Manager', 'NNP'),\n",
       " ('Scott', 'NNP'),\n",
       " ('Petello', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('good', 'JJ'),\n",
       " ('egg', 'NN'),\n",
       " ('Not', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('go', 'VB'),\n",
       " ('into', 'IN'),\n",
       " ('detail', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('let', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('assure', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('if', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('any', 'DT'),\n",
       " ('issues', 'NNS'),\n",
       " ('albeit', 'IN'),\n",
       " ('rare', 'NN'),\n",
       " ('speak', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('Scott', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('treat', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('guy', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('respect', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('state', 'NN'),\n",
       " ('your', 'PRP$'),\n",
       " ('case', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " (\"'d\", 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('surprised', 'VBN'),\n",
       " ('if', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('walk', 'VB'),\n",
       " ('out', 'RP'),\n",
       " ('totally', 'RB'),\n",
       " ('satisfied', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('did', 'VBD'),\n",
       " ('Like', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('always', 'RB'),\n",
       " ('say', 'VBP'),\n",
       " ('.....', 'JJ'),\n",
       " ('Mistakes', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('inevitable', 'JJ'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('how', 'WRB'),\n",
       " ('we', 'PRP'),\n",
       " ('recover', 'VBP'),\n",
       " ('from', 'IN'),\n",
       " ('them', 'PRP'),\n",
       " ('that', 'WDT'),\n",
       " ('is', 'VBZ'),\n",
       " ('important', 'JJ'),\n",
       " ('Thanks', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('Scott', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('his', 'PRP$'),\n",
       " ('awesome', 'JJ'),\n",
       " ('staff', 'NN'),\n",
       " ('You', 'PRP'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('got', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('customer', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('life', 'NN'),\n",
       " ('..........', 'NN'),\n",
       " ('^', 'NN')]"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_df[4].tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero no solo podemos extraer los tags de un texto, sino que también podemos realizar cosas como un análisis de sentimiento, donde nos dirá, para un texto en concreto, el nivel de polaridad (de -1 (malo) a 1 (bueno)) y su objetividad (de 0 (objetivo) a 1 (subjetivo)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Manager Scott Petello is a good egg!!! Not to go into detail, but let me assure you if you have any issues (albeit rare) speak with Scott and treat the guy with some respect as you state your case and I'd be surprised if you don't walk out totally satisfied as I just did. Like I always say..... \"Mistakes are inevitable, it's how we recover from them that is important\"!!!\n",
      "\n",
      "Thanks to Scott and his awesome staff. You've got a customer for life!! .......... :^)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.468125, subjectivity=0.8100000000000002)"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(blob_df[4])\n",
    "blob_df[4].sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.22977272727272727, subjectivity=0.6384848484848485)"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_df[1].sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=1.0, subjectivity=0.7800000000000001)"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si lo probamos para unos textos en particular:\n",
    "texto = \"Very good!\"\n",
    "blob_texto = TextBlob(texto)\n",
    "blob_texto.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO\n",
    "\n",
    "1. Crea una función a la que le pasemos un string, realice el análisis de sentimiento e imprima por pantalla algo como:\n",
    "\n",
    "```\n",
    "Texto:\n",
    "Aquí vendría el texto bajo análisis.\n",
    "\n",
    "Polaridad: 0.87\n",
    "Subjetividad: 0.5\n",
    "```\n",
    "\n",
    "2. Crea otra función que reciba una serie de textos y calcule la media de la polaridad y objetividad. Deberá imprimir un mensaje por pantalla como el siguiente:\n",
    "```\n",
    "Media de polaridad: 0.66\n",
    "Media de subjetividad: 0.2\n",
    "```\n",
    "\n",
    "\n",
    "    A lo que deberá de añadir un mensaje que diga que los mensajes son \"muy buenos\" (0.8, 1], \"buenos\" (0.5, 0.8], \"normales\" [-0.5, 0.5], \"malos\" [-0.8, -0.5) o \"muy malos\" [-1, -0.8), y \"muy objetivos\" [0, 0.1), \"objetivos\" [0.1, 0.3), \"no demasiado objetivos\" [0.3, 0.7], \"subjetivos\" (0.7, 0.9], \"muy subjetivos\" (0.9, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lista_textos = pd.Series([\"Very good!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_txt(text):\n",
    "    from textblob import TextBlob\n",
    "    import numpy as np\n",
    "    all_polarities = []\n",
    "    all_subjectivity = []\n",
    "    blob_text = text.apply(TextBlob)\n",
    "    for comments in blob_text:\n",
    "        all_polarities.append(comments.sentiment[0])\n",
    "        all_subjectivity.append(comments.sentiment[1])\n",
    "    if np.mean(all_polarities) >= 0.8:\n",
    "        print(f'Los mensajes son muy buenos, la media de polaridad es {np.mean(all_polarities)}')\n",
    "    elif (np.mean(all_polarities) >= 0.5) and (np.mean(all_polarities) < 0.8):\n",
    "        print(f'Los mensajes son buenos, la media de polaridad es {np.mean(all_polarities)}')\n",
    "    elif (np.mean(all_polarities) >= -0.5) and (np.mean(all_polarities) < 0.5):\n",
    "        print(f'Los mensajes son normales, la media de polaridad es {np.mean(all_polarities)}')\n",
    "    elif (np.mean(all_polarities) >= -0.8) and (np.mean(all_polarities) < -0.5):\n",
    "        print(f'Los mensajes son malos, la media de polaridad es {np.mean(all_polarities)}')\n",
    "    elif (np.mean(all_polarities) >= -1) and (np.mean(all_polarities) < -0.8):\n",
    "        print(f'Los mensajes son muy malos, la media de polaridad es {np.mean(all_polarities)}')\n",
    "    if (np.mean(all_subjectivity) >= 0) and (np.mean(all_subjectivity) < 0.1):\n",
    "        print(f'Los mensajes son muy objetivos, la media de subjetividad es {np.mean(all_subjectivity)}')\n",
    "    elif (np.mean(all_subjectivity) >= 0.1) and (np.mean(all_subjectivity) < 0.3):\n",
    "        print(f'Los mensajes son objetivos, la media de subjetividad es {np.mean(all_subjectivity)}')\n",
    "    elif (np.mean(all_subjectivity) >= 0.3) and (np.mean(all_subjectivity) < 0.7):\n",
    "        print(f'Los mensajes no son demasiado objetivos, la media de subjetividad es {np.mean(all_subjectivity)}')\n",
    "    elif (np.mean(all_subjectivity) >= 0.7) and (np.mean(all_subjectivity) < 0.9):\n",
    "        print(f'Los mensajes son subjetivos, la media de subjetividad es {np.mean(all_subjectivity)}')\n",
    "    elif (np.mean(all_subjectivity) >= 0.9) and (np.mean(all_subjectivity) < 1):\n",
    "        print(f'Los mensajes son muy subjetivos, la media de subjetividad es {np.mean(all_subjectivity)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los mensajes son muy buenos, la media de polaridad es 1.0\n",
      "Los mensajes son subjetivos, la media de subjetividad es 0.7800000000000001\n"
     ]
    }
   ],
   "source": [
    "multiple_txt(lista_textos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "COLAB_PROFE_TextData.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
